## 机器学习算法

## 目录参考
1. 理解时间
2. 背景介绍
3. 参考资料
4. 核心思考问题
5. 入门概念
6. 阅读笔记
7. 项目工作流
8. 技术流图和图解
9.  源码目录
10. 模块拆解-横向
11. 模块拆解-纵向
12. 性能总结
13. 设计总结
14. 经验总结
15. 第三方依赖
16. 应用场景
17. 业务通点
18. 行业实践
19. case代码


### 理解时间
```
2024年10月10号启动

永远带着问题/需求/目标/兴趣/收益看代码

源码理解角度
   高层次流图分析 - 更好把握主次
    比如大数据框架 考虑流式计算范式
    比如机器学习框架 考虑数学计算流图
    共性分析数据格式 存储 读写 和 网络流图
    业务使用流程图和场景图
   横向梳理所有模块
   纵向梳理某个功能点
   编译角度
   使用角度
   性能角度
   底层数据结构角度

完整理解机器学习算法项目
如果只是在搜索引擎 搜 机器学习算法是远远不够的
机器学习算法 + 架构图

机器学习算法 + 概念关键词

机器学习算法 + 问题排查

机器学习算法 + 面试汇总

机器学习算法 + 极客挑战赛

机器学习算法 + 论坛会议

机器学习算法 + 论文

机器学习算法 + 前沿分享

机器学习算法 + 场景应用

机器学习算法 + 机器学习算法大佬名字

机器学习算法 + 公司项目
等等才能完全熟悉机器学习算法


```

## 参考资料
1. 基础算法实现：https://github.com/MLEveryday/practicalAI-cn?tab=readme-ov-file
2. 传统模型讲解：https://www.zhihu.com/column/easymachinelearning
3. numpy手写度量：https://zhuanlan.zhihu.com/p/130318593
4. numpy-ml：https://github.com/ddbourgin/numpy-ml
5. pytorch复现论文仓库：https://github.com/lucidrains/
6. ml学习路径：https://github.com/loveunk/machine-learning-deep-learning-notes?tab=readme-ov-file
7. xgboost
   1. 讲解：https://www.youtube.com/watch?v=GrJP9FLV3FE&t=2005s
8. 


## 核心
1. 吐槽
   1. 网上一搜kaggle普遍是泰坦尼克号教程，根本没有进阶的材料
   2. 高质量内容还是得持续做，坚持做
2. 从0实现
   1. knn：https://github.com/yunsuxiaozi/Implementing-algorithms-from-scratch/blob/main/KNNalgorithm/KNN%20algorithm.ipynb
   2. 线性回归：https://github.com/yunsuxiaozi/Implementing-algorithms-from-scratch/blob/main/KNNalgorithm/KNN%20algorithm.ipynb
   3. 李航统计机器学习书本算法实现：https://github.com/fengdu78/lihang-code/blob/master/%E7%AC%AC02%E7%AB%A0%20%E6%84%9F%E7%9F%A5%E6%9C%BA/2.Perceptron.ipynb
   4. The Elements of Statistical Learning  esl算法实现：https://github.com/szcf-weiya/ESL-CN
   5. ctr：https://github.com/shenweichen/DeepCTR
3. 深度学习教材 一本就够了
   1. https://zh.d2l.ai/chapter_linear-networks/linear-regression.html#subsec-normal-distribution-and-squared-loss
4. 机器学习教材
   1. https://www.csie.ntu.edu.tw/~htlin/
   2. 机器学习基石（林轩田）：https://github.com/RedstoneWill/HsuanTienLin_MachineLearning/tree/master/Machine%20Learning%20Foundations
   3. 机器学习技法（林轩田）：https://github.com/RedstoneWill/HsuanTienLin_MachineLearning/tree/master/Machine%20Learning%20Techniques
5. 数据分布
   1. 实验，调整，过拟合和优化：https://openeclass.panteion.gr/modules/document/file.php/PMS152/LEARNING/Abu-Mostafa%20Yaser%20S.%2C%20Malik%20Magdon%20%282012%29%20--Ismail%2C%20et%20al.%2C%20Learning%20From%20Data%20-%20A%20short%20course%20%282012%29.pdf
6. 课程作业和问题
   1. cs231：https://cs231n.github.io/
      1. https://github.com/Halfish/cs231n
      2. 



## 方法
1. 

## 常见模型原理

### Transformer
```
如何最简单、通俗地理解Transformer？ - 鱼先生的回答 - 知乎
https://www.zhihu.com/question/445556653/answer/2882383919
Transformer 之逐层介绍 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604450283
Transformer 之多头注意力 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604452790
Transformer 之注意力计算原理 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604454823


【【精校珍藏版】大牛Andrej Karpathy的stanford深度学习课程：深入理解Transformer，从零打造最简版GPT】 https://www.bilibili.com/video/BV1Tm4y1b7UP/?share_source=copy_web&vd_source=8783d6f7758784f093c06edba717af3d


源码实现（有能力自己看）
http://nlp.seas.harvard.edu/annotated-transformer/
https://wmathor.com/index.php/archives/1455/
https://github.com/BoXiaolei/MyTransformer_pytorch
nlp模型算法实现：https://github.com/graykode/nlp-tutorial


源码讲解
https://wmathor.com/index.php/archives/1438/

```


#### 整体思路
1. Key
2. Query
3. Value
4. QKV计算公式，如何初始化，最终达到注意力的效果

#### LSTM RNN 对比
1. 没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系
2. 位置嵌入的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成
3. 

#### 注意力机制
1. Embedding Size
2. Query
3. number of Attention heads
4. batch_size
思路灵感
1. Neural machine translation by jointly learning to align and translate
2. Massive exploration of neural machine translation architectures


#### layer-normal
```
思路灵感
Layer normalization

```
#### position encoding
```
思路灵感
Convolutional sequence to sequence learning



```

#### position-wise feedward networks
1. 

#### 网络结构优化
思路灵感
1. Rethinking the inception architecture for computer vision
2.  Dropout: a simple way to prevent neural networks from overfitting
3.  Deep residual learning for image recognition

### Bert
```

```

### resnet
```

```



### ernie-m 网络结构
```
NetWork(
  (ernie): ErnieMModel(
    (embeddings): ErnieMEmbeddings(
      (word_embeddings): Embedding(250002, 768, sparse=False)
      (position_embeddings): Embedding(514, 768, sparse=False)
      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (encoder): TransformerEncoder(
      (layers): LayerList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (6): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (7): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (8): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (9): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (10): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (11): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
    (pooler): ErnieMPooler(
      (dense): Linear(in_features=768, out_features=768, dtype=float32)
      (activation): Tanh()
    )
  )
  (resnet): EncoderCNN(
    (resnet): Sequential(
      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)
      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
      (2): ReLU()
      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)
      (4): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (5): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (6): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (4): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (5): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (6): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (7): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (8): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (9): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (10): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (11): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (12): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (13): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (14): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (15): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (16): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (17): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (18): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (19): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (20): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (21): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (22): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (7): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
    )
    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))
  )
  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)
  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)
  (attention_text): MultiHeadAttention(
    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
  )
  (attention_image): MultiHeadAttention(
    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
  )
)
```



### DSSM双塔模型
```
DSSM双塔模型及pytorch实现 - 简之的文章 - 知乎
https://zhuanlan.zhihu.com/p/402123341

https://github.com/MemoryForSky/deepctr

https://github.com/HeartFu/DSSM.git

```
 
### wide & deep & XDeepFM 
1. wide
   1. 特征构造
   2. 特征交叉
   3. FTRL优化器（特征稀疏）
2. depp
   1. embedding层
   2. nn层
   3. AdaGrad优化器

### FM & FFM & DeepFM & DeepFFM
```





```

### DCN & DCNv2



## 线性模型
### LR - 单输出的线性模型
1. Derivative of Cost function for Logistic Regression | Machine Learning：https://www.youtube.com/watch?v=0VMK18nphpg&t=312s
2. Beginner’s Guide to Finding Gradient/Derivative of Log Loss by Hand (Detailed Steps)：https://medium.com/@ilmunabid/beginners-guide-to-finding-gradient-derivative-of-log-loss-by-hand-detailed-steps-74a6cacfe5cf
3. find loss function：https://towardsdatascience.com/calculating-gradient-descent-manually-6d9bee09aa0b
4. 原书：https://zh.d2l.ai/chapter_linear-networks/linear-regression.html#subsec-linear-model
5. 公式源码：https://github.com/d2l-ai/d2l-zh/blob/master/chapter_linear-networks/linear-regression.md

### LR - 模型公式
$\hat{y} = w_1x_1 + .. + w_dx_d + b$

$\downarrow$ 向量化并点积运算 $\mathbf{x} \in \mathbb{R}^d$ $\mathbf{w} \in \mathbb{R}^d$ 

$\hat{y} = \mathbf{w}^\top \mathbf{x} + b$

$\downarrow$ N个样本， 矩阵化 $\mathbf{X} \in \mathbb{R}^{n \times d}$ $\mathbf{X}$的每一行是一个样本，每一列是一种特征

$\downarrow$ N个预测值 $\hat{\mathbf{y}} \in \mathbb{R}^n$

${\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b$

### LR - 模型目标
线性回归的目标是找到一组权重向量$\mathbf{w}$和偏置$b$。当给定从$\mathbf{X}$的同分布中取样的新样本特征时， 这组权重向量和偏置能够使得新样本预测标签的误差尽可能小
1. 前提：样本分布尽可能符合线性模型才有意义


### LR - 损失函数
$l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2.$

### LR - 模型更新参数
1. 初始化模型参数的值，如随机初始化
2. 从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤
3. 平方损失和仿射变换


gradient descent $\rightarrow$ minibatch stochastic gradient descent

$\begin{aligned} \mathbf{w} &\leftarrow \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b) = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right),\ b &\leftarrow b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_b l^{(i)}(\mathbf{w}, b) = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right). \end{aligned}$

### LR - 模型画图


### Softmax regression 多输出的线性模型
1. https://zh.d2l.ai/chapter_linear-networks/softmax-regression.html
2. 分类问题
   1. 我们只对样本的“硬性”类别感兴趣，即属于哪个类别
   2. 我们希望得到“软性”类别，即得到属于每个类别的概率
   3. 我们只关心硬类别，但是我们使用软类别的模型解决分类问题


### Softmax - 模型公式


### Softmax - 模型目标


### Softmax - 损失函数


### Softmax - 模型更新参数


### Softmax - 模型画图

## 非线性模型
### MLP
### MLP - 模型公式


### MLP - 模型目标


### MLP - 损失函数


### MLP - 模型更新参数


### MLP - 模型画图



## 树模型
### lightgbm
1. parameters：https://lightgbm.readthedocs.io/en/stable/Parameters.html
2. application：https://lightgbm.readthedocs.io/en/stable/Features.html
   1. regression, the objective function is L2 loss
   2. binary classification, the objective function is logloss
   3. multi classification
   4. cross-entropy, the objective function is logloss and supports training on non-binary labels
   5. LambdaRank, the objective function is LambdaRank with NDCG

### xgboost
1. Introduction to Boosted Trees：https://xgboost.readthedocs.io/en/stable/tutorials/model.html

### gbdt(traditional Gradient Boosting Decision Tree)


### rf(Random Forest)

### dart(Dropouts meet Multiple Additive Regression Trees)




## 评估指标

### mse - mean_squared_error
1. parameters：https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_squared_error.html
2. source code：https://gist.github.com/cookieblues/9030aa56732241fd10acdf7cc0c5ba6d

### mse - code
```

numpy version
mse = (np.square(A - B)).mean(axis=ax)
or 
mse = ((A - B)**2).mean(axis=ax)

```

### mse - math

$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$

其中：
- \( n \) 是样本数量。
- \( y_i \) 是第 \( i \) 个样本的真实值。
- \( \hat{y}_i \) 是第 \( i \) 个样本的预测值。

### mse - gradient 梯度
1. https://blog.csdn.net/hei653779919/article/details/104167070




### rmse - root mean squared error
1. description：https://docs.oracle.com/en/cloud/saas/planning-budgeting-cloud/pfusu/insights_metrics_RMSE.html

### rmse - code
```
def rmse(y_true, y_pred):
  return np.sqrt(np.mean((y_true - y_pred)**2))
```

### rmse - math
formula

$RMSE = \sqrt{\sum_{i=1}^{n}\frac{(\hat{y_i} - y_i)^2}{n}}$


### rmse - gradient 




## 微积分
1. https://github.com/d2l-ai/d2l-en/blob/master/chapter_preliminaries/calculus.md?plain=1
2. 问题
   1. 梯度怎么算，损失函数怎么推导出来的
3. Calculating Gradient Descent Manually：https://towardsdatascience.com/calculating-gradient-descent-manually-6d9bee09aa0b
4. 深度学习中的梯度计算与反向传播推导（一）DNN中单样本反向传播推导：https://blog.csdn.net/qq_42734797/article/details/109539100
5. 【转载】梯度下降法的推导（非常详细、易懂的推导）：https://blog.csdn.net/byn12345/article/details/101081537



### 极限
$f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h) - f(x)}{h}$
1. f在x处，可微分

### 偏导数


### 矩阵求导和求偏导


### 梯度
1. 梯度结果含义
2. 应用适当的损失函数，根据模型参数最小化损失



### 链式法则




### 自动微分


### 仿射函数 affine function

### 损失函数 loss function
1. https://www.datarobot.com/blog/introduction-to-loss-functions/


## 概率
1. 如何将输出转换为有效的概率分布

### 抽样
1. 从概率分布中抽取样本的过程


### 分布
1. 分布（distribution）看作对事件的概率分配
2. 将概率分配给一些离散选择的分布称为多项分布（multinomial distribution）


### 随机变量


### 高斯分布

### gamma分布

## 信息论 information theory 
### 熵

## xxx

### xxx - 模型公式


### xxx - 模型目标


### xxx - 损失函数


### xxx - 模型更新参数


### xxx - 模型画图