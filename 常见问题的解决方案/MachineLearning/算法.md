## 机器学习算法

## 目录参考
1. 理解时间
2. 背景介绍
3. 参考资料
4. 核心思考问题
5. 入门概念
6. 阅读笔记
7. 项目工作流
8. 技术流图和图解
9.  源码目录
10. 模块拆解-横向
11. 模块拆解-纵向
12. 性能总结
13. 设计总结
14. 经验总结
15. 第三方依赖
16. 应用场景
17. 业务通点
18. 行业实践
19. case代码


### 理解时间
```
2024年10月10号启动

永远带着问题/需求/目标/兴趣/收益看代码

源码理解角度
   高层次流图分析 - 更好把握主次
    比如大数据框架 考虑流式计算范式
    比如机器学习框架 考虑数学计算流图
    共性分析数据格式 存储 读写 和 网络流图
    业务使用流程图和场景图
   横向梳理所有模块
   纵向梳理某个功能点
   编译角度
   使用角度
   性能角度
   底层数据结构角度

完整理解机器学习算法项目
如果只是在搜索引擎 搜 机器学习算法是远远不够的
机器学习算法 + 架构图

机器学习算法 + 概念关键词

机器学习算法 + 问题排查

机器学习算法 + 面试汇总

机器学习算法 + 极客挑战赛

机器学习算法 + 论坛会议

机器学习算法 + 论文

机器学习算法 + 前沿分享

机器学习算法 + 场景应用

机器学习算法 + 机器学习算法大佬名字

机器学习算法 + 公司项目
等等才能完全熟悉机器学习算法


```

## 参考资料
1. 基础算法实现：https://github.com/MLEveryday/practicalAI-cn?tab=readme-ov-file
2. 传统模型讲解：https://www.zhihu.com/column/easymachinelearning
3. numpy手写度量：https://zhuanlan.zhihu.com/p/130318593
4. numpy-ml：https://github.com/ddbourgin/numpy-ml
5. pytorch复现论文仓库：https://github.com/lucidrains/
6. ml学习路径：https://github.com/loveunk/machine-learning-deep-learning-notes?tab=readme-ov-file
7. xgboost
   1. 讲解：https://www.youtube.com/watch?v=GrJP9FLV3FE&t=2005s
8. 


## 核心
1. 吐槽
   1. 网上一搜kaggle普遍是泰坦尼克号教程，根本没有进阶的材料
   2. 高质量内容还是得持续做，坚持做
2. 从0实现
   1. knn：https://github.com/yunsuxiaozi/Implementing-algorithms-from-scratch/blob/main/KNNalgorithm/KNN%20algorithm.ipynb
   2. 线性回归：https://github.com/yunsuxiaozi/Implementing-algorithms-from-scratch/blob/main/KNNalgorithm/KNN%20algorithm.ipynb
   3. 李航统计机器学习书本算法实现：https://github.com/fengdu78/lihang-code/blob/master/%E7%AC%AC02%E7%AB%A0%20%E6%84%9F%E7%9F%A5%E6%9C%BA/2.Perceptron.ipynb
   4. The Elements of Statistical Learning  esl算法实现：https://github.com/szcf-weiya/ESL-CN
   5. ctr：https://github.com/shenweichen/DeepCTR
   6. pytorch高级编程：https://github.com/BinFuPKU/pytorch-practice
3. 深度学习教材 一本就够了
   1. https://zh.d2l.ai/chapter_linear-networks/linear-regression.html#subsec-normal-distribution-and-squared-loss
4. 机器学习教材
   1. https://www.csie.ntu.edu.tw/~htlin/
   2. 统计学习方法：https://datawhalechina.github.io/statistical-learning-method-solutions-manual/#/
   3. 机器学习基石（林轩田）：https://github.com/RedstoneWill/HsuanTienLin_MachineLearning/tree/master/Machine%20Learning%20Foundations
   4. 机器学习技法（林轩田）：https://github.com/RedstoneWill/HsuanTienLin_MachineLearning/tree/master/Machine%20Learning%20Techniques
   5. 李宏毅ML：https://github.com/doongz/ml-lhy 一般般别看了

5. 数据分布
   1. 实验，调整，过拟合和优化：https://openeclass.panteion.gr/modules/document/file.php/PMS152/LEARNING/Abu-Mostafa%20Yaser%20S.%2C%20Malik%20Magdon%20%282012%29%20--Ismail%2C%20et%20al.%2C%20Learning%20From%20Data%20-%20A%20short%20course%20%282012%29.pdf
6. 课程作业和问题
   1. cs231：https://cs231n.github.io/
      1. https://github.com/Halfish/cs231n
7. 算法日常
   1. 傅聪Cong：https://www.zhihu.com/question/29692814/answer/1647726434

## 问题
1. 解决给用户发放信用卡额度的问题，为什么是一个线性回归问题。如何定义一个问题是线性回归问题
   1. 主要是因为这个问题的目标是预测一个连续的数值（即信用额度）。线性回归是一种常用的统计方法，用于建立因变量（目标变量）和一个或多个自变量（特征变量）之间的线性关系。
   2. 

## 方法
1. 

## 常见模型原理

### Transformer
```
如何最简单、通俗地理解Transformer？ - 鱼先生的回答 - 知乎
https://www.zhihu.com/question/445556653/answer/2882383919
Transformer 之逐层介绍 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604450283
Transformer 之多头注意力 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604452790
Transformer 之注意力计算原理 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604454823


【【精校珍藏版】大牛Andrej Karpathy的stanford深度学习课程：深入理解Transformer，从零打造最简版GPT】 https://www.bilibili.com/video/BV1Tm4y1b7UP/?share_source=copy_web&vd_source=8783d6f7758784f093c06edba717af3d


源码实现（有能力自己看）
http://nlp.seas.harvard.edu/annotated-transformer/
https://wmathor.com/index.php/archives/1455/
https://github.com/BoXiaolei/MyTransformer_pytorch
nlp模型算法实现：https://github.com/graykode/nlp-tutorial


源码讲解
https://wmathor.com/index.php/archives/1438/

```


#### 整体思路
1. Key
2. Query
3. Value
4. QKV计算公式，如何初始化，最终达到注意力的效果

#### LSTM RNN 对比
1. 没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系
2. 位置嵌入的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成
3. 

#### 注意力机制
1. Embedding Size
2. Query
3. number of Attention heads
4. batch_size
思路灵感
1. Neural machine translation by jointly learning to align and translate
2. Massive exploration of neural machine translation architectures


#### layer-normal
```
思路灵感
Layer normalization

```
#### position encoding
```
思路灵感
Convolutional sequence to sequence learning



```

#### position-wise feedward networks
1. 

#### 网络结构优化
思路灵感
1. Rethinking the inception architecture for computer vision
2.  Dropout: a simple way to prevent neural networks from overfitting
3.  Deep residual learning for image recognition

### Bert
```

```

### resnet
```

```



### ernie-m 网络结构
```
NetWork(
  (ernie): ErnieMModel(
    (embeddings): ErnieMEmbeddings(
      (word_embeddings): Embedding(250002, 768, sparse=False)
      (position_embeddings): Embedding(514, 768, sparse=False)
      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (encoder): TransformerEncoder(
      (layers): LayerList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (6): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (7): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (8): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (9): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (10): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (11): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
    (pooler): ErnieMPooler(
      (dense): Linear(in_features=768, out_features=768, dtype=float32)
      (activation): Tanh()
    )
  )
  (resnet): EncoderCNN(
    (resnet): Sequential(
      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)
      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
      (2): ReLU()
      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)
      (4): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (5): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (6): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (4): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (5): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (6): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (7): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (8): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (9): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (10): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (11): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (12): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (13): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (14): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (15): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (16): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (17): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (18): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (19): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (20): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (21): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (22): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (7): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
    )
    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))
  )
  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)
  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)
  (attention_text): MultiHeadAttention(
    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
  )
  (attention_image): MultiHeadAttention(
    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
  )
)
```


## 广告模型

### FM：Factorization Machines

### FFM

### AFM：Attentional Factorization Machines

### Embedding+MLP


### DeepFM & DeepFFM
```





```

### 双路并行的模型

### DSSM双塔模型
```
DSSM双塔模型及pytorch实现 - 简之的文章 - 知乎
https://zhuanlan.zhihu.com/p/402123341

https://github.com/MemoryForSky/deepctr

https://github.com/HeartFu/DSSM.git

```
 
### wide & deep & XDeepFM 
1. wide
   1. 特征构造
   2. 特征交叉
   3. FTRL优化器（特征稀疏）
2. depp
   1. embedding层
   2. nn层
   3. AdaGrad优化器



### DCN & DCNv2



## 线性模型
1. LR 有多层含义，linear regression 或者 log-log linear regression 又或者 logistic regression
2. 

### LR - 探究根本
1. 如何判断一个问题，属于线性回归问题
2. 什么是线性回归
   1. 在统计学中，利用称为线性回归方程的最小二乘函数对一个或多个自变量和因变量之间关系进行建模的一种回归分析
   2. 线性回归的“回归”指的是回归到平均值
3. 什么是回归分析
   1. 回归分析 一种统计学上分析数据的方法，目的在于了解两个或多个变量间是否相关、相关方向与强度，并建立数学模型以便观察特定变量来预测研究者感兴趣的变量。
   2. 回归的最早形式是最小二乘法
   3. 目的在于找出一条最能够代表所有观测资料的函数曲线（回归估计式）
   4. 用此函数代表因变量和自变量之间的关系。
4. 什么是回归模型
   1. 未知参数，记为${\displaystyle \beta}$，可以代表一个标量或一个向量。
   2. 自变量，${\displaystyle \mathbf {X} }$
   3. 因变量，${\displaystyle Y}$
   4. 回归模型将${\displaystyle Y}$和一个关于${\displaystyle \mathbf {X} }$和${\displaystyle \beta }$的函数关联起来
5. 回归模型种类
   1. 简单线性回归
   2. 复回归（或多变量回归）
   3. 对数线性回归：Log-linear model 取对数值之后再进行线性回归 
   4. 对数几率回归：Logistic regression 
      1. log 和 logistic区别：https://www.quora.com/What-is-the-difference-between-log-log-regression-and-logistic-regression
      2. 在二元逻辑回归中，有一个二元因变量，用于二元分类问题
   5. 偏回归：Partial Regression
   6. 自回归：
   7. 自回归滑动平均模型
   8. 差分自回归滑动平均模型
   9. 向量自回归模型
6. 什么是最小二乘法 Least squares
   1. 又称最小平方法，是一种数学优化建模方法。它通过最小化误差的平方和寻找数据的最佳函数匹配。
   2. 最重要的应用是在曲线拟合上。最小二乘所涵义的最佳拟合，即残差（残差为：观测值与模型提供的拟合值之间的差距）平方总和的最小化。
7. 什么是残差
   1. 统计学和最优化中，误差（error）和残差（residual）是两个相近但有区别的概念
   2. 残差是观测值与统计量的估计值（例如样本均值）之间的差值
   3. 误差是观测值与相关量（例如总体平均值）的真值之间的差值
   4. 误差也称为扰动（disturbances）
8. 什么是 closed-form的模型解

### LR - 单输出的线性模型
1. wiki：https://zh.wikipedia.org/wiki/%E7%B7%9A%E6%80%A7%E5%9B%9E%E6%AD%B8
2. Derivative of Cost function for Logistic Regression | Machine Learning：https://www.youtube.com/watch?v=0VMK18nphpg&t=312s
3. Beginner’s Guide to Finding Gradient/Derivative of Log Loss by Hand (Detailed Steps)：https://medium.com/@ilmunabid/beginners-guide-to-finding-gradient-derivative-of-log-loss-by-hand-detailed-steps-74a6cacfe5cf
4. find loss function：https://towardsdatascience.com/calculating-gradient-descent-manually-6d9bee09aa0b
5. 原书：https://zh.d2l.ai/chapter_linear-networks/linear-regression.html#subsec-linear-model
6. 公式源码：https://github.com/d2l-ai/d2l-zh/blob/master/chapter_linear-networks/linear-regression.md


### LR - 更详细定义和理解
1. 统计学 -> 线性回归 
2. 


### LR - 模型公式
$\hat{y} = w_1x_1 + .. + w_dx_d + b$

$\downarrow$ 向量化并点积运算 $\mathbf{x} \in \mathbb{R}^d$ $\mathbf{w} \in \mathbb{R}^d$ 

$\hat{y} = \mathbf{w}^\top \mathbf{x} + b$

$\downarrow$ N个样本， 矩阵化 $\mathbf{X} \in \mathbb{R}^{n \times d}$ $\mathbf{X}$的每一行是一个样本，每一列是一种特征

$\downarrow$ N个预测值 $\hat{\mathbf{y}} \in \mathbb{R}^n$

${\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b$

### LR - 模型目标
线性回归的目标是找到一组权重向量$\mathbf{w}$和偏置$b$。当给定从$\mathbf{X}$的同分布中取样的新样本特征时， 这组权重向量和偏置能够使得新样本预测标签的误差尽可能小
1. 前提：样本分布尽可能符合线性模型才有意义


### LR - 损失函数
$l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2.$

### LR - 模型更新参数
1. 初始化模型参数的值，如随机初始化
2. 从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤
3. 平方损失和仿射变换


gradient descent $\rightarrow$ minibatch stochastic gradient descent

$\begin{aligned} \mathbf{w} &\leftarrow \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{\mathbf{w}} l^{(i)}(\mathbf{w}, b) = \mathbf{w} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \mathbf{x}^{(i)} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right),\ b &\leftarrow b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_b l^{(i)}(\mathbf{w}, b) = b - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right). \end{aligned}$

### LR - 模型画图


### Logistic regression 多输出的线性模型
1. 

### Logistic - 模型公式


### Logistic - 模型目标


### Logistic - 损失函数


### Logistic - 模型更新参数


### Logistic - 模型画图

### Softmax regression 多输出的线性模型
1. https://zh.d2l.ai/chapter_linear-networks/softmax-regression.html
2. 分类问题
   1. 我们只对样本的“硬性”类别感兴趣，即属于哪个类别
   2. 我们希望得到“软性”类别，即得到属于每个类别的概率
   3. 我们只关心硬类别，但是我们使用软类别的模型解决分类问题
3. 一文搞懂 Softmax 函数：https://developer.volcengine.com/articles/7382255487758106675
4. 一文彻底搞懂 Softmax 函数：https://blog.csdn.net/qq_43799400/article/details/131202148
5. sigmoid 和 softmax结果区别：https://www.cnblogs.com/jins-note/p/12528412.html 写的不错
6. 公式源码：https://github.com/d2l-ai/d2l-zh/blob/master/chapter_linear-networks/softmax-regression.md
7. 尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。 因此，softmax回归是一个线性模型（linear model）！！！
8. 


### Softmax - 模型公式
Softmax激活函数

$\hat{\mathbf{y}} = \mathrm{softmax}(\mathbf{o})\quad where \quad \hat{y}_j = \frac{\exp(o_j)}{\sum_k \exp(o_k)}$

$\operatorname*{argmax}_j \hat{y_j} = \operatorname*{argmax}_j o_j.$

小批量样本的矢量化
$\begin{aligned} \mathbf{O} &= \mathbf{X} \mathbf{W} + \mathbf{b}, \ \hat{\mathbf{Y}} & = \mathrm{softmax}(\mathbf{O}). \end{aligned}$

### Softmax - 模型目标
```
def softmax(x):
  x_exp = x.exp()
  partition = x_exp.sum(dim=1, keepdim=True)
  return x_exp/partition

# net y = wx + b
def net(X):
  return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)
```

### Softmax - 损失函数
最大似然估计 度量预测效果

对数似然
$P(\mathbf{Y} \mid \mathbf{X}) = \prod_{i=1}^n P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}).$


根据最大似然估计，我们最大化$P(\mathbf{Y} \mid \mathbf{X})$，相当于最小化负对数似然：
$-\log P(\mathbf{Y} \mid \mathbf{X}) = \sum_{i=1}^n -\log P(\mathbf{y}^{(i)} \mid \mathbf{x}^{(i)}) = \sum_{i=1}^n l(\mathbf{y}^{(i)}, \hat{\mathbf{y}}^{(i)})$


其中，对于任何标签$\mathbf{y}$和模型预测$\hat{\mathbf{y}}$，损失函数为：
$l(\mathbf{y}, \hat{\mathbf{y}}) = - \sum_{j=1}^q y_j \log \hat{y}_j.$

交叉熵的推导

$$\begin{aligned}
l(\mathbf{y}, \mathbf{\hat{y}}) &= -\sum_{j=1}^q y_i \log\frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\ 
&= \sum_{j=1}^q y_i \log\sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_i o_j \\
&=  \log{\sum_{k=1}^q \exp(o_k)}^{\sum_{j=1}^q y_i} - \sum_{j=1}^q y_i o_j\\
&= \log\sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_i o_j 

\end{aligned}$$
$$\downarrow$$
$$\sum_{j=1}^q y_i = 1?$$




$$ \begin{aligned} l(\mathbf{y}, \hat{\mathbf{y}}) &= - \sum_{j=1}^q y_j \log \frac{\exp(o_j)}{\sum_{k=1}^q \exp(o_k)} \\ &= \sum_{j=1}^q y_j \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j\\ &= \log \sum_{k=1}^q \exp(o_k) - \sum_{j=1}^q y_j o_j. \end{aligned} $$

```
def cross_entropy(y_hat, y):
    return - torch.log(y_hat.gather(1, y.view(-1, 1)))


def accuracy(y_hat, y):
    return (y_hat.argmax(dim=1) == y).float().mean().item()

```

### Softmax - 模型更新参数


### Softmax - 模型画图

## 非线性模型
### MLP
### MLP - 模型公式


### MLP - 模型目标


### MLP - 损失函数


### MLP - 模型更新参数


### MLP - 模型画图



## 树模型
### 决策树
1. 分类树分析是当预计结果可能为离散类型（例如三个种类的花，输赢等）使用的概念
2. 回归树分析是当局域结果可能为实数（例如房价，患者住院时间等）使用的概念
3. CART分析是结合了上述二者的一个概念。CART是Classification And Regression Trees的缩写.
4. CHAID（Chi-Square Automatic Interaction Detector）
5. 损失函数
   1. 统计学习方法理解：https://ifwind.github.io/2021/12/25/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94%E7%AC%AC5%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91/
   2. 理解：https://blog.csdn.net/weixin_45834080/article/details/103040439
6. 源码实现
   1. https://www.cnblogs.com/haohai9309/p/17912188.html
   2. 

### 决策树 - 探究根本
1. 历史
   1. Hunt等人于1966年提出
   2. Hunt算法是许多决策树算法的基础
   3. ID3 C4.5 CART
2. 思想
   1. 决策树算法是一种有监督学习算法，利用分类的思想，根据数据的特征构建数学模型，从而达到数据的筛选，决策的目标
3. 构建
   1. 特征选择：选取有较强分类能力的特征
   2. 决策树生成：典型的算法有 ID3 和 C4.5， 它们生成决策树过程相似， ID3 是采用信息增益作为特征选择度量， 而 C4.5 采用信息增益比率。
   3. 决策树剪枝：剪枝原因是决策树生成算法生成的树对训练数据的预测很准确， 但是对于未知数据分类很差， 这就产生了过拟合的现象。涉及算法有CART算法。
4. 划分原理
   1. 熵：物理意义是体系混乱程度的度量。
   2. 信息熵：表示事物不确定性的度量标准，可以根据数学中的概率计算，出现的概率就大，出现的机会就多，不确定性就小（信息熵小）
   3. 基尼指数
5. 融合技术
   1. aggregation tyep 聚合方法
      1. 平均 
      2. 最大
      3. 最小
      4. 加权平均
      5. 条件聚合
   2. blending
      1. uniformly 权值均为1 voting averaging
      2. non-uniform 不同权值 linearly
      3. conditional  stacking
   3. learning
      1. uniformly - bagging bootstrapping制备样本
      2. non-uniform - adaptive boosting
      3. conditional - decisionTree 
6. 样本技术
   1. bootstrapping 统计学的一个工具，思想就是从已有数据集D中模拟出其他类似的样本newD

### 决策树 - 模型公式


### 决策树 - 模型目标


### 决策树 - 损失函数


### 决策树 - 模型更新参数


### 决策树 - 模型画图


### RF(Random Forest)

### RF - 模型公式


### RF - 模型目标


### RF - 损失函数


### RF - 模型更新参数


### RF - 模型画图



### GBDT(traditional Gradient Boosting Decision Tree)

### GBDT - 模型公式


### GBDT - 模型目标


### GBDT - 损失函数


### GBDT - 模型更新参数


### GBDT - 模型画图







### lightgbm
1. parameters：https://lightgbm.readthedocs.io/en/stable/Parameters.html
2. application：https://lightgbm.readthedocs.io/en/stable/Features.html
   1. regression, the objective function is L2 loss
   2. binary classification, the objective function is logloss
   3. multi classification
   4. cross-entropy, the objective function is logloss and supports training on non-binary labels
   5. LambdaRank, the objective function is LambdaRank with NDCG

### xgboost
1. Introduction to Boosted Trees：https://xgboost.readthedocs.io/en/stable/tutorials/model.html



### dart(Dropouts meet Multiple Additive Regression Trees)




## 评估指标

### mse - mean_squared_error
1. parameters：https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.mean_squared_error.html
2. source code：https://gist.github.com/cookieblues/9030aa56732241fd10acdf7cc0c5ba6d

### mse - code
```

numpy version
mse = (np.square(A - B)).mean(axis=ax)
or 
mse = ((A - B)**2).mean(axis=ax)

```

### mse - math

$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$

其中：
- \( n \) 是样本数量。
- \( y_i \) 是第 \( i \) 个样本的真实值。
- \( \hat{y}_i \) 是第 \( i \) 个样本的预测值。

### mse - gradient 梯度
1. https://blog.csdn.net/hei653779919/article/details/104167070




### rmse - root mean squared error
1. description：https://docs.oracle.com/en/cloud/saas/planning-budgeting-cloud/pfusu/insights_metrics_RMSE.html

### rmse - code
```
def rmse(y_true, y_pred):
  return np.sqrt(np.mean((y_true - y_pred)**2))
```

### rmse - math
formula

$RMSE = \sqrt{\sum_{i=1}^{n}\frac{(\hat{y_i} - y_i)^2}{n}}$


### rmse - gradient 




## 微积分
1. https://github.com/d2l-ai/d2l-en/blob/master/chapter_preliminaries/calculus.md?plain=1
2. 问题
   1. 梯度怎么算，损失函数怎么推导出来的
3. Calculating Gradient Descent Manually：https://towardsdatascience.com/calculating-gradient-descent-manually-6d9bee09aa0b
4. 深度学习中的梯度计算与反向传播推导（一）DNN中单样本反向传播推导：https://blog.csdn.net/qq_42734797/article/details/109539100
5. 【转载】梯度下降法的推导（非常详细、易懂的推导）：https://blog.csdn.net/byn12345/article/details/101081537


### 对数运算法则


### 极限
$f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h) - f(x)}{h}$
1. f在x处，可微分

### 偏导数


### 矩阵求导和求偏导


### 梯度
1. 梯度结果含义
2. 应用适当的损失函数，根据模型参数最小化损失




### 链式法则




### 自动微分


### 仿射函数 affine function

### 损失函数 loss function
1. https://www.datarobot.com/blog/introduction-to-loss-functions/


## 概率
1. 如何将输出转换为有效的概率分布


### 抽样
1. 从概率分布中抽取样本的过程


### 分布
1. 分布（distribution）看作对事件的概率分配
2. 将概率分配给一些离散选择的分布称为多项分布（multinomial distribution）


### 随机变量


### 高斯分布

### gamma分布

### 梯度下降法

### 最小二乘法


## 信息论 information theory 
### 熵


## 深度学习 - 网络层

### BN层
1. Batch Normalization导读 - 张俊林的文章 - 知乎 https://zhuanlan.zhihu.com/p/38176412
2. 深度学习中的Normalization模型 - 张俊林的文章 - 知乎 https://zhuanlan.zhihu.com/p/43200897


## 哲学
### feature transform 和 regularization
1. feature transform 和 regularization是对立的，还把它们分别比作踩油门和踩刹车
2. aggregation却能将feature transform和regularization各自的优势结合起来，好比把油门和刹车都控制得很好，从而得到不错的预测模型

### log运算法则能简化运算，所以经常用于各种算法优化中

### 正负样本的优化 - 是放大错误样本，缩小正确样本

## xxx

### xxx - 模型公式


### xxx - 模型目标


### xxx - 损失函数


### xxx - 模型更新参数


### xxx - 模型画图
