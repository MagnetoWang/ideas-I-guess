## 机器学习算法

## 目录参考
1. 理解时间
2. 背景介绍
3. 参考资料
4. 核心思考问题
5. 入门概念
6. 阅读笔记
7. 项目工作流
8. 技术流图和图解
9.  源码目录
10. 模块拆解-横向
11. 模块拆解-纵向
12. 性能总结
13. 设计总结
14. 经验总结
15. 第三方依赖
16. 应用场景
17. 业务通点
18. 行业实践
19. case代码


### 理解时间
```
2024年10月10号启动

永远带着问题/需求/目标/兴趣/收益看代码

源码理解角度
   高层次流图分析 - 更好把握主次
    比如大数据框架 考虑流式计算范式
    比如机器学习框架 考虑数学计算流图
    共性分析数据格式 存储 读写 和 网络流图
    业务使用流程图和场景图
   横向梳理所有模块
   纵向梳理某个功能点
   编译角度
   使用角度
   性能角度
   底层数据结构角度

完整理解机器学习算法项目
如果只是在搜索引擎 搜 机器学习算法是远远不够的
机器学习算法 + 架构图

机器学习算法 + 概念关键词

机器学习算法 + 问题排查

机器学习算法 + 面试汇总

机器学习算法 + 极客挑战赛

机器学习算法 + 论坛会议

机器学习算法 + 论文

机器学习算法 + 前沿分享

机器学习算法 + 场景应用

机器学习算法 + 机器学习算法大佬名字

机器学习算法 + 公司项目
等等才能完全熟悉机器学习算法


```

## 参考资料
1. 基础算法实现：https://github.com/MLEveryday/practicalAI-cn?tab=readme-ov-file
2. 传统模型讲解：https://www.zhihu.com/column/easymachinelearning
3. numpy手写度量：https://zhuanlan.zhihu.com/p/130318593
4. numpy-ml：https://github.com/ddbourgin/numpy-ml

## 核心
1. 吐槽
   1. 网上一搜kaggle普遍是泰坦尼克号教程，根本没有进阶的材料
   2. 高质量内容还是得持续做，坚持做

## 常见模型原理

### Transformer
```
如何最简单、通俗地理解Transformer？ - 鱼先生的回答 - 知乎
https://www.zhihu.com/question/445556653/answer/2882383919
Transformer 之逐层介绍 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604450283
Transformer 之多头注意力 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604452790
Transformer 之注意力计算原理 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604454823


【【精校珍藏版】大牛Andrej Karpathy的stanford深度学习课程：深入理解Transformer，从零打造最简版GPT】 https://www.bilibili.com/video/BV1Tm4y1b7UP/?share_source=copy_web&vd_source=8783d6f7758784f093c06edba717af3d


源码实现（有能力自己看）
http://nlp.seas.harvard.edu/annotated-transformer/
https://wmathor.com/index.php/archives/1455/
https://github.com/BoXiaolei/MyTransformer_pytorch
nlp模型算法实现：https://github.com/graykode/nlp-tutorial


源码讲解
https://wmathor.com/index.php/archives/1438/

```


#### 整体思路
1. Key
2. Query
3. Value
4. QKV计算公式，如何初始化，最终达到注意力的效果

#### LSTM RNN 对比
1. 没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系
2. 位置嵌入的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成
3. 

#### 注意力机制
1. Embedding Size
2. Query
3. number of Attention heads
4. batch_size
思路灵感
1. Neural machine translation by jointly learning to align and translate
2. Massive exploration of neural machine translation architectures


#### layer-normal
```
思路灵感
Layer normalization

```
#### position encoding
```
思路灵感
Convolutional sequence to sequence learning



```

#### position-wise feedward networks
1. 

#### 网络结构优化
思路灵感
1. Rethinking the inception architecture for computer vision
2.  Dropout: a simple way to prevent neural networks from overfitting
3.  Deep residual learning for image recognition

### Bert
```

```

### resnet
```

```



### ernie-m 网络结构
```
NetWork(
  (ernie): ErnieMModel(
    (embeddings): ErnieMEmbeddings(
      (word_embeddings): Embedding(250002, 768, sparse=False)
      (position_embeddings): Embedding(514, 768, sparse=False)
      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (encoder): TransformerEncoder(
      (layers): LayerList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (6): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (7): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (8): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (9): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (10): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (11): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
    (pooler): ErnieMPooler(
      (dense): Linear(in_features=768, out_features=768, dtype=float32)
      (activation): Tanh()
    )
  )
  (resnet): EncoderCNN(
    (resnet): Sequential(
      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)
      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
      (2): ReLU()
      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)
      (4): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (5): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (6): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (4): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (5): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (6): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (7): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (8): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (9): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (10): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (11): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (12): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (13): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (14): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (15): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (16): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (17): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (18): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (19): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (20): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (21): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (22): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (7): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
    )
    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))
  )
  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)
  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)
  (attention_text): MultiHeadAttention(
    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
  )
  (attention_image): MultiHeadAttention(
    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
  )
)
```



### DSSM双塔模型
```
DSSM双塔模型及pytorch实现 - 简之的文章 - 知乎
https://zhuanlan.zhihu.com/p/402123341

https://github.com/MemoryForSky/deepctr

https://github.com/HeartFu/DSSM.git

```
 
### wide & deep & XDeepFM 
1. wide
   1. 特征构造
   2. 特征交叉
   3. FTRL优化器（特征稀疏）
2. depp
   1. embedding层
   2. nn层
   3. AdaGrad优化器

### FM & FFM & DeepFM & DeepFFM
```





```

### DCN & DCNv2


