## 框架安装
```
初学者建议统一安装cpu版本

安装pytorch
http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/#21-%E5%AE%89%E8%A3%85-pytorch

pip3 install torch torchvision -i https://pypi.mirrors.ustc.edu.cn/simple # 用国内源
pip3 install graphviz -i https://pypi.mirrors.ustc.edu.cn/simple


安装paddlepaddle全家桶
pip3 install paddlepaddle==2.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple    
pip3 install paddleocr
```

### 前置安装
```bash
apt install python3.9
apt install python3-pip
# openGL库
apt-get install libgl1-mesa-glx


```

### transformers 安装
```bash
安装rust
curl https://sh.rustup.rs -sSf | sh
# rust生效
source "$HOME/.cargo/env"

pip3 install setuptools_rust
pip3 install transformers

```

### juypter 安装
```
pip install --upgrade pip
pip3 install --upgrade pip
pip3 install --upgrade pip3

pip3 install setuptools_scm
pip3 install argon2-cffi-bindings
pip3 install jupyter

```

### 镜像安装
```
阿里云
https://cr.console.aliyun.com/cn-shanghai/instances/artifact

cpu
docker pull dsw-registry.cn-hangzhou.cr.aliyuncs.com/pai/pytorch:1.8-cpu-py36-ubuntu18.04

gpu
dsw-registry.cn-hangzhou.cr.aliyuncs.com/pai/pytorch:1.8PAI-gpu-py36-cu101-ubuntu18.04

sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 100 --slave /usr/bin/g++ g++ /usr/bin/g++-9


```

## 工具向
### 翻译工具
```
训练Transformer 模型将 中文翻译成英语：https://zhuanlan.zhihu.com/p/469388563

```

## 数据处理
```
paddle：https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html



```





## Embedding
### 介绍
```
向量检索引擎：https://zhuanlan.zhihu.com/p/364923722
IndexFlatL2（基于欧氏距离的暴力索引）
IndexIVFFlat（加聚类的倒排索引，支持欧式距离和向量内积两种距离算法）
IndexIVFPQ（加聚类、加量化的倒排索引）

开源项目
facebook：https://github.com/facebookresearch/faiss
阿里：https://github.com/alibaba/proxima

手把手搭建一个语义检索系统：https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search



```
### 模型和工业实践
```


```
### 标签 转 embedding
```


```

### 数值 转 embedding
```


```
### 文字 转 embedding
```


```
### 数学公式 转 embedding
```


```
### pdf 转 embedding
```
pdf文本加载
https://zhuanlan.zhihu.com/p/644938147

paddleOCR解析文本：https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart.md



安装ocr工具
yum install mupdf-devel


paddleocr --image_dir=/home/aistudio/data/pdf/IETS13_A.pdf --type=structure --recovery=true --use_pdf2docx_api=true

paddleocr --image_dir=/home/aistudio/data/pdf/IETS13_A.pdf --type=structure --recovery=true --lang='en'

paddleocr --image_dir=/home/aistudio/data/pdf/MOBIUS\ Towards\ the\ Next\ Generation\ of\ Query-Ad\ Matching\ in\ Baidu\ Sponsored\ Search.pdf --type=structure --recovery=true --lang='en'



```
### 图片 转 embedding
```


```
### 语音 转 embedding
```


```

### 语音
```bash
https://aistudio.baidu.com/aistudio/projectdetail/4353348?sUid=2470186&shared=1&ts=1660878142250

# 前置依赖
apt-get install libsndfile1 -y
apt-get install ffmpeg -y

# 新增speech环境
git clone https://gitee.com/mirrors/pyenv.git ~/.pyenv
export PYTHON_BUILD_MIRROR_URL="https://npm.taobao.org/mirrors/python/"
export HOME=~
export PYENV_ROOT="$HOME/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"

pyenv virtualenv 3.8.10 speech 
pyenv activate speech
source speech/bin/activate
pip3 install paddlepaddle==2.4.2
pip3 install paddlespeech
pip3 install paddlespeech_ctcdecoders
# mp3 to wav 格式
pip3 install pydub

# 退出
pyenv deactivate


paddlespeech asr --lang zh --input /docker/root/projects/demo/data/mp4/剑4真题听力/test1/test1_section1.wav


```

## GPT
### 制作一个BadyGpt
```
参考文档：http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/#21-%E5%AE%89%E8%A3%85-pytorch

langchain方式
https://github.com/chatchat-space/langchain-ChatGLM

```

### chatGLM
```
https://github.com/RonaldJEN/FinanceChatGLM.git



比赛
官网论坛：https://tianchi.aliyun.com/competition/entrance/532126/forum
全训练过程：https://tianchi.aliyun.com/forum/post/573555
数据集：https://modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset/summary?spm=a2c22.21852664.0.0.68171434jkTm0x
baseline代码：https://github.com/RonaldJEN/FinanceChatGLM/
参赛笔记：https://tianchi.aliyun.com/forum/post/571708
基于paddlepaddle的chatglm推理实现代码：https://tianchi.aliyun.com/forum/post/572601

微调模型：https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning
paddle结合GLM：https://aistudio.baidu.com/aistudio/projectdetail/6195067
动手搭建一套端到端文本语义检索系统：https://aistudio.baidu.com/projectdetail/3351784

思路 
gpt生成关键词 prompt 区分文本分析 数学计算
先测试分类效果 
请将下述问题区分为搜索信息类，计算数值类，总结陈述类

关键词语义搜索找到相关pdf paddle语义召回
5000行构建花了10分钟 cpu

pdf识别语义



解析pdf逻辑参考
Traceback (most recent call last):
  File "paddle_model.py", line 16, in <module>
    pprint(docprompt([{"doc": pdf_path, "prompt": ["财报利润率多少",  "住宅投资是多少?"]}]))
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/taskflow.py", line 850, in __call__
    results = self.task_instance(inputs)
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/task.py", line 515, in __call__
    inputs = self._preprocess(*args)
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/document_intelligence.py", line 90, in _preprocess
    ocr_result = self._ocr.ocr(example["doc"], cls=True)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py", line 637, in ocr
    img = check_img(img)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py", line 527, in check_img
    img, flag_gif, flag_pdf = check_and_read(image_file)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/ppocr/utils/utility.py", line 96, in check_and_read
    for pg in range(0, pdf.pageCount):


下载模型和数据集
参考链接：https://tianchi.aliyun.com/forum/post/573555
pip3 install datasets==2.13.0
pip3 install dill==0.3.6
pip3 install multiprocess==0.70.14
pip3 install numpy pandas urllib3
pip3 install torch
pip3 install transformers -U
pip3 install accelerate -U
pip3 install sentencepiece -U
pip3 install torch torchvision -U
pip3 install modelscope -U 

打包当前环境
pip3 freeze > requirements.txt

数据集
git clone http://www.modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset.git

异常
RuntimeError: "addmm_impl_cpu_" not implemented for 'Half'
原因
机器没有gpu，需要配置只跑cpu。加参数 trust_remote_code=True
model = Model.from_pretrained('ZhipuAI/chatglm2-6b', low_cpu_mem_usage=False, trust_remote_code=True, revision='v1.0.7')



export PYTHONPATH=$PYTHONPATH:/docker/root/projects/demo/project/chatglm/baseline_demo/FinanceChatGLM

总结
大模型现阶段一些问题和优势
问题：
模型需要的资源太多了，响应慢，开发慢。这些都是成本
模型对数据质量要求很高，不然基本不可用
输出结果不可控
不适合做大数据计算
不适合做搜索引擎

优势
在提供足量的正确的数据，能融合数据，并生成可看的结果

大模型 + 向量 + 搜索 + 大数据
数据存储成本
索引构建成本
向量生成成本
大模型运行成本
每一个成本都很高
而且pipeline很长
数据同步延迟高，排查问题慢，同时依赖没有简化现有的软件开发模式，反而新增一个链路

我理想中认为的大模型
存储所有的大数据内容，完成端到端的数据链路更新

实际中，因为大模型的成本问题
大模型应该需要具备推理和分析能力，来代替人，生成sql，生成代码。然后提交执行命令
完成一系列自动化机器运维，软件开发，bug修复等操作
这样就能带来明显的价值效益


```

### AI小镇
```
https://github.com/joonspk-research/generative_agents

```

## huggingface
### SkyTextTiny 模型
```
git clone https://huggingface.co/SkyWork/SkyTextTiny.git    


```
## 业务向
### Readlist

6. 
### 智能文档信息提取
```
https://www.paddlepaddle.org.cn/support/news?action=detail&id=3174

DocVQA榜单
https://rrc.cvc.uab.es/?ch=17&com=evaluation&task=1 

百度AI开放平台——智能文档分析平台
https://ai.baidu.com/tech/nlp/Textanalysis

在线调试
https://console.bce.baidu.com/tools/#/api?product=AI&project=%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB&parent=%E9%89%B4%E6%9D%83%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6&api=oauth%2F2.0%2Ftoken&method=post


开源了！文心大模型ERNIE-Tiny轻量化技术，又准又快，效果全开 - 飞桨PaddlePaddle的文章 - 知乎
https://zhuanlan.zhihu.com/p/535541528

【快速上手ERNIE 3.0】机器阅读理解实战 - 快速实现AI想法的文章 - 知乎
https://zhuanlan.zhihu.com/p/536541088


```
1. 信息抽取方法综述：https://zhuanlan.zhihu.com/p/376898772
2. 




### 2023IKCEST第五届一带一路国际大数据竞赛
#### todolist
1. 提供resnet模型效果
2. bert ernie模型训练加载器
3. LinearDecayWithWarmup 学习率调度器类，它根据线性递减策略计算学习率。在训练过程中
4. LinearWarmup
5. 交叉熵损失
6. 评估的时候采用准确率指标
7. Optimizer
   1. Momentum
   2. adam
8. 模型断点训练
9.  paddle
   1. vision
   2. paddle.concat
   3. paddle.stack
   4. paddle.reshape
   5. 

#### 优化目标
```
文本识别
图形识别
向量concat

预测分类

我的想法
文本识别的特征如何 和 图像识别的特征保持一致呢

数据增广 丰富训练集，加强训练
https://ai.baidu.com/ai-doc/ERNIE-Ultimate/Pl6egw3pu


可使用工具
PaddleDetection

分词工具与词表生成工具
数据增强
交叉验证
网格搜索
编码及转换工具
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tools



问题拆解
文本分类
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/text_classification

文本匹配
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/text_matching


序列标注
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/sequence_labeling


信息抽取
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/information_extraction_many_to_many

文本生成
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/text_generation

数据蒸馏
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/data_distillation
Distilling Task-Specific Knowledge from BERT into
Simple Neural Networks：https://arxiv.org/pdf/1903.12136.pdf

指标评估
https://ai.baidu.com/ai-doc/ERNIE-Ultimate/nkmlroqy2

多模态
自回归网络

自编码网络

Token-Drop
https://arxiv.org/pdf/2106.14448v1.pdf

paddlenlp工具


paddlecv



```
#### 数据集介绍
```
标签说明
0	1	2
non-rumor	rumor	unverified


img文件夹下存放每一条声明的图片

img_html_news文件夹下存放根据每一条声明的caption检索到的网页与图片，其中direct_annotation.json包含如下信息：

{
      "img_link": 检索到的相关图片的链接,
      "page_link": 检索到的网页链接,
      "domain": 检索到的网页的域名,
      "snippet": 检索到的网页的简洁摘要,
      "image_path": 检索到的图片的路径,
      "html_path": 检索到的网页的路径,
      "page_title": 检索到的网页标题
}
inverse_search文件夹下存放根据声明的图片找到的网页，其中inverse_annotation.json包含如下信息

{
"entities": 声明中图片中的实体, 
"entities_scores": 声明中图片中的实体的分数, 
"best_guess_lbl": 声明中图片最可能是什么, 
"all_fully_matched_captions": , 
"all_partially_matched_captions":  
"fully_matched_no_text": 
上述三个字段的值均为寻找到的网页，为一个列表，列表中的元素为一个字典，格式如下
	{
	"page_link": 检索到的网页链接, 
	"image_link": 检索到的图片链接, 
	"html_path": 检索到的网页的路径, 
	"title": 检索到的网页的标题
	}
}








```
建模
1. 问题分析
   1. 输入 陈述句
   2. 输出 判断真假消息或不确定
2. 问题拆解
   1. 定义 真消息
      1. 
   2. 定义 假消息
   3. 定义 不确定消息


模型库
1. DUMA 给定一段上下文Passage, 问题Question, 选项Answer Options，选出最合适的答案。
2. roberta 文本向量化
3. RoBERTa-wwm-large
4. ernie模型历史迭代
   1. https://ai.baidu.com/ai-doc/ERNIE-Ultimate/5kye50810
5. 跨模态检索
   1. https://ai.baidu.com/ai-doc/ERNIE-Ultimate/ukxk3hkzc
6. 跨模态信息抽取
   1. https://ai.baidu.com/ai-doc/ERNIE-Ultimate/nkwnlv73o
7. 模型库评测
   1. nlp：https://github.com/CLUEbenchmark/CLUE
8. 工程
   1. ERNIEKit：https://ai.baidu.com/ai-doc/ERNIE-Ultimate/rkmlroren  
   2. paddleNLP
      1. task api：https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples


论文库
1. 训练
   1. 基于 In-batch negatives 策略训练：https://arxiv.org/abs/2004.04906
   2. 基于 HardestNeg 策略训练

文本数据处理
1. 计算下最长句子的长度
2. 生成向量方案
   1. roberta 模型
3. 文本特征方案
   1. ernie-m
   2. bert

图形数据处理
1. resnet

#### 训练速度
```
杀死进程
ps -ef|grep multi_gpu.py | awk '{print $2}' |  xargs kill -9

多卡和单卡情况差不多
global step 100, epoch: 1, batch: 100, loss: 0.94645, accu: 0.41750, speed: 0.09 step/s
global step 200, epoch: 1, batch: 200, loss: 1.37231, accu: 0.43625, speed: 0.09 step/s
global step 300, epoch: 1, batch: 300, loss: 1.22456, accu: 0.45083, speed: 0.10 step/s
global step 400, epoch: 1, batch: 400, loss: 1.50505, accu: 0.47937, speed: 0.10 step/s
global step 500, epoch: 1, batch: 500, loss: 0.68333, accu: 0.50050, speed: 0.10 step/s

单卡会出现内存溢出，训练失败的情况

```

#### 模型训练优化经验
```
如何优化你的模型 - 错乱空时的文章 - 知乎
https://zhuanlan.zhihu.com/p/360647927

NLP中文预训练模型泛化能力挑战赛
https://tianchi.aliyun.com/competition/entrance/531841/forum

2021语言与智能技术竞赛：多形态信息抽取任务
https://aistudio.baidu.com/competition/detail/65/0/introduction

二等奖方案|产品评论观点提取赛题
https://discussion.datafountain.cn/articles/detail/3764

推荐 nlp cv大模型参数量总结
https://zhuanlan.zhihu.com/p/529863941

竞赛达人的竞赛之旅
https://zhuanlan.zhihu.com/p/375688838

数据
数据预处理
数据增广
外部数据
模型
大力出奇迹
模型结构
loss
label Smooting
优化方法
学习率
对抗训练
EMA，SWA
正则化
word mixup
dropout
early stop
后处理
阈值优化
其他
未起效方法
训练技巧
自知识蒸馏


```
### GPT解决数学建模问题
```


```

## 竞赛方案复现
```
关键词搜索
名方案

竞赛达人竞赛之旅
https://zhuanlan.zhihu.com/p/375688838


“公益AI之星”挑战赛-新冠疫情相似句对判定大赛
https://tianchi.aliyun.com/competition/entrance/231776/forum
第一名
https://tianchi.aliyun.com/notebook/101624

NLP中文预训练模型泛化能力挑战赛
https://tianchi.aliyun.com/competition/entrance/531841/forum

2021语言与智能技术竞赛：多形态信息抽取任务
https://aistudio.baidu.com/competition/detail/65/0/introduction

二等奖方案|产品评论观点提取赛题
https://discussion.datafountain.cn/articles/detail/3764

表格检测
https://aistudio.baidu.com/competition/detail/702/0/submit-result
https://aistudio.baidu.com/competition/detail/704/0/introduction

第二名方案
https://aistudio.baidu.com/projectdetail/5398861?channelType=0&channel=0


百度网盘AI大赛——图像处理挑战赛：文档图像摩尔纹消除第1名方案
https://aistudio.baidu.com/projectdetail/3462083?channelType=0&channel=0


百度网盘文档图像超分比赛-Serendipity团队-AB榜第二方案 metaRLFN网络
https://aistudio.baidu.com/projectdetail/5133608?channelType=0&channel=0


第五届“中国法研杯”司法人工智能挑战赛
https://aistudio.baidu.com/competition/detail/664/0/submit-result

中国人工智能大赛·语言与知识技术竞赛（个人赛）冠军方案分享
https://aistudio.baidu.com/projectdetail/755387?channelType=0&channel=0

WSDM Cup 2023: Pre-training for Web Search Demo Code
https://aistudio.baidu.com/projectdetail/4844225?channelType=0&channel=0

【飞桨学习赛：百度搜索首届技术创新挑战赛：赛道一】第5名方案
https://aistudio.baidu.com/projectdetail/4950227?channelType=0&channel=0


百度搜索首届技术创新挑战赛赛道二Baseline
https://aistudio.baidu.com/projectdetail/5007642?channelType=0&channel=0


“飞桨杯”重庆市首届人工智能创新大赛-社交网络大数据谣言核查官方baseline
https://aistudio.baidu.com/projectdetail/4913037?channelType=0&channel=0

2022 IKCEST第四届“一带一路”国际大数据竞赛：“一带一路”重点语种-法俄泰阿与中文互译
https://aistudio.baidu.com/competition/detail/477/0/introduction

2022 CCF BDCI 基于文心NLP大模型的阅读理解可解释评测
https://aistudio.baidu.com/competition/detail/394/0/introduction
第五名
https://aistudio.baidu.com/projectdetail/5016503?channelType=0&channel=0


CCKS2022基于知识图谱的优质文章识别
https://aistudio.baidu.com/competition/detail/255/0/introduction


2022 CCF BDCI 基于文心CV大模型的智慧城市视觉多任务识别
https://aistudio.baidu.com/competition/detail/455/0/introduction
第一名
https://aistudio.baidu.com/projectdetail/5035322?channelType=0&channel=0


AIWIN 世界人工智能创新大赛：中文保险小样本多任务竞赛
https://aistudio.baidu.com/competition/detail/218/0/introduction

AIWIN 世界人工智能创新大赛：发债主体违约风险预测竞赛
https://aistudio.baidu.com/competition/detail/222/0/introduction

2021“智荟杯”浦发百度高校极客挑战赛
https://aistudio.baidu.com/competition/detail/123/0/task-definition

【Paddle打比赛】基于PaddleNLP法研杯2022 -犯罪事实实体识别
https://aistudio.baidu.com/projectdetail/4821353?channelType=0&channel=0

2021中国软件杯——新闻智分系统
https://aistudio.baidu.com/projectdetail/1981601?channelType=0&channel=0


2022 CCF BDCI 模心智创-文心大模型智能创意赛
https://aistudio.baidu.com/competition/detail/397/0/introduction



文本智能校对大赛
https://aistudio.baidu.com/competition/detail/404/0/introduction

航旅纵横-领域知识问答测评
https://aistudio.baidu.com/competition/detail/313/0/introduction

飞桨论文复现挑战赛（第六期）
https://aistudio.baidu.com/competition/detail/205/0/introduction

飞桨论文复现挑战赛（第七期）
https://aistudio.baidu.com/competition/detail/406/0/task-definition

2022世界人工智能大会黑客马拉松：百度飞桨论文复现赛
https://aistudio.baidu.com/competition/detail/430/0/introduction

2022世界人工智能大会黑客马拉松：百度飞桨黑客马拉松
https://aistudio.baidu.com/competition/detail/428/0/introduction

兴智杯 全国人工智能创新应用大赛：百度飞桨论文复现赛
https://aistudio.baidu.com/competition/detail/439/0/introduction

“兴智杯”全国人工智能创新应用大赛：深度学习模型可解释性赛
https://aistudio.baidu.com/competition/detail/472/0/introduction



```
### Kaggle汇总
```
前端搜索：https://github.com/faridrashidi/kaggle-solutions

```
### Kaggle - mercari-price-suggestion-challenge
```
比赛链接：https://www.kaggle.com/c/mercari-price-suggestion-challenge

解决方案：https://www.leiphone.com/category/yanxishe/HGSuMdM6c4U6jWLi.html

代码：https://github.com/pjankiewicz/mercari-solution

```

### Kaggle - Predict Future Sales
```
比赛链接：https://www.kaggle.com/competitions/competitive-data-science-predict-future-sales/data

代码：https://www.kaggle.com/code/zhangyunsheng/xgboost/notebook

```



## 基础
### Transformer
```

```
#### layer-normal
```

```
#### position
```

```

### Bert
```

```

### resnet
```

```



### ernie-m 网络结构
```
NetWork(
  (ernie): ErnieMModel(
    (embeddings): ErnieMEmbeddings(
      (word_embeddings): Embedding(250002, 768, sparse=False)
      (position_embeddings): Embedding(514, 768, sparse=False)
      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (encoder): TransformerEncoder(
      (layers): LayerList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (6): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (7): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (8): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (9): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (10): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (11): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
    (pooler): ErnieMPooler(
      (dense): Linear(in_features=768, out_features=768, dtype=float32)
      (activation): Tanh()
    )
  )
  (resnet): EncoderCNN(
    (resnet): Sequential(
      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)
      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
      (2): ReLU()
      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)
      (4): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (5): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (6): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (4): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (5): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (6): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (7): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (8): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (9): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (10): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (11): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (12): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (13): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (14): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (15): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (16): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (17): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (18): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (19): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (20): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (21): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (22): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (7): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
    )
    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))
  )
  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)
  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)
  (attention_text): MultiHeadAttention(
    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
  )
  (attention_image): MultiHeadAttention(
    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
  )
)
```

### NLP 技术图谱

1. 自监督词表示学习
   1. 词向量模型(Word2Vec)
   2. 语言模型(Language Modeling, LM)
2. 句子编码网络
   1. 自回归 n-gram语言模型
   2. 循环神经网络(Recurrent Neural Network, RNN)
   3. 注意力机制 Transformer
3. 自回归、自编码预训练模型
   1. GPT(自回归)
      1. 无马尔科夫链
      2. self-attention
      3. 大规模自监督学习
   2. BERT 自编码
      1. cbow
      2. 利用上下文预测中间词
      3. 作为encoder 能看到整个句子的信号
4. 任务类型
   1. classification
   2. entailment
   3. similary
   4. multiple choice
5. 语言任务
   1. 字理解
   2. 词理解
   3. 句子理解
   4. 篇章理解
   5. 多义 同义 歧义
   6. 语境
   7. 语义理解
      1. 双向语言模型建模 建模上下文信息
      2. 两层lstm 建模不同层次语义信息 （单词特征 句法特征 语义特征）
   8. 单句分类
   9. 句对分类 自然语言推断
   10. 文本匹配
       1.  query - document
       2.  question - answer
       3.  utterance - response
   11. 命名实体识别
   12. 事件关系抽取
   13. 机器阅读理解
6. ELMo
   1. pre-training
      1. 双向语言模型建模 建模上下文信息
      2. 两层lstm 建模不同层次语义信息 （单词特征 句法特征 语义特征）
   2. fine-tuning
      1. 基于feature-based方式
   3. 问题
      1. 不完全双向训练
      2. 任务相关网络结构设计
      3. 仅有词向量，无句向量
7. GPT
   1. pre-training
      1. transform decoder
      2. bookscorpus
   2. fine-tuning
      1. 基于model-based方式
8. Bert
   1. pre-training
      1. LM -> Auto-encoder
      2. sentence-level
   2. fine-tuning
      1. add token-level
      2. add sentence-level
   3. 单句分类
   4. 句对分类
   5. 序列标注任务
9. ernie
   1.  ernie-vil
   2.  unimo
   3.  -M
   4.  -Doc
10. 语言
    1.  语序
    2.  语义：关联，非关联，同话题
    3.  逻辑关系
11. 信息抽取
    1.  实体
    2.  关系
    3.  事件
    4.  方法
        1.  抽取解析式
        2.  理解生成式
12. 问答系统
    1.  文本
    2.  知识库
    3.  表格
    4.  视频
    5.  方法
        1.  稀疏向量
        2.  稠密向量
13. 数学工具
   1. 前向传播
   2. 反向传播
   3. 损失函数
   4. 负梯度反向传播
14. 
15. 网络层
   1. embedding
   2. 

模型
1. 2013
   1. cbow skip-gram glove
2. 2014
   1. cnn rnn lstm seq-to-seq
3. 2015
   1. transformer
4. 2018
   1. elmo gpt bert

论文
1. 基础论文
   1. Efficient Estimation of Word Representations in Vector Space.
   2. RNN
   3. self-attention
   4. elmo
   5. gpt
   6. bert
   7. ernie
   8.  A continual pre-training framework for language understanding
2.  问答系统论文
    1.  Reading Wikipedia to Answer Open-domain Questions
    2.  Questions for Machine Comprehension of Text
    3.  DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications
    4.  Dense Passage Retrieval for Open-Domain Question Answering.

### Kaggle - Corporacion Favorita Grocery Sales Forecasting
```
比赛地址：

https://www.kaggle.com/c/favorita-grocery-sales-forecasting

论文地址：

https://arxiv.org/pdf/1803.04037.pdf

方案：https://cloud.tencent.com/developer/article/1166628
代码：https://www.kaggle.com/code/shixw125/1st-place-lgb-model-public-0-506-private-0-511/script
```

### 
```
数据科学竞赛2019：https://mp.weixin.qq.com/s?__biz=Mzk0NDE5Nzg1Ng==&mid=2247490157&idx=1&sn=674461f9cbb0e60bf23994576b67c5d8&source=41#wechat_redirect

【乘用车细分市场销量预测】

赛事方向：预测回归、数据挖掘

赛事简介：本赛题需要参赛队伍根据给出的60款车型在22个细分市场（省份）的销量连续24个月（从2016年1月至2018年12月）的销量数据，建立销量预测模型；基于该模型预测同一款车型和相同细分市场在接下来一个季度连续4个月份的销量；除销量数据外，还提供同时期的用户互联网行为统计数据，包括：各细分市场每个车型名称的互联网搜索量数据；主流汽车垂直媒体用户活跃数据等。参赛队伍可同时使用这些非销量数据用于建模。除了模型的准确性外，参赛队伍需对本赛题任务有系统性的思考和设计，在决赛阶段，参赛队伍对于所提交的模型的适应性、可扩展性、代码的工程性等方面也会影响参赛队伍的最终名次。

方案分享：

https://mp.weixin.qq.com/s/-tT9BKrANTwJK9-N1K4j9g



【消费者人群画像—信用智能评分】

赛事方向：机器学习、数据挖掘

赛事简介：中国移动福建公司提供2018年x月份的样本数据（脱敏），包括客户的各类通信支出、欠费情况、出行情况、消费场所、社交、个人兴趣等丰富的多维度数据，参赛者通过分析建模，运用机器学习和深度学习算法，准确评估用户消费信用分值。

方案分享：

1、https://mp.weixin.qq.com/s/t0oIP6XPWeSxDV2_lsliiA

2、https://github.com/C-rawler/DCIC-2019-Credit-intelligence-score-2th-Place

3、https://github.com/xy0210/DCIC-2019-China-Mobile


【超大规模推荐之用户兴趣高效检索】

赛事方向：结构化数据

赛事简介：参赛选手需要为测试集中的每一个用户生成一个商品推荐列表，列表中需要包含该用户最有可能感兴趣的 50 个商品。选手提交的推荐结果将用于和真实的用户兴趣进行比对，推荐结果的精准度和新颖性将作为最终的评价指标并反馈给参赛者。

方案分享：

第一名：https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.12.762d5059KmffL5&postId=81152

第三名：https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.3.762d5059KmffL5&postId=81487

第四名：https://tianchi.aliyun.com/forum/postDetail?spm=5176.12586969.1002.9.762d5059KmffL5&postId=81500



赛事方向：结构化数据

赛事简介：购买转化率是品牌商家在电商平台运营时最关注的指标之一，本次大赛中云积互动提供了品牌商家的历史订单数据，参赛选手通过人工智能技术构建预测模型，预估用户人群在规定时间内产生购买行为的概率。

方案分享：

baseline：https://github.com/Travisgogogo/2019-datacastle-enbrands



赛事方向：结构化数据

赛事简介：从给定的房屋基本信息以及房屋销售信息等，建立一个回归模型预测房屋的销售价格。

方案分享：

baseline：https://github.com/bingshen/KingCounty



```

### NLP竞赛
```

赛事方向：自然语言处理

赛事简介：为应对当前虚假新闻泛滥的现状，将虚假新闻带来的危害最小化，我们设立此赛题以促进对虚假新闻自动化检测方法的研究。针对虚假新闻的特点，我们设立了三个子任务：虚假新闻文本检测、虚假新闻图片检测、虚假新闻多模态检测。

方案分享：

第一名：https://www.biendata.com/models/category/3529/L_notebook/

其他:https://github.com/deping-1/2019-false-news-detection-challenge


赛事方向：自然语言处理

赛事简介：本次比赛将提供一个论文库（约含20万篇论文），同时提供对论文的描述段落，来自论文中对同类研究的介绍。参赛选手需要为描述段落匹配三篇最相关的论文。

方案分享：

冠军:https://zhuanlan.zhihu.com/p/88664963

亚军:https://zhuanlan.zhihu.com/p/88257675



```

### 疫情期间互联网虚假新闻检测
```
比赛：https://discussion.datafountain.cn/questions/2638
代码：https://github.com/parthpatwa/covid19-fake-news-detection/blob/main/ml_baseline.ipynb


补充知识
论文
Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks
Capturing the Style of Fake News
Weak Supervision for Fake News Detection via Reinforcement Learning
Proactive Discovery of Fake News Domains from Real-Time Social Media Feeds


参考代码
https://github.com/piotrmp/fakestyle
https://github.com/yaqingwang/WeFEND-AAAI20

虚假新闻检测
https://github.com/YuzheMao/Multimodal-Fake-News-Detection-during-COVID-19
https://github.com/shibing624/fake-news-detector
https://jiaxiangbu.github.io/rumor_detection_2019_ncov/
https://github.com/YuzheMao/Multimodal-Fake-News-Detection-during-COVID-19

biendata-智源&计算所-互联网虚假新闻检测挑战赛
https://github.com/datawhalechina/competition-baseline/blob/master/competition/biendata-%E6%99%BA%E6%BA%90%26%E8%AE%A1%E7%AE%97%E6%89%80-%E4%BA%92%E8%81%94%E7%BD%91%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/README.md

2019虚假新闻检测挑战赛冠军思路&方法揭秘
https://www.secrss.com/articles/15352

参考文章
万字长文带你解读『虚假新闻检测』最新进展：https://cloud.tencent.com/developer/article/1774448
CIKM 2021 | 假新闻有“两幅面孔”：整合模式和事实信息的虚假新闻检测（已开源）：https://zhuanlan.zhihu.com/p/414464291
如何实现网络虚假信息的智能识别：https://www.ccf.org.cn/Media_list/cncc/2022-11-02/775967.shtml
```

### 2023数学建模C题方案
```
题目：http://www.mcm.edu.cn/html_cn/node/c74d72127066f510a5723a94b5323a26.html
全套解决方案：https://aistudio.baidu.com/projectdetail/6805057

数学建模资料：https://github.com/zhanwen/MathModel


论文 + 代码：https://github.com/HuaYuXiao/Automated-pricing-and-replenishment-decisions-for-vegetable-products
计算品类关联代码：https://github.com/jxtse/MCM2023_C/blob/main/%E5%8D%95%E5%93%81Apriori.py


简单思路参考
盗火的想法 - 知乎
https://www.zhihu.com/pin/1684959372697100288
2023国赛C题-蔬菜定价与补货-探索性思路及初步实现 - 模型视角的文章 - 知乎
https://zhuanlan.zhihu.com/p/654953916
2023数学建模C题国赛高教社杯模型代码 - 数学玩客的文章 - 知乎
https://zhuanlan.zhihu.com/p/655188680


官方解题思路：https://mp.weixin.qq.com/s/zO7i2mi0we2n1BEOkpNkQA


附件1给出了某商超经销的6个蔬菜品类的商品信息;附件2和附件3分别给出了该商超2020年7月1日至2023年6月30日各商品的销售流水明细与批发价格的相关数据;附件4给出了各商品近期的损耗率数据。请根据附件和实际情况建立数学模型解决以下问题:
问题1蔬菜类商品不同品类或不同单品之间可能存在一定的关联关系，请分析蔬菜各品类及单品销售量的分布规律及相互关系。

问题2考虑商超以品类为单位做补货计划，请分析各蔬菜品类的销售总量与成本加成定价的关系，并给出各蔬菜品类未来一周(2023年7月1-7日)的日补货总量和定价策略，使得商超收益最大。

问题3因蔬菜类商品的销售空间有限，商超希望进一步制定单品的补货计划，要求可售单品总数控制在27-33个，且各单品订购量满足最小陈列量25千克的要求。根据2023年6月24-30日的可售品种，给出7月1日的单品补货量和定价策略，在尽量满足市场对各品类蔬菜商品需求的前提下，使得商超收益最大。

问题4为了更好地制定蔬菜商品的补货和定价决策，商超还需要采集哪些相关数据，这些数据对解决上述问题有何帮助，请给出你们的意见和理由。
附件16个蔬菜品类的商品信息附件2销售流水明细数据
附件3蔬菜类商品的批发价格附件4蔬菜类商品的近期损耗率
注(1)附件1中，部分单品名称包含的数字编号表示不同的供应来源。
(2)附件4中的损耗率反映了近期商品的损耗情况，通过近期盘点周期的数据计算得到。


第二题
简单arima 或者 机器学习模型搭建 成本-销量模型
用mini 和公式 搭建最优化解法

第三题
品类粒度切换单品类
主体解法不变
加约束条件

df_profit[col] = df_sale[col].astype(float)*df_price[col].astype(float) - df_sale[col].astype(float) *(1+selected_columns[selected_columns['单品净名称'] == col]['平均损耗率'].values[0].astype(float))*df_cost[col].astype(float)

a=float(df_total.loc[(1078+i),[S]])+(float(df_sale.loc[(1078+i),[S]])-2.5)*(float(df_cost.loc[(1078+i),[S]]))/(np.log(3.5))*(np.log(3.5-x))

画图工具
pip3 install seaborn



中文乱码
安装字体
apt-get install fonts-wqy-zenhei
清楚字体缓存
python3 -c "import matplotlib; print(matplotlib.get_cachedir())"
rm  /root/.cache/matplotlib/fontlist-v330.json 



!wget http://129.204.205.246/downloads/SimHei.ttf
!rm -r /home/aistudio/.cache/matplotlib
!mkdir -p ~/.fonts
!cp SimHei.ttf ~/.fonts/SimHei.ttf
!fc-cache -fv
```

### 交叉验证
```
【机器学习】Cross-Validation（交叉验证）详解：https://zhuanlan.zhihu.com/p/24825503
```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

## 从0到1安装
```bash
ubuntu
apt-get update
apt install sudo -y
# programm
apt install -y gcc-9 g++-9
# golang 1.20版本
wget https://mirrors.ustc.edu.cn/golang/go1.21.0.linux-amd64.tar.gz
tar -zxvf go1.21.0.linux-amd64.tar.gz
rm -rf /usr/local/go && tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz
rm -rf /usr/bin/go && tar -C /usr/bin -xzf go1.21.0.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
go version
go env -w GO111MODULE=on
go env -w GOPROXY=https://goproxy.cn,direct

# pg库
apt-get install libpq-dev -y
apt install postgresql -y

# 创建库表 - 业务操作
# service postgresql start
# sudo -u postgres psql
# CREATE USER dbusername WITH PASSWORD 'dbpassword';
# CREATE DATABASE db;


# python3
apt install -y python3.8
apt install -y python3-pip
# openGL库
apt-get install -y libgl1-mesa-glx
# 进度条库
pip3 install tqdm   
# sql
pip3 install SQLAlchemy==1.4.23 -i https://pypi.mirrors.ustc.edu.cn/simple
pip3 install psycopg2 


# pytorch
pip3 install torch torchvision -i https://pypi.mirrors.ustc.edu.cn/simple # 用国内源
pip3 install graphviz -i https://pypi.mirrors.ustc.edu.cn/simple

# huggingface
pip3 install setuptools_rust
pip3 install transformers

# juypter
pip3 install setuptools_scm
pip3 install argon2-cffi-bindings
pip3 install jupyter



# paddlepaddle 全家桶
pip3 install paddlepaddle==2.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install paddleocr
pip3 install visualdl==2.4.0  
pip3 install flask-babel==1.0.0
pip3 install paddlenlp -i https://pypi.tuna.tsinghua.edu.cn/simple    

# pdf工具
pip3 install pdf2image
pip3 install gradio
pip3 install pdfplumber   

pip3 install langchain
# embedding
pip3 install fastNLP  
pip3 install fuzzywuzzy
python3 -m pip install milvus
pip3 install jieba

# modelscope
pip3 install numpy pandas urllib3
pip3 install datasets==2.13.0
pip3 install dill==0.3.6
pip3 install multiprocess==0.70.14
pip3 install accelerate -U
pip3 install sentencepiece -U
pip3 install modelscope -U 

# 打包当前环境
pip3 freeze > requirements.txt



# 业务逻辑
# llm_demo服务
dir=`pwd`
export PYTHONPATH=$PYTHONPATH:$dir
export PYTHONPATH=$PYTHONPATH:/mnt/workspace

# 写入数据
cd /mnt/workspace/llm_demo/util
python3 insert_balance_sheet.py
python3 insert_cash_flow.py
python3 insert_company_annual_reports.py
python3 insert_profit_statement.py

mv /etc/dsw/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /etc/dsw/lib/libffi.so.8 /mnt/workspace/libffi/.
mv /opt/conda/lib/libffi.so.8 /mnt/workspace/libffi/.
mv /opt/conda/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /opt/conda/pkgs/libffi-3.4.2-h6a678d5_6/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /opt/conda/pkgs/libffi-3.4.2-h6a678d5_6/lib/libffi.so.8 /mnt/workspace/libffi/.


cp /mnt/workspace/libffi/libffi.so.8 /opt/conda/lib/libffi.so.8 



```
