## 关键词
1. 召回
2. 搜索相关性
3. query改写/理解
4. bert/ernie
5. paddle/pytorch
6. 文本相关性
7. 向量化/检索
8. 预训练/推理资源
9. 参考写法 https://github.com/chenzomi12/AISystem/tree/main

## 前沿技术
1. MLSys 2024有哪些值得关注的文章？ - Mskg4b8的回答 - 知乎 https://www.zhihu.com/question/653657864/answer/3473761245
2. EMNLP 2023 Best Paper公布啦：https://mp.weixin.qq.com/s/NQ2eLJ47Oni85O7m1oGWtA
3. sigir‘23「快手」SESRec: When Search Meets Recommendation: Learning Disentangled Search Representation - 猫的薛定谔的文章 - 知乎 https://zhuanlan.zhihu.com/p/670956973
4. [VLDB 2019] 如何为 HTAP 负载寻找最优的列式存储布局 - 马克刘的文章 - 知乎 https://zhuanlan.zhihu.com/p/668222560
5. MoE 入门介绍 核心工作回顾 模型篇 - 原石人类的文章 - 知乎 https://zhuanlan.zhihu.com/p/671434414
6. CIKM'22 腾讯 | 召回模型大一统：U2I/U2U/I2I召回联合建模 - Gordon Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/671371188
7. 【EMNLP 2023】基于大语言模型的复杂任务认知推理算法CogTree - 阿里灵杰的文章 - 知乎 https://zhuanlan.zhihu.com/p/671744294
8. ACL 2023获奖论文全分享！NLP领域最新研究进展都在这了 - 鱼子酱的文章 - 知乎 https://zhuanlan.zhihu.com/p/643033773
9. 因果推断技术的实际应用落地情况是怎样的？ - 阿里妈妈技术的回答 - 知乎 https://www.zhihu.com/question/515386955/answer/2609255138
10. 《LLM+搜索召排》10篇论文一览 - 情迷搜广推的文章 - 知乎 https://zhuanlan.zhihu.com/p/672777138
11. ATorch：蚂蚁开源PyTorch分布式训练扩展库，助你将硬件算力压榨到极致 - AI Infra的文章 - 知乎 https://zhuanlan.zhihu.com/p/674090806
12. 苹果最新研究：将LLM放在闪存推理显著提升推理效率 - 岳廷的文章 - 知乎 https://zhuanlan.zhihu.com/p/673812879
13. 超长序列推荐：如何让推荐系统“读懂”你的“人生轨迹” - AI Box专栏的文章 - 知乎 https://zhuanlan.zhihu.com/p/668343442
14. VLDB 2022有哪些值得关注的论文？ - Hsword的回答 - 知乎 https://www.zhihu.com/question/549857210/answer/2687128931
15. 【性能工具】HPC/ML/OS/SW性能工具总结 - eyesighting的文章 - 知乎 https://zhuanlan.zhihu.com/p/673459718
16. 世界范围内有哪些研究流处理（stream processing）的高校和团队？ - 孙挺Sunt的回答 - 知乎 https://www.zhihu.com/question/516225132/answer/2346639834
17. 谷歌出品 | TIGER:生成式检索推荐系统 - Houye的文章 - 知乎 https://zhuanlan.zhihu.com/p/674703547
18. 图解高级RAG技术 - iyacontrol的文章 - 知乎 https://zhuanlan.zhihu.com/p/674755232
19. AI编译优化---访存密集算子优化 - sunshinelala的文章 - 知乎 https://zhuanlan.zhihu.com/p/674804131
20. 商品推荐系统场景，商品点击序列信息有多重要？ - magicwt的回答 - 知乎 https://www.zhihu.com/question/635887488/answer/3333662517
21. 关于特征工程里面的特征选择法？ - 郑昀昊的回答 - 知乎 https://www.zhihu.com/question/274263273/answer/2819168772
22. 淘宝主搜 | 大模型在长尾Query改写召回上的实践 - Gordon Lee的文章 - 知乎 https://zhuanlan.zhihu.com/p/675421157
23. CIKM23向量检索5篇论文一览 - 情迷搜广推的文章 - 知乎 https://zhuanlan.zhihu.com/p/675179867
24. 12家研究机构、160页、参考了650篇论文：基础模型推理最全综述 Part3 - 北方的郎的文章 - 知乎 https://zhuanlan.zhihu.com/p/675541255
25. 从 0 手撸一个 pytorch - 易迟的文章 - 知乎 https://zhuanlan.zhihu.com/p/675673150
26. A Survey on Large Language Models for Recommendation：大模型用于推荐系统-论文阅读 - 韩恪的文章 - 知乎 https://zhuanlan.zhihu.com/p/673491147
27. 浅谈推荐算法之长序列模型TWIN - feng的文章 - 知乎 https://zhuanlan.zhihu.com/p/667311200
28. PyTorch Parallelism - talk notes - JackonYang的文章 - 知乎 https://zhuanlan.zhihu.com/p/677808809
29. 最小熵原理（六）：词向量的维度应该怎么选择：https://kexue.fm/archives/7695
30. 维度公式可用性分析：https://kexue.fm/archives/8711
31. Havenask在线检索服务：https://github.com/alibaba/havenask
32. 如何入门 GPT 并快速跟上当前的大语言模型 LLM 进展？ - 叶兀的回答 - 知乎 https://www.zhihu.com/question/599713780/answer/3018222382



## 框架安装
```
虚拟环境
sudu  apt install python3.10-venv -y

python3 -m venv myml
source myml/bin/activate
python3 -m pip install requests


初学者建议统一安装cpu版本

安装pytorch
http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/#21-%E5%AE%89%E8%A3%85-pytorch

pip3 install torch torchvision -i https://pypi.mirrors.ustc.edu.cn/simple # 用国内源
pip3 install graphviz -i https://pypi.mirrors.ustc.edu.cn/simple


安装paddlepaddle全家桶
pip3 install paddlepaddle==2.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple    
pip3 install paddleocr


进阶者安装GPU
cuda安装
wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda_12.4.1_550.54.15_linux.run
sudo sh cuda_12.4.1_550.54.15_linux.run

验证
nvidia-smi
nvcc -V

pytroch
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124 -i https://pypi.mirrors.ustc.edu.cn/simple # 用国内源

```

### 前置安装
```bash
apt install python3.9
apt install python3-pip
# openGL库
apt-get install libgl1-mesa-glx


```

### transformers 安装
```bash
安装rust
curl https://sh.rustup.rs -sSf | sh
# rust生效
source "$HOME/.cargo/env"

pip3 install setuptools_rust
pip3 install transformers

```

### juypter 安装
```
pip install --upgrade pip
pip3 install --upgrade pip
pip3 install --upgrade pip3

pip3 install setuptools_scm
pip3 install argon2-cffi-bindings
pip3 install jupyter

```

### 镜像安装
```
阿里云
https://cr.console.aliyun.com/cn-shanghai/instances/artifact

cpu
docker pull dsw-registry.cn-hangzhou.cr.aliyuncs.com/pai/pytorch:1.8-cpu-py36-ubuntu18.04

gpu
dsw-registry.cn-hangzhou.cr.aliyuncs.com/pai/pytorch:1.8PAI-gpu-py36-cu101-ubuntu18.04

sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 100 --slave /usr/bin/g++ g++ /usr/bin/g++-9


```

## 工具向
### 翻译工具
```
训练Transformer 模型将 中文翻译成英语：https://zhuanlan.zhihu.com/p/469388563

```

## 数据处理
```
paddle：https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html



```
### 并行式加载/读写/缓存

### 不平衡数据
1. 处理不平衡数据的10个方法：imbalanced-learn操作指南 - 新语数据故事汇的文章 - 知乎 https://zhuanlan.zhihu.com/p/702281863
2. 一文带您理解机器学习中的类别不平衡问题 - 新语数据故事汇的文章 - 知乎 https://zhuanlan.zhihu.com/p/681450992
3. Delving into Deep Imbalanced Regression：https://arxiv.org/pdf/2102.09554

```
因为 数据不平衡
所以导致问题
准确率 指标 不准，不具备参考性

解决
SMOTE（Synthetic Minority Over-sampling Technique，合成少数类过采样技术）
RandomOverSampler随机增加少数类的样本数量
RandomUnderSampler随机减少多数类的样本数量
ADASYN（Adaptive Synthetic Sampling，自适应合成采样）
Tomek Links可以移除不同类别之间的最近邻对，减少噪音样本的数量


```

### 正负样本理解
1. 正负样本构造（Negative Sampling） - 松鼠NLP的文章 - 知乎 https://zhuanlan.zhihu.com/p/587033700
2. 召回模型内负采样在batch内采样和全局采样有什么区别？ - 杨旭东的回答 - 知乎 https://www.zhihu.com/question/570722391/answer/3224925189
3. 5.3.2 双塔召回--正负样本选取 - 曾凡喜的文章 - 知乎 https://zhuanlan.zhihu.com/p/688998790


## AI 调度器
### AllReduce

### Gang-Schedule
1. https://xigang.github.io/2019/02/17/gang-scheduler/



## Embedding
### 介绍
```
向量检索引擎：https://zhuanlan.zhihu.com/p/364923722
IndexFlatL2（基于欧氏距离的暴力索引）
IndexIVFFlat（加聚类的倒排索引，支持欧式距离和向量内积两种距离算法）
IndexIVFPQ（加聚类、加量化的倒排索引）

开源项目
facebook：https://github.com/facebookresearch/faiss
阿里：https://github.com/alibaba/proxima

手把手搭建一个语义检索系统：https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search

OpenAI官方教程：如何使用基于embeddings检索来解决GPT无法处理长文本和最新数据的问题 - 数据学习的文章 - 知乎
https://zhuanlan.zhihu.com/p/622365401

https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb

```
### 模型和工业实践
```
Embedding技术的两个小应用：鲁迅全集检索 & 新闻早报聚类 - 段誉的文章 - 知乎
https://zhuanlan.zhihu.com/p/672400191

```
### 标签 转 embedding
```


```

### 数值 转 embedding
```


```
### 文字 转 embedding
```


```
### 数学公式 转 embedding
```


```
### pdf 转 embedding
```
pdf文本加载
https://zhuanlan.zhihu.com/p/644938147

paddleOCR解析文本：https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart.md



安装ocr工具
yum install mupdf-devel


paddleocr --image_dir=/home/aistudio/data/pdf/IETS13_A.pdf --type=structure --recovery=true --use_pdf2docx_api=true

paddleocr --image_dir=/home/aistudio/data/pdf/IETS13_A.pdf --type=structure --recovery=true --lang='en'

paddleocr --image_dir=/home/aistudio/data/pdf/MOBIUS\ Towards\ the\ Next\ Generation\ of\ Query-Ad\ Matching\ in\ Baidu\ Sponsored\ Search.pdf --type=structure --recovery=true --lang='en'



```
### 图片 转 embedding
```


```
### 语音 转 embedding
```


```

### 语音
```bash
https://aistudio.baidu.com/aistudio/projectdetail/4353348?sUid=2470186&shared=1&ts=1660878142250

# 前置依赖
apt-get update
apt install sudo -y
# programm
apt install -y gcc-9 g++-9
apt install -y python3.8
apt install -y python3-pip

apt-get install libsndfile1 -y
apt-get install ffmpeg -y


# 新增speech环境
git clone https://gitee.com/mirrors/pyenv.git ~/.pyenv
export PYTHON_BUILD_MIRROR_URL="https://npm.taobao.org/mirrors/python/"
export HOME=~
export PYENV_ROOT="$HOME/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"

pyenv virtualenv 3.8.10 speech 
pyenv activate speech
source speech/bin/activate
pip3 install paddlepaddle==2.4.2 -i https://mirrors.aliyun.com/pypi/simple/
pip3 install paddlespeech -i https://mirrors.aliyun.com/pypi/simple/
pip3 install paddlespeech_ctcdecoders -i https://mirrors.aliyun.com/pypi/simple/
# mp3 to wav 格式
pip3 install pydub -i https://mirrors.aliyun.com/pypi/simple/

# 退出
pyenv deactivate


paddlespeech asr --lang zh --input /docker/root/projects/demo/data/mp4/剑4真题听力/test1/test1_section1.wav


```

## 检索系统
1. hnsw：https://github.com/nmslib/hnswlib
2. [SIGIR'23|Huawei]Beyond Two-Tower Matching - 失落的萨特的文章 - 知乎 https://zhuanlan.zhihu.com/p/663855432
3. 百度内容理解推理服务FaaS实战——Punica系统：https://mp.weixin.qq.com/s/v5wUF0ZYuHUPNdkYJQ6vPQ
4. 从稀疏表征出发、召回方向的前沿探索：https://mp.weixin.qq.com/s/hFYOzwueaJIdm6rHDDWTFw
### ES安装
```
官网：https://www.elastic.co/cn/downloads/elasticsearch




━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✅ Elasticsearch security features have been automatically configured!
✅ Authentication is enabled and cluster connections are encrypted.

ℹ️  Password for the elastic user (reset with `bin/elasticsearch-reset-password -u elastic`):
  V-W=e0BF3SBK+a2mspgU

ℹ️  HTTP CA certificate SHA-256 fingerprint:
  5c75487e8bb0c8126f493257e6772e33a17bc763b64096886b0246ca853483b5

ℹ️  Configure Kibana to use this cluster:
• Run Kibana and click the configuration link in the terminal when Kibana starts.
• Copy the following enrollment token and paste it into Kibana in your browser (valid for the next 30 minutes):
  eyJ2ZXIiOiI4LjEwLjQiLCJhZHIiOlsiMTEuMy45Ljk0OjkyMDAiXSwiZmdyIjoiNWM3NTQ4N2U4YmIwYzgxMjZmNDkzMjU3ZTY3NzJlMzNhMTdiYzc2M2I2NDA5Njg4NmIwMjQ2Y2E4NTM0ODNiNSIsImtleSI6IlhWWlJWb3NCaFlzTUZYWWZCNmNoOkV6WExwOTFoVGh5N1hxUUVzNVIyQXcifQ==

ℹ️  Configure other nodes to join this cluster:
• On this node:
  ⁃ Create an enrollment token with `bin/elasticsearch-create-enrollment-token -s node`.
  ⁃ Uncomment the transport.host setting at the end of config/elasticsearch.yml.
  ⁃ Restart Elasticsearch.
• On other nodes:
  ⁃ Start Elasticsearch with `bin/elasticsearch --enrollment-token <token>`, using the enrollment token that you generated.
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━


```
### 长文本
```
大模型检索增强生成（RAG）有哪些好用的技巧？ - 战士金的回答 - 知乎
https://www.zhihu.com/question/625481187/answer/3260085982




```


#### case 1
```
你现在是一个关系提取的大模型，我会输入一段文本给你
    输入结构
    1. 背景
    2. 问题
    输出结构
    1. 三元组<实体，属性名，属性值>
    2. 如果你不知道答案，请不要打多余的字，直接回复：没有找到该问题对应的知识
    
    背景如下
    <
    科列斯尼科夫,别名,科列斯尼科夫
科列斯尼科夫,外文名,Kolesnikov
科列斯尼科夫,国籍,俄罗斯
科列斯尼科夫,出生日期,1985年12月26日
科列斯尼科夫,身高,195CM
科列斯尼科夫,体重,78kg
科列斯尼科夫,运动项目,篮球
科列斯尼科夫,所属运动队,圣彼得堡俱乐部
科列斯尼科夫,中文名,科列斯尼科夫
科列斯尼科夫,位置,后卫
科列斯尼科夫,号码,5号
科列斯尼科夫,出生地,俄罗斯
科列斯尼科夫,性别,男
科列斯尼科夫,出生年月,1985年12月26日
科列斯尼科夫,星座,魔羯座
科列斯尼科夫,职业,篮球
米哈伊尔·彼特罗维奇·科列斯尼科夫,别名,米哈伊尔·彼特罗维奇·科列斯尼科夫
米哈伊尔·彼特罗维奇·科列斯尼科夫,中文名,米哈伊尔·彼特罗维奇·科列斯尼科夫
米哈伊尔·彼特罗维奇·科列斯尼科夫,外文名,Михаи́л Петро́вич Коле́сников
米哈伊尔·彼特罗维奇·科列斯尼科夫,出生日期,1939.10
米哈伊尔·彼特罗维奇·科列斯尼科夫,逝世日期,2007.3.26
同第三帝国决斗,作者,玛·瓦·科列斯尼科娃 / 米·谢·科列斯尼科夫
>
    问题如下
    <我想了解一下科列斯尼科夫这位篮球运动员。我知道他是一位后卫球员，且运动技能很高。但是他的出生年月，以及他在哪个队伍效力，他的身高和体重等等，这些我都不太清楚。你能告诉我这些信息吗？>
    输出如下
    输出结果以三元组形式返回: <实体，属性名，属性值>




你现在是一个关系提取的大模型，我会输入一段文本给你
    输入结构
    1. 背景
    2. 问题
    输出结构
    1. 三元组<实体，属性名，属性值>
    2. 如果你不知道答案，请不要打多余的字，直接回复：没有找到该问题对应的知识
    
    背景如下
    <
许仕廉,别名,许仕廉
许仕廉,中文名,许仕廉
许仕廉,国籍,中国
许仕廉,出生地,湖南湘潭
许仕廉,出生日期,1896年
许仕廉,毕业院校,爱荷华大学
许仕廉,主要成就,中国著名社会学家
许仕廉,主要从事,社会、人口学的调查研究教学工作
许仕廉,籍贯,湖南湘潭
许仕廉,性别,男
许仕廉,民族,汉族
许仕廉,出生年月,1896年
许仕廉,职业,社会学家
许仕廉,代表作品,《文化与政治》；《一个市镇调查的尝试》；《社会教育与社会理论》；《中国人口问题》；《人口论纲要》
许仕廉,国 籍,中国
>
    问题如下
    <许仕廉主要是任职什么的？>
    输出如下
    输出结果以三元组形式返回: <实体，属性名，属性值>


```
### faiss
```
看faiss源码解析

https://github.com/facebookresearch/faiss/wiki

faiss使用-入门级小白篇代码教程 - 程序员小丁的文章 - 知乎
https://zhuanlan.zhihu.com/p/642959732

向量数据库入坑指南：初识 Faiss，如何将数据转换为向量
https://cloud.tencent.com/developer/article/2153613

pip install  -i https://mirrors.aliyun.com/pypi/simple faiss-cpu 
pip install  -i https://mirrors.aliyun.com/pypi/simple  faiss-gpu





```

### puck
```
https://github.com/baidu/puck

sudo apt-get remove cmake
apt-get install -y libssl-dev
wget https://github.com/Kitware/CMake/releases/download/v3.21.0/cmake-3.21.0.tar.gz
tar -zxvf cmake-3.21.0.tar.gz
cd cmake-3.21.0
./bootstrap -DCMAKE_USE_OPENSSL=OFF
make -j8  && make install
cmake --version




```

### query理解
```
搜索召回算法实践：文本召回综述 - 南枫的文章 - 知乎
https://zhuanlan.zhihu.com/p/467939766
深入理解搜索引擎——详解query理解 - 药老算法的文章 - 知乎
https://zhuanlan.zhihu.com/p/344631739
美团搜索——基于用户Session的Query改写 - 药老算法的文章 - 知乎
https://zhuanlan.zhihu.com/p/355132926



query结构分析
query改写
query纠错、query对齐、query扩展

```

### 搜索召回
```
Que2Search（上）：FaceBook新一代query搜索召回模型分享 - MECH的文章 - 知乎
https://zhuanlan.zhihu.com/p/615284379
深入理解搜索引擎-搜索召回 - 药老算法的文章 - 知乎
https://zhuanlan.zhihu.com/p/348159133
Que2Search（下）：OPPO搜索广告召回模型落地分享 - MECH的文章 - 知乎
https://zhuanlan.zhihu.com/p/616880233
[召回|KDD2020|FaceBook]Embedding-based Retrieval in Facebook Search论文超级详细解读 - 杰尼小子的文章 - 知乎
https://zhuanlan.zhihu.com/p/438047408

经典推荐算法学习（十三）| 常见推荐召回算法梳理 - 秋雨淅淅l的文章 - 知乎 https://zhuanlan.zhihu.com/p/472770659


```


### 文本相关性
```
百度搜索相关性算法笔记 - 张备的文章 - 知乎
https://zhuanlan.zhihu.com/p/586676631
知乎搜索文本相关性与知识蒸馏 - DataFunTalk的文章 - 知乎
https://zhuanlan.zhihu.com/p/422185499

```
## NLP - 纠错
### 资料
1. 中文纠错技术综述 - 低级炼丹师的文章 - 知乎 https://zhuanlan.zhihu.com/p/357812484
2. 百度中文纠错技术：https://mp.weixin.qq.com/s/r0kWgPHKthPgGqTbVc3lKw
3. PyCorrector文本纠错工具实践和代码详解 - Roger的文章 - 知乎 https://zhuanlan.zhihu.com/p/138981644

### 信息抽取

### BM25
1. BM25算法的通俗理解 - 徐波的文章 - 知乎 https://zhuanlan.zhihu.com/p/420048609
2. 

### ernie
1. 文本分类
2. 命名实体识别
3. 超详细中文预训练模型ERNIE使用指南 - 飞桨PaddlePaddle的文章 - 知乎 https://zhuanlan.zhihu.com/p/76757794
4. 


### ernie_vil 

### 蒸馏技术

https://aistudio.baidu.com/modelsdetail/21/intro?modelId=21
ERNIE-Tiny: A Progressive Distillation Framework for Pretrained Transformer Compression
ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation

### TTS
```
paddleSpeech
https://paddlespeech.readthedocs.io/en/latest/tts/demo.html

```


## 模型推理预估
- Kv cache 原理，计算量的解读https://juejin.cn/post/7362789570217885759
- Continue batching:https://www.cnblogs.com/marsggbo/p/18113963
- vllm源码分析:https://me.tric.space/2023/07/10/vllm/
- vllm源码:https://github.com/vllm-project/vllm
- GenAI的推理分享:https://bytetech.info/articles/7367598886703071286#KLdOd8aKGoKKQfxggArcFQkzn7G
- 知乎vllm源码解析调度策略：https://zhuanlan.zhihu.com/p/692540949
- 知乎vllm源码解析整体架构https://zhuanlan.zhihu.com/p/691045737
- 知乎vllm-prefix解析:https://zhuanlan.zhihu.com/p/678256296
- https://blog.csdn.net/just_sort/article/details/132115735
- https://blog.csdn.net/qq_29788741/article/details/138402133
```
TensorRT详细入门指北，如果你还不了解TensorRT，过来看看吧！ - OLDPAN的文章 - 知乎
https://zhuanlan.zhihu.com/p/371239130

TensorRT-Index：https://docs.nvidia.com/deeplearning/tensorrt/quick-start-guide/index.htmlAPI：https://docs.nvidia.com/deeplearning/tensorrt/api/ONNX GraphSurgeon: https://docs.nvidia.com/deeplearning/tensorrt/onnx-graphsurgeon/docs/index.htmlhttps://docs.nvidia.com/deeplea

作者：OLDPAN
链接：https://zhuanlan.zhihu.com/p/371239130
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。


大模型MLSYS学习随笔- 训推框架总览（DRAFT） - Bruce 仗剑走天涯的文章 - 知乎
https://zhuanlan.zhihu.com/p/692438094


纯原生 PyTorch 加速生成式 AI 模型
代码地址：https://github.com/pytorch-labs/gpt-fast

mamba
https://github.com/state-spaces/mamba.
论文链接：https://arxiv.org/ftp/arxiv/papers/2312/2312.00752.pdf

llama.c
https://github.com/karpathy/llama2.c

Xinference
https://zhuanlan.zhihu.com/p/663065437


llamacpp


chatglm
https://github.com/li-plus/chatglm.cpp

地址标准化服务AI深度学习模型推理优化实践 - 阿里云云栖号的文章 - 知乎
https://zhuanlan.zhihu.com/p/552908554

大模型推理加速论文阅读（三） - 风不语的文章 - 知乎
https://zhuanlan.zhihu.com/p/676309607


大模型如何高效部署？CMU最新万字综述纵览LLM推理MLSys优化技术 - Hsword的文章 - 知乎
https://zhuanlan.zhihu.com/p/677635306


大模型推理加速调研（框架、方法） - mingming的文章 - 知乎
https://zhuanlan.zhihu.com/p/683986024


flash attention V1 V2 V3 V4 如何加速 attention - RedHerring的文章 - 知乎
https://zhuanlan.zhihu.com/p/685020608

```

### 前沿关键词
- FlashAttention、Flash Attention v2、Flash-Decoding的作者
- Mamba
- llama.c
- llamacpp

### 加速思路
1. 量化
2. 权重量化
3. kv cache  int8量化

### 离线批量预测性能


### 容灾能力
1. checkpoint
2. 断点续训

## 模型评估
```
**平均绝对误差**（MAE）
均方误差（MSE）
标准化加权均方根对数误差（NWRMSLE）
交叉熵

```

## 模型结构
1. onnx结构：https://github.com/microsoft/onnxruntime
```

Mixtral 8x7B(Mistral MoE) 模型解析 - CodeLearner的文章 - 知乎
https://zhuanlan.zhihu.com/p/684922663





```

## GPT
### 制作一个BadyGpt
```
参考文档：http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/#21-%E5%AE%89%E8%A3%85-pytorch

langchain方式
https://github.com/chatchat-space/langchain-ChatGLM

```

### chatGLM
```
https://github.com/RonaldJEN/FinanceChatGLM.git



比赛
官网论坛：https://tianchi.aliyun.com/competition/entrance/532126/forum
全训练过程：https://tianchi.aliyun.com/forum/post/573555
数据集：https://modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset/summary?spm=a2c22.21852664.0.0.68171434jkTm0x
baseline代码：https://github.com/RonaldJEN/FinanceChatGLM/
参赛笔记：https://tianchi.aliyun.com/forum/post/571708
基于paddlepaddle的chatglm推理实现代码：https://tianchi.aliyun.com/forum/post/572601

微调模型：https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning
paddle结合GLM：https://aistudio.baidu.com/aistudio/projectdetail/6195067
动手搭建一套端到端文本语义检索系统：https://aistudio.baidu.com/projectdetail/3351784

思路 
gpt生成关键词 prompt 区分文本分析 数学计算
先测试分类效果 
请将下述问题区分为搜索信息类，计算数值类，总结陈述类

关键词语义搜索找到相关pdf paddle语义召回
5000行构建花了10分钟 cpu

pdf识别语义



解析pdf逻辑参考
Traceback (most recent call last):
  File "paddle_model.py", line 16, in <module>
    pprint(docprompt([{"doc": pdf_path, "prompt": ["财报利润率多少",  "住宅投资是多少?"]}]))
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/taskflow.py", line 850, in __call__
    results = self.task_instance(inputs)
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/task.py", line 515, in __call__
    inputs = self._preprocess(*args)
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/document_intelligence.py", line 90, in _preprocess
    ocr_result = self._ocr.ocr(example["doc"], cls=True)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py", line 637, in ocr
    img = check_img(img)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py", line 527, in check_img
    img, flag_gif, flag_pdf = check_and_read(image_file)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/ppocr/utils/utility.py", line 96, in check_and_read
    for pg in range(0, pdf.pageCount):


下载模型和数据集
参考链接：https://tianchi.aliyun.com/forum/post/573555
pip3 install datasets==2.13.0
pip3 install dill==0.3.6
pip3 install multiprocess==0.70.14
pip3 install numpy pandas urllib3
pip3 install torch
pip3 install transformers -U
pip3 install accelerate -U
pip3 install sentencepiece -U
pip3 install torch torchvision -U
pip3 install modelscope -U 

打包当前环境
pip3 freeze > requirements.txt

数据集
git clone http://www.modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset.git

异常
RuntimeError: "addmm_impl_cpu_" not implemented for 'Half'
原因
机器没有gpu，需要配置只跑cpu。加参数 trust_remote_code=True
model = Model.from_pretrained('ZhipuAI/chatglm2-6b', low_cpu_mem_usage=False, trust_remote_code=True, revision='v1.0.7')



export PYTHONPATH=$PYTHONPATH:/docker/root/projects/demo/project/chatglm/baseline_demo/FinanceChatGLM

总结
大模型现阶段一些问题和优势
问题：
模型需要的资源太多了，响应慢，开发慢。这些都是成本
模型对数据质量要求很高，不然基本不可用
输出结果不可控
不适合做大数据计算
不适合做搜索引擎

优势
在提供足量的正确的数据，能融合数据，并生成可看的结果

大模型 + 向量 + 搜索 + 大数据
数据存储成本
索引构建成本
向量生成成本
大模型运行成本
每一个成本都很高
而且pipeline很长
数据同步延迟高，排查问题慢，同时依赖没有简化现有的软件开发模式，反而新增一个链路

我理想中认为的大模型
存储所有的大数据内容，完成端到端的数据链路更新

实际中，因为大模型的成本问题
大模型应该需要具备推理和分析能力，来代替人，生成sql，生成代码。然后提交执行命令
完成一系列自动化机器运维，软件开发，bug修复等操作
这样就能带来明显的价值效益


```
### chatglm3-本地部署
```
https://modelscope.cn/models/Xorbits/chatglm3-ggml/summary

高性能推理

mac
./Library/Python/3.9/bin/xinference -p 9997

```

### AI小镇
```
https://github.com/joonspk-research/generative_agents

```

## huggingface
### SkyTextTiny 模型
```
git clone https://huggingface.co/SkyWork/SkyTextTiny.git    


```
## 业务向
### Readlist
1. 分割一切：https://pytorch.org/blog/accelerating-generative-ai/
2. 

### 智能文档信息提取
```
https://www.paddlepaddle.org.cn/support/news?action=detail&id=3174

DocVQA榜单
https://rrc.cvc.uab.es/?ch=17&com=evaluation&task=1 

百度AI开放平台——智能文档分析平台
https://ai.baidu.com/tech/nlp/Textanalysis

在线调试
https://console.bce.baidu.com/tools/#/api?product=AI&project=%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB&parent=%E9%89%B4%E6%9D%83%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6&api=oauth%2F2.0%2Ftoken&method=post


开源了！文心大模型ERNIE-Tiny轻量化技术，又准又快，效果全开 - 飞桨PaddlePaddle的文章 - 知乎
https://zhuanlan.zhihu.com/p/535541528

【快速上手ERNIE 3.0】机器阅读理解实战 - 快速实现AI想法的文章 - 知乎
https://zhuanlan.zhihu.com/p/536541088


```
1. 信息抽取方法综述：https://zhuanlan.zhihu.com/p/376898772
2. 




### 2023IKCEST第五届一带一路国际大数据竞赛
#### todolist
1. 提供resnet模型效果
2. bert ernie模型训练加载器
3. LinearDecayWithWarmup 学习率调度器类，它根据线性递减策略计算学习率。在训练过程中
4. LinearWarmup
5. 交叉熵损失
6. 评估的时候采用准确率指标
7. Optimizer
   1. Momentum
   2. adam
8. 模型断点训练
9.  paddle
   1. vision
   2. paddle.concat
   3. paddle.stack
   4. paddle.reshape
   5. 

#### 优化目标
```
文本识别
图形识别
向量concat

预测分类

我的想法
文本识别的特征如何 和 图像识别的特征保持一致呢

数据增广 丰富训练集，加强训练
https://ai.baidu.com/ai-doc/ERNIE-Ultimate/Pl6egw3pu


可使用工具
PaddleDetection

分词工具与词表生成工具
数据增强
交叉验证
网格搜索
编码及转换工具
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tools



问题拆解
文本分类
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/text_classification

文本匹配
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/text_matching


序列标注
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/sequence_labeling


信息抽取
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/information_extraction_many_to_many

文本生成
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/text_generation

数据蒸馏
https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/applications/tasks/data_distillation
Distilling Task-Specific Knowledge from BERT into
Simple Neural Networks：https://arxiv.org/pdf/1903.12136.pdf

指标评估
https://ai.baidu.com/ai-doc/ERNIE-Ultimate/nkmlroqy2

多模态
自回归网络

自编码网络

Token-Drop
https://arxiv.org/pdf/2106.14448v1.pdf

paddlenlp工具


paddlecv



```
#### 数据集介绍
```
标签说明
0	1	2
non-rumor	rumor	unverified


img文件夹下存放每一条声明的图片

img_html_news文件夹下存放根据每一条声明的caption检索到的网页与图片，其中direct_annotation.json包含如下信息：

{
      "img_link": 检索到的相关图片的链接,
      "page_link": 检索到的网页链接,
      "domain": 检索到的网页的域名,
      "snippet": 检索到的网页的简洁摘要,
      "image_path": 检索到的图片的路径,
      "html_path": 检索到的网页的路径,
      "page_title": 检索到的网页标题
}
inverse_search文件夹下存放根据声明的图片找到的网页，其中inverse_annotation.json包含如下信息

{
"entities": 声明中图片中的实体, 
"entities_scores": 声明中图片中的实体的分数, 
"best_guess_lbl": 声明中图片最可能是什么, 
"all_fully_matched_captions": , 
"all_partially_matched_captions":  
"fully_matched_no_text": 
上述三个字段的值均为寻找到的网页，为一个列表，列表中的元素为一个字典，格式如下
	{
	"page_link": 检索到的网页链接, 
	"image_link": 检索到的图片链接, 
	"html_path": 检索到的网页的路径, 
	"title": 检索到的网页的标题
	}
}








```
建模
1. 问题分析
   1. 输入 陈述句
   2. 输出 判断真假消息或不确定
2. 问题拆解
   1. 定义 真消息
      1. 
   2. 定义 假消息
   3. 定义 不确定消息


模型库
1. DUMA 给定一段上下文Passage, 问题Question, 选项Answer Options，选出最合适的答案。
2. roberta 文本向量化
3. RoBERTa-wwm-large
4. ernie模型历史迭代
   1. https://ai.baidu.com/ai-doc/ERNIE-Ultimate/5kye50810
5. 跨模态检索
   1. https://ai.baidu.com/ai-doc/ERNIE-Ultimate/ukxk3hkzc
6. 跨模态信息抽取
   1. https://ai.baidu.com/ai-doc/ERNIE-Ultimate/nkwnlv73o
7. 模型库评测
   1. nlp：https://github.com/CLUEbenchmark/CLUE
8. 工程
   1. ERNIEKit：https://ai.baidu.com/ai-doc/ERNIE-Ultimate/rkmlroren  
   2. paddleNLP
      1. task api：https://github.com/PaddlePaddle/PaddleNLP/tree/develop/examples


论文库
1. 训练
   1. 基于 In-batch negatives 策略训练：https://arxiv.org/abs/2004.04906
   2. 基于 HardestNeg 策略训练

文本数据处理
1. 计算下最长句子的长度
2. 生成向量方案
   1. roberta 模型
3. 文本特征方案
   1. ernie-m
   2. bert

图形数据处理
1. resnet

#### 训练速度
```
杀死进程
ps -ef|grep multi_gpu.py | awk '{print $2}' |  xargs kill -9

多卡和单卡情况差不多
global step 100, epoch: 1, batch: 100, loss: 0.94645, accu: 0.41750, speed: 0.09 step/s
global step 200, epoch: 1, batch: 200, loss: 1.37231, accu: 0.43625, speed: 0.09 step/s
global step 300, epoch: 1, batch: 300, loss: 1.22456, accu: 0.45083, speed: 0.10 step/s
global step 400, epoch: 1, batch: 400, loss: 1.50505, accu: 0.47937, speed: 0.10 step/s
global step 500, epoch: 1, batch: 500, loss: 0.68333, accu: 0.50050, speed: 0.10 step/s

单卡会出现内存溢出，训练失败的情况

```

#### 模型训练优化经验
```
如何优化你的模型 - 错乱空时的文章 - 知乎
https://zhuanlan.zhihu.com/p/360647927

NLP中文预训练模型泛化能力挑战赛
https://tianchi.aliyun.com/competition/entrance/531841/forum

2021语言与智能技术竞赛：多形态信息抽取任务
https://aistudio.baidu.com/competition/detail/65/0/introduction

二等奖方案|产品评论观点提取赛题
https://discussion.datafountain.cn/articles/detail/3764

推荐 nlp cv大模型参数量总结
https://zhuanlan.zhihu.com/p/529863941

竞赛达人的竞赛之旅
https://zhuanlan.zhihu.com/p/375688838

数据
数据预处理
数据增广
外部数据
模型
大力出奇迹
模型结构
loss
label Smooting
优化方法
学习率
对抗训练
EMA，SWA
正则化
word mixup
dropout
early stop
后处理
阈值优化
其他
未起效方法
训练技巧
自知识蒸馏


```
### GPT解决数学建模问题
```


```


### 西安电子科技大学-基于文心一言的法律助手
```
1、提炼核心需求

2、思考满足核心需求的方式

3、评估方式优劣选定方案

4、思考功能概要

5、思考支撑功能和关联功能

6、细化设计功能

7、子功能（功能间迭代）



prd
https://www.woshipm.com/pmd/4289732.html

```
1. 法治的重要性 - 背景
2. 法治遇到的问题 - 调研
   1. 统计角度
      1. 全民普法率
      2. 冤家错案
      3. 法考难度
   2. 执法效率
   3. 
3. 执法链路参与人
   1. 法律人角度：学法，懂法，立法
   2. 群众角度：普法重要性
   3. 原告被告：维护自身权益重要性
4. 法律
   1. 刑法＞刑诉＞行政法＞法理学＞民法＞民诉
5. 产品
   1. 业界情况对比
      1. 差异化
      2. 竞品情况
   2. 整体流程
   3. 需求描述
   4. 版本规划
   5. 产品框架
   6. 功能列表
6. 功能需求
7. 非功能需求
   1. 安全
8. 应用场景
9. 市场化
10. 未来
    1.  视频多模态

   


### 信贷时序特征建模
```
信贷时序数据与特征工程介绍 - 求是汪在路上的文章 - 知乎
https://zhuanlan.zhihu.com/p/397614923


```

### 线上线下全场景生鲜超市库存履约一体化决策
```
https://github.com/MineQihang/BDCI2023/tree/main
```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 自然场景文字定位技术详解
```
自然场景文字定位是文字识别中非常重要的一部分。与通用的物体检测相比，文字定位更具挑战性，文字在长宽比、尺度和方向上有更大范围的变化。针对这些问题，本文介绍一种融合文字片段及金字塔网络的场景文字定位方法。该方法将特征金字塔机制应用到单步多框检测器以处理不同尺度文字，同时检测多个文字片段以及学习出文字片段之间8-neighbor连接关系，最后通过8-neighbor连接关系将文字片段连接起来，实现对不同方向和长宽比的文字定位。此外，针对文字通常较小特点，扩大检测网络中backbone模型深层特征图，以获得更好性能。

（1）基于分割的文本定位；（2）基于回归的文本定位。

"中文门脸招牌文字识别"比赛（ICDAR 2019 Robust Reading Challenge on Reading Chinese Text on Signboards）。


刘曦，美团视觉图像中心文字识别组算法专家
```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

## 竞赛方案复现
```
关键词搜索
名方案

竞赛达人竞赛之旅
https://zhuanlan.zhihu.com/p/375688838


“公益AI之星”挑战赛-新冠疫情相似句对判定大赛
https://tianchi.aliyun.com/competition/entrance/231776/forum
第一名
https://tianchi.aliyun.com/notebook/101624

NLP中文预训练模型泛化能力挑战赛
https://tianchi.aliyun.com/competition/entrance/531841/forum

2021语言与智能技术竞赛：多形态信息抽取任务
https://aistudio.baidu.com/competition/detail/65/0/introduction

二等奖方案|产品评论观点提取赛题
https://discussion.datafountain.cn/articles/detail/3764

表格检测
https://aistudio.baidu.com/competition/detail/702/0/submit-result
https://aistudio.baidu.com/competition/detail/704/0/introduction

第二名方案
https://aistudio.baidu.com/projectdetail/5398861?channelType=0&channel=0


百度网盘AI大赛——图像处理挑战赛：文档图像摩尔纹消除第1名方案
https://aistudio.baidu.com/projectdetail/3462083?channelType=0&channel=0


百度网盘文档图像超分比赛-Serendipity团队-AB榜第二方案 metaRLFN网络
https://aistudio.baidu.com/projectdetail/5133608?channelType=0&channel=0


第五届“中国法研杯”司法人工智能挑战赛
https://aistudio.baidu.com/competition/detail/664/0/submit-result

中国人工智能大赛·语言与知识技术竞赛（个人赛）冠军方案分享
https://aistudio.baidu.com/projectdetail/755387?channelType=0&channel=0

WSDM Cup 2023: Pre-training for Web Search Demo Code
https://aistudio.baidu.com/projectdetail/4844225?channelType=0&channel=0

【飞桨学习赛：百度搜索首届技术创新挑战赛：赛道一】第5名方案
https://aistudio.baidu.com/projectdetail/4950227?channelType=0&channel=0


百度搜索首届技术创新挑战赛赛道二Baseline
https://aistudio.baidu.com/projectdetail/5007642?channelType=0&channel=0


“飞桨杯”重庆市首届人工智能创新大赛-社交网络大数据谣言核查官方baseline
https://aistudio.baidu.com/projectdetail/4913037?channelType=0&channel=0

2022 IKCEST第四届“一带一路”国际大数据竞赛：“一带一路”重点语种-法俄泰阿与中文互译
https://aistudio.baidu.com/competition/detail/477/0/introduction

2022 CCF BDCI 基于文心NLP大模型的阅读理解可解释评测
https://aistudio.baidu.com/competition/detail/394/0/introduction
第五名
https://aistudio.baidu.com/projectdetail/5016503?channelType=0&channel=0


CCKS2022基于知识图谱的优质文章识别
https://aistudio.baidu.com/competition/detail/255/0/introduction


2022 CCF BDCI 基于文心CV大模型的智慧城市视觉多任务识别
https://aistudio.baidu.com/competition/detail/455/0/introduction
第一名
https://aistudio.baidu.com/projectdetail/5035322?channelType=0&channel=0


AIWIN 世界人工智能创新大赛：中文保险小样本多任务竞赛
https://aistudio.baidu.com/competition/detail/218/0/introduction

AIWIN 世界人工智能创新大赛：发债主体违约风险预测竞赛
https://aistudio.baidu.com/competition/detail/222/0/introduction

2021“智荟杯”浦发百度高校极客挑战赛
https://aistudio.baidu.com/competition/detail/123/0/task-definition

【Paddle打比赛】基于PaddleNLP法研杯2022 -犯罪事实实体识别
https://aistudio.baidu.com/projectdetail/4821353?channelType=0&channel=0

2021中国软件杯——新闻智分系统
https://aistudio.baidu.com/projectdetail/1981601?channelType=0&channel=0


2022 CCF BDCI 模心智创-文心大模型智能创意赛
https://aistudio.baidu.com/competition/detail/397/0/introduction



文本智能校对大赛
https://aistudio.baidu.com/competition/detail/404/0/introduction

航旅纵横-领域知识问答测评
https://aistudio.baidu.com/competition/detail/313/0/introduction

飞桨论文复现挑战赛（第六期）
https://aistudio.baidu.com/competition/detail/205/0/introduction

飞桨论文复现挑战赛（第七期）
https://aistudio.baidu.com/competition/detail/406/0/task-definition

2022世界人工智能大会黑客马拉松：百度飞桨论文复现赛
https://aistudio.baidu.com/competition/detail/430/0/introduction

2022世界人工智能大会黑客马拉松：百度飞桨黑客马拉松
https://aistudio.baidu.com/competition/detail/428/0/introduction

兴智杯 全国人工智能创新应用大赛：百度飞桨论文复现赛
https://aistudio.baidu.com/competition/detail/439/0/introduction

“兴智杯”全国人工智能创新应用大赛：深度学习模型可解释性赛
https://aistudio.baidu.com/competition/detail/472/0/introduction



```
### Kaggle汇总
```
前端搜索：https://github.com/faridrashidi/kaggle-solutions

```
### Kaggle - mercari-price-suggestion-challenge
```
比赛链接：https://www.kaggle.com/c/mercari-price-suggestion-challenge

解决方案：https://www.leiphone.com/category/yanxishe/HGSuMdM6c4U6jWLi.html

代码：https://github.com/pjankiewicz/mercari-solution

```

### Kaggle - Predict Future Sales
```
比赛链接：https://www.kaggle.com/competitions/competitive-data-science-predict-future-sales/data

代码：https://www.kaggle.com/code/zhangyunsheng/xgboost/notebook

```

### 2018 腾讯广告算法大赛
```
10th:https://github.com/ShawnyXiao/2018-Tencent-Lookalike

```

### 2021 腾讯广告算法大赛
```
https://github.com/JacksonWuxs/taac2021-Video-Classification-Rank5

```



### Kaggle - Corporacion Favorita Grocery Sales Forecasting
```
比赛地址：

https://www.kaggle.com/c/favorita-grocery-sales-forecasting

论文地址：

https://arxiv.org/pdf/1803.04037.pdf

方案：https://cloud.tencent.com/developer/article/1166628
代码：https://www.kaggle.com/code/shixw125/1st-place-lgb-model-public-0-506-private-0-511/script
```

### 数据科学竞赛2019
```
数据科学竞赛2019：https://mp.weixin.qq.com/s?__biz=Mzk0NDE5Nzg1Ng==&mid=2247490157&idx=1&sn=674461f9cbb0e60bf23994576b67c5d8&source=41#wechat_redirect

【乘用车细分市场销量预测】

赛事方向：预测回归、数据挖掘

赛事简介：本赛题需要参赛队伍根据给出的60款车型在22个细分市场（省份）的销量连续24个月（从2016年1月至2018年12月）的销量数据，建立销量预测模型；基于该模型预测同一款车型和相同细分市场在接下来一个季度连续4个月份的销量；除销量数据外，还提供同时期的用户互联网行为统计数据，包括：各细分市场每个车型名称的互联网搜索量数据；主流汽车垂直媒体用户活跃数据等。参赛队伍可同时使用这些非销量数据用于建模。除了模型的准确性外，参赛队伍需对本赛题任务有系统性的思考和设计，在决赛阶段，参赛队伍对于所提交的模型的适应性、可扩展性、代码的工程性等方面也会影响参赛队伍的最终名次。

方案分享：

https://mp.weixin.qq.com/s/-tT9BKrANTwJK9-N1K4j9g



【消费者人群画像—信用智能评分】

赛事方向：机器学习、数据挖掘

赛事简介：中国移动福建公司提供2018年x月份的样本数据（脱敏），包括客户的各类通信支出、欠费情况、出行情况、消费场所、社交、个人兴趣等丰富的多维度数据，参赛者通过分析建模，运用机器学习和深度学习算法，准确评估用户消费信用分值。

方案分享：

1、https://mp.weixin.qq.com/s/t0oIP6XPWeSxDV2_lsliiA

2、https://github.com/C-rawler/DCIC-2019-Credit-intelligence-score-2th-Place

3、https://github.com/xy0210/DCIC-2019-China-Mobile


【超大规模推荐之用户兴趣高效检索】

赛事方向：结构化数据

赛事简介：参赛选手需要为测试集中的每一个用户生成一个商品推荐列表，列表中需要包含该用户最有可能感兴趣的 50 个商品。选手提交的推荐结果将用于和真实的用户兴趣进行比对，推荐结果的精准度和新颖性将作为最终的评价指标并反馈给参赛者。

方案分享：

第一名：https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.12.762d5059KmffL5&postId=81152

第三名：https://tianchi.aliyun.com/notebook-ai/detail?spm=5176.12586969.1002.3.762d5059KmffL5&postId=81487

第四名：https://tianchi.aliyun.com/forum/postDetail?spm=5176.12586969.1002.9.762d5059KmffL5&postId=81500



赛事方向：结构化数据

赛事简介：购买转化率是品牌商家在电商平台运营时最关注的指标之一，本次大赛中云积互动提供了品牌商家的历史订单数据，参赛选手通过人工智能技术构建预测模型，预估用户人群在规定时间内产生购买行为的概率。

方案分享：

baseline：https://github.com/Travisgogogo/2019-datacastle-enbrands



赛事方向：结构化数据

赛事简介：从给定的房屋基本信息以及房屋销售信息等，建立一个回归模型预测房屋的销售价格。

方案分享：

baseline：https://github.com/bingshen/KingCounty



```

### NLP竞赛
```

赛事方向：自然语言处理

赛事简介：为应对当前虚假新闻泛滥的现状，将虚假新闻带来的危害最小化，我们设立此赛题以促进对虚假新闻自动化检测方法的研究。针对虚假新闻的特点，我们设立了三个子任务：虚假新闻文本检测、虚假新闻图片检测、虚假新闻多模态检测。

方案分享：

第一名：https://www.biendata.com/models/category/3529/L_notebook/

其他:https://github.com/deping-1/2019-false-news-detection-challenge


赛事方向：自然语言处理

赛事简介：本次比赛将提供一个论文库（约含20万篇论文），同时提供对论文的描述段落，来自论文中对同类研究的介绍。参赛选手需要为描述段落匹配三篇最相关的论文。

方案分享：

冠军:https://zhuanlan.zhihu.com/p/88664963

亚军:https://zhuanlan.zhihu.com/p/88257675



```

### 疫情期间互联网虚假新闻检测
```
比赛：https://discussion.datafountain.cn/questions/2638
代码：https://github.com/parthpatwa/covid19-fake-news-detection/blob/main/ml_baseline.ipynb


补充知识
论文
Rumor Detection on Social Media with Bi-Directional Graph Convolutional Networks
Capturing the Style of Fake News
Weak Supervision for Fake News Detection via Reinforcement Learning
Proactive Discovery of Fake News Domains from Real-Time Social Media Feeds


参考代码
https://github.com/piotrmp/fakestyle
https://github.com/yaqingwang/WeFEND-AAAI20

虚假新闻检测
https://github.com/YuzheMao/Multimodal-Fake-News-Detection-during-COVID-19
https://github.com/shibing624/fake-news-detector
https://jiaxiangbu.github.io/rumor_detection_2019_ncov/
https://github.com/YuzheMao/Multimodal-Fake-News-Detection-during-COVID-19

biendata-智源&计算所-互联网虚假新闻检测挑战赛
https://github.com/datawhalechina/competition-baseline/blob/master/competition/biendata-%E6%99%BA%E6%BA%90%26%E8%AE%A1%E7%AE%97%E6%89%80-%E4%BA%92%E8%81%94%E7%BD%91%E8%99%9A%E5%81%87%E6%96%B0%E9%97%BB%E6%A3%80%E6%B5%8B%E6%8C%91%E6%88%98%E8%B5%9B/README.md

2019虚假新闻检测挑战赛冠军思路&方法揭秘
https://www.secrss.com/articles/15352

参考文章
万字长文带你解读『虚假新闻检测』最新进展：https://cloud.tencent.com/developer/article/1774448
CIKM 2021 | 假新闻有“两幅面孔”：整合模式和事实信息的虚假新闻检测（已开源）：https://zhuanlan.zhihu.com/p/414464291
如何实现网络虚假信息的智能识别：https://www.ccf.org.cn/Media_list/cncc/2022-11-02/775967.shtml
```

### 2023数学建模C题方案
```
题目：http://www.mcm.edu.cn/html_cn/node/c74d72127066f510a5723a94b5323a26.html
全套解决方案：https://aistudio.baidu.com/projectdetail/6805057

数学建模资料：https://github.com/zhanwen/MathModel


论文 + 代码：https://github.com/HuaYuXiao/Automated-pricing-and-replenishment-decisions-for-vegetable-products
计算品类关联代码：https://github.com/jxtse/MCM2023_C/blob/main/%E5%8D%95%E5%93%81Apriori.py


简单思路参考
盗火的想法 - 知乎
https://www.zhihu.com/pin/1684959372697100288
2023国赛C题-蔬菜定价与补货-探索性思路及初步实现 - 模型视角的文章 - 知乎
https://zhuanlan.zhihu.com/p/654953916
2023数学建模C题国赛高教社杯模型代码 - 数学玩客的文章 - 知乎
https://zhuanlan.zhihu.com/p/655188680


官方解题思路：https://mp.weixin.qq.com/s/zO7i2mi0we2n1BEOkpNkQA


附件1给出了某商超经销的6个蔬菜品类的商品信息;附件2和附件3分别给出了该商超2020年7月1日至2023年6月30日各商品的销售流水明细与批发价格的相关数据;附件4给出了各商品近期的损耗率数据。请根据附件和实际情况建立数学模型解决以下问题:
问题1蔬菜类商品不同品类或不同单品之间可能存在一定的关联关系，请分析蔬菜各品类及单品销售量的分布规律及相互关系。

问题2考虑商超以品类为单位做补货计划，请分析各蔬菜品类的销售总量与成本加成定价的关系，并给出各蔬菜品类未来一周(2023年7月1-7日)的日补货总量和定价策略，使得商超收益最大。

问题3因蔬菜类商品的销售空间有限，商超希望进一步制定单品的补货计划，要求可售单品总数控制在27-33个，且各单品订购量满足最小陈列量25千克的要求。根据2023年6月24-30日的可售品种，给出7月1日的单品补货量和定价策略，在尽量满足市场对各品类蔬菜商品需求的前提下，使得商超收益最大。

问题4为了更好地制定蔬菜商品的补货和定价决策，商超还需要采集哪些相关数据，这些数据对解决上述问题有何帮助，请给出你们的意见和理由。
附件16个蔬菜品类的商品信息附件2销售流水明细数据
附件3蔬菜类商品的批发价格附件4蔬菜类商品的近期损耗率
注(1)附件1中，部分单品名称包含的数字编号表示不同的供应来源。
(2)附件4中的损耗率反映了近期商品的损耗情况，通过近期盘点周期的数据计算得到。


第二题
简单arima 或者 机器学习模型搭建 成本-销量模型
用mini 和公式 搭建最优化解法

第三题
品类粒度切换单品类
主体解法不变
加约束条件

df_profit[col] = df_sale[col].astype(float)*df_price[col].astype(float) - df_sale[col].astype(float) *(1+selected_columns[selected_columns['单品净名称'] == col]['平均损耗率'].values[0].astype(float))*df_cost[col].astype(float)

a=float(df_total.loc[(1078+i),[S]])+(float(df_sale.loc[(1078+i),[S]])-2.5)*(float(df_cost.loc[(1078+i),[S]]))/(np.log(3.5))*(np.log(3.5-x))

画图工具
pip3 install seaborn



中文乱码
安装字体
apt-get install fonts-wqy-zenhei
清楚字体缓存
python3 -c "import matplotlib; print(matplotlib.get_cachedir())"
rm  /root/.cache/matplotlib/fontlist-v330.json 



!wget http://129.204.205.246/downloads/SimHei.ttf
!rm -r /home/aistudio/.cache/matplotlib
!mkdir -p ~/.fonts
!cp SimHei.ttf ~/.fonts/SimHei.ttf
!fc-cache -fv
```

### 交叉验证
```
【机器学习】Cross-Validation（交叉验证）详解：https://zhuanlan.zhihu.com/p/24825503
```

### OTTO 
```
kaggle推荐系统比赛汇总 （含金牌方案） - 鱼子酱的文章 - 知乎
https://zhuanlan.zhihu.com/p/651824600

1st place solution
https://www.kaggle.com/competitions/otto-recommender-system/discussion/384022 

3st code
https://github.com/TheoViel/kaggle_otto_rs/tree/master


开发环境-硬件条件
Features are computed per batch on a 32Gb V100 using RAPIDS. It's fast
https://rapids.ai/
https://drive.google.com/drive/search?q=owner:me+(type:application/vnd.google.colaboratory+%7C%7C+type:application/vnd.google.colab)




```


### HMS - Harmful Brain Activity Classification
1. 医疗图像场景
   1. https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/overview   
2. Kullback Leibler Divergence kl散度评估
   1. https://www.kaggle.com/code/metric/kullback-leibler-divergence/notebook
3. baseline：https://www.kaggle.com/code/awsaf49/hms-hbac-kerascv-starter-notebook

```

https://www.kaggle.com/code/awsaf49/hms-hbac-kerascv-starter-notebook

```
## AB实验
1. 什么是ab实验
2. 什么是人群打散
3. 什么是算法人群包
4. 如何定义好一个可信的实验
5. 如何快速验证实验效果

## 基础

### 深度思考
1. 算法
   1. 分类和回归到底什么区别
   2. 万能近似定理 是什么
   3. 主流网络层：全连接层（Fully-connected layer）、卷积层（Convolution layer）、循环网络层（Recurrent neral network layer）和注意力层（Attention layer）
2. 工程
   1. 数据流图（Dataflow Graph）和 张量核心设计与结合
      1. 数据流图优化，运行时调度策略，以及算子优化
   2. 单设备算子间调度
   3. 图切分与多设备执行
   4. 动态图向静态图转换分为基于追踪（Tracing）和基于源代码解析（Parsing）两种方式
   5. 以TensorFlow的Auto-graph[6]和PyTorch的JIT[8]为代表，主流深度学习框架最终都走向了探索动态图与静态图的融合
   6. Dynamic Control Flow in Large-Scale Machine Learning
   7. 在CPU上实现一个矩阵乘法算子
      1. https://github.com/microsoft/AI-System/blob/main/Labs/BasicLabs/Lab2/mnist_custom_linear.py
      2. https://github.com/microsoft/AI-System/blob/main/Labs/BasicLabs/Lab2/mnist_custom_linear_cpp.py
   8. GPU
      1. https://github.com/microsoft/AI-System/blob/main/Labs/BasicLabs/Lab3/mnist_custom_linear_cuda.py
   9.  计算访存比是在针对硬件特点优化算法的常用指标，请参考文本中针对矩阵乘法的计算方法，给其它常用的算子计算其计算访存比和分块大小的关系，并推测其在GPU和CPU上实现的时候最关键的性能因素。
   10. 计算图上做的这些优化和传统编译器上的优化有何不同？你还能想到哪些计算图上的优化方法？
   11. 请读者思考为何进行编译时调度而不是运行时调度？如何实现运行时调度最可行的方案是什么？
   12. 内存和计算的优化之间是否互相影响？还有哪些有损的内存优化方法可以用在深度学习计算中？
   13. 在传统的编译器程序生成中，我们很少看到利用机器学习来自动生成程序的方法，请读者思考这种方法的好处与主要缺点，还有自动代码生成还能被用到哪些场景中呢？
   14. 为什么模型训练通常需要分布式进行，而分布式模型预测并不常见？
       1.  计算模式不同：预测任务占用存储更小，更容易放在单个设备中
       2.  训练需要各个工作节点（Worker）保持通信，从而协调统一地更新模型参数；
       3.  预测中的模型参数是固定的，各个工作节点分别使用只读副本，无需相互通信协调
   15. AllReduce的实现和优化
       1.  https://github.com/microsoft/AI-System/blob/main/Textbook/%E7%AC%AC6%E7%AB%A0-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E7%AE%97%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F/6.5-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%B0%83.md
   16. 利用C++/CUDA API实现更为高效的压缩/解压缩编码
   17. 调度问题
       1.  如何提交作业与解决环境依赖问题？
       2.  如何高效调度作业并分配资源？
       3.  如何将启动的作业运行时环境，资源与命名空间隔离？
       4.  如何面向深度学习作业和异构资源设计集群管理系统？
       5.  如何高效存取数据？
       6.  如何不断开发平台新功能与运维平台并保证稳定性？
   18. 总结思考深度学习作业和传统操作系统作业以及大数据平台作业的异同点？
   19. 如果需要兼顾以上指标，新一代深度学习调度与平台设计应该朝着哪个方向设计与发展？
   20. 请读者设计算法或策略，保证公平性的同时，最大限度提升集群效率，可以上一小节的日志痕迹（Trace）进行实验设计与算法验证。
   21. 请读者思考，当前是否有必要设计一款针对深度学习场景的文件系统？



### 架构
1. 深度神经网络编译器
   1. DSL python go c++
   2. 中间表达（Intermediate Representation, IR）
   3. 算子表达式（Tensor Expression）
   4. 深度神经网络编译器的优化过程（Optimization Pass）
      1. 如常数传播、公共子表达式消除等
   5. 计算图优化
      2. 算术表达式化简
      3. 公共子表达式消除（Common Subexpression Elimination, CSE）
      4. 常数传播（constant propagation）就叫常数折叠（constant folding）
      5. 矩阵乘自动融合 BatchMatMul
      6. 算子融合方法是针对矩阵乘算子
         1. 针对大量的小算子的融合都可以提高GPU的利用率，减少内核启动开销、减少访存开销等好处。例如，Element-wise的算子（如Add，Mul，Sigmoid，Relu等）其计算量非常小，主要计算瓶颈都在内存的读取和写出上，如果前后的算子能够融合起来，前面算子的计算结果就可以直接被后面算子在寄存器中使用，避免数据在内存的读写，从而提交整体计算效率。
      7. 子图替换和随机子图替换
         1. 编译器在计算图中识别出一个子图并替换成一个等价的新的算子或子图的过程就是子图替换优化 
   6. 内存优化
      1. 基于拓扑序的最小内存分配
      2. 张量重计算
      3. 张量换入换出
   7. 内核优化
      1. 算子表达式
      2. 算子表示与调度逻辑的分离
      3. 自动调度搜索与代码生成
   8. 跨算子的全局调度优化
      1. 任意算子的融合
      2. 编译时全局算子调度
      3. 单个Op的调度时间与计算时间相比不可忽略，造成较大的调度开销；
      4. OP的并行度不足以占满GPU的计算核心。
2. 算子
   1. Add Log MatMul Conv BatchNorm Loss
3. 并行计算
   1. 串行计算到并行计算的演进
      1. 从原理上来讲，并行计算通过并行算法将问题的求解进行划分，并将编译的指令分发给分布式系统中的多处理器并行执行。这样一来，所有的计算量被分摊到多个计算单元之上，相比于串行计算，并行计算中的每个计算单元只需要负责部分的计算，缩短了整体的计算时间。
   2. 并行计算加速定律
      1. 阿姆达尔定律 (Amdahl's law)
      2. Gustafson定律 (Gustafson’s law)
   3. 深度学习的并行化训练
      1. 单步计算量取决于模型的复杂程度和批尺寸（Batch Size），结合计算速率可以算得训练耗时
      2. 并行训练BERT[7] 引入了全新的LARS优化器才能保证模型在设置了更大的批尺寸后依然能够收敛
   4. 算子内并行保持已有的算子的组织方式，探索将单个深度学习算子有效地映射到并行硬件设备上的执行
   5. 算子间并行则更注重发掘多个算子在多个设备上并行执行的策略，甚至解耦已有的单个算子为多个等效算子的组合，进一步发掘并行性。
4. 分布式训练
   1. 数据并行
   2. 模型并行
   3. 流水并行
   4. 同步并行、异步并行、半同步并行
   5. 机器内通信
      1. 共享内存、GPUDirect P2P over PCIe、GPUDirect P2P over NVLink
   6. 机器间通信
      1. TCP/IP网络、 RDMA网络和GPUDirect RDMA网络
5. 通信库
   1. NCCL: NVIDIA Collective Communication Library
   2. 集合式通信（collective communication）all-gather、 all-reduce、 broadcast、 reduce、reduce-scatter 以及点对点(point-to-point)通信send 和receive。
6. 调度问题优化目标
   1.  

### Transformer
```
如何最简单、通俗地理解Transformer？ - 鱼先生的回答 - 知乎
https://www.zhihu.com/question/445556653/answer/2882383919
Transformer 之逐层介绍 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604450283
Transformer 之多头注意力 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604452790
Transformer 之注意力计算原理 - 鱼先生的文章 - 知乎
https://zhuanlan.zhihu.com/p/604454823


【【精校珍藏版】大牛Andrej Karpathy的stanford深度学习课程：深入理解Transformer，从零打造最简版GPT】 https://www.bilibili.com/video/BV1Tm4y1b7UP/?share_source=copy_web&vd_source=8783d6f7758784f093c06edba717af3d


源码实现（有能力自己看）
http://nlp.seas.harvard.edu/annotated-transformer/
https://wmathor.com/index.php/archives/1455/
https://github.com/BoXiaolei/MyTransformer_pytorch
nlp模型算法实现：https://github.com/graykode/nlp-tutorial


源码讲解
https://wmathor.com/index.php/archives/1438/

```


#### 整体思路
1. Key
2. Query
3. Value
4. QKV计算公式，如何初始化，最终达到注意力的效果

#### LSTM RNN 对比
1. 没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系
2. 位置嵌入的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成
3. 

#### 注意力机制
1. Embedding Size
2. Query
3. number of Attention heads
4. batch_size
思路灵感
1. Neural machine translation by jointly learning to align and translate
2. Massive exploration of neural machine translation architectures


#### layer-normal
```
思路灵感
Layer normalization

```
#### position encoding
```
思路灵感
Convolutional sequence to sequence learning



```

#### position-wise feedward networks
1. 

#### 网络结构优化
思路灵感
1. Rethinking the inception architecture for computer vision
2.  Dropout: a simple way to prevent neural networks from overfitting
3.  Deep residual learning for image recognition

### Bert
```

```

### resnet
```

```



### ernie-m 网络结构
```
NetWork(
  (ernie): ErnieMModel(
    (embeddings): ErnieMEmbeddings(
      (word_embeddings): Embedding(250002, 768, sparse=False)
      (position_embeddings): Embedding(514, 768, sparse=False)
      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (encoder): TransformerEncoder(
      (layers): LayerList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (6): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (7): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (8): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (9): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (10): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (11): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
    (pooler): ErnieMPooler(
      (dense): Linear(in_features=768, out_features=768, dtype=float32)
      (activation): Tanh()
    )
  )
  (resnet): EncoderCNN(
    (resnet): Sequential(
      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)
      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
      (2): ReLU()
      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)
      (4): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (5): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (6): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (4): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (5): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (6): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (7): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (8): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (9): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (10): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (11): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (12): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (13): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (14): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (15): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (16): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (17): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (18): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (19): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (20): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (21): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (22): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (7): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
    )
    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))
  )
  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)
  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)
  (attention_text): MultiHeadAttention(
    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
  )
  (attention_image): MultiHeadAttention(
    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
  )
)
```

### NLP 技术图谱

1. 自监督词表示学习
   1. 词向量模型(Word2Vec)
   2. 语言模型(Language Modeling, LM)
2. 句子编码网络
   1. 自回归 n-gram语言模型
   2. 循环神经网络(Recurrent Neural Network, RNN)
   3. 注意力机制 Transformer
3. 自回归、自编码预训练模型
   1. GPT(自回归)
      1. 无马尔科夫链
      2. self-attention
      3. 大规模自监督学习
   2. BERT 自编码
      1. cbow
      2. 利用上下文预测中间词
      3. 作为encoder 能看到整个句子的信号
4. 任务类型
   1. classification
   2. entailment
   3. similary
   4. multiple choice
5. 语言任务
   1. 字理解
   2. 词理解
   3. 句子理解
   4. 篇章理解
   5. 多义 同义 歧义
   6. 语境
   7. 语义理解
      1. 双向语言模型建模 建模上下文信息
      2. 两层lstm 建模不同层次语义信息 （单词特征 句法特征 语义特征）
   8. 单句分类
   9. 句对分类 自然语言推断
   10. 文本匹配
       1.  query - document
       2.  question - answer
       3.  utterance - response
   11. 命名实体识别
   12. 事件关系抽取
   13. 机器阅读理解
6. ELMo
   1. pre-training
      1. 双向语言模型建模 建模上下文信息
      2. 两层lstm 建模不同层次语义信息 （单词特征 句法特征 语义特征）
   2. fine-tuning
      1. 基于feature-based方式
   3. 问题
      1. 不完全双向训练
      2. 任务相关网络结构设计
      3. 仅有词向量，无句向量
7. GPT
   1. pre-training
      1. transform decoder
      2. bookscorpus
   2. fine-tuning
      1. 基于model-based方式
8. Bert
   1. pre-training
      1. LM -> Auto-encoder
      2. sentence-level
   2. fine-tuning
      1. add token-level
      2. add sentence-level
   3. 单句分类
   4. 句对分类
   5. 序列标注任务
9. ernie
   1.  ernie-vil
   2.  unimo
   3.  -M
   4.  -Doc
10. 语言
    1.  语序
    2.  语义：关联，非关联，同话题
    3.  逻辑关系
11. 信息抽取
    1.  实体
    2.  关系
    3.  事件
    4.  方法
        1.  抽取解析式
        2.  理解生成式
12. 问答系统
    1.  文本
    2.  知识库
    3.  表格
    4.  视频
    5.  方法
        1.  稀疏向量
        2.  稠密向量
13. 数学工具
   1. 前向传播
   2. 反向传播
   3. 损失函数
   4. 负梯度反向传播
14. 
15. 网络层
   1. embedding
   2. 

模型
1. 2013
   1. cbow skip-gram glove
2. 2014
   1. cnn rnn lstm seq-to-seq
3. 2015
   1. transformer
4. 2018
   1. elmo gpt bert

论文
1. 基础论文
   1. Efficient Estimation of Word Representations in Vector Space.
   2. RNN
   3. self-attention
   4. elmo
   5. gpt
   6. bert
   7. ernie
   8.  A continual pre-training framework for language understanding
2.  问答系统论文
    1.  Reading Wikipedia to Answer Open-domain Questions
    2.  Questions for Machine Comprehension of Text
    3.  DuReader: a Chinese Machine Reading Comprehension Dataset from Real-world Applications
    4.  Dense Passage Retrieval for Open-Domain Question Answering.


### DSSM双塔模型
```
DSSM双塔模型及pytorch实现 - 简之的文章 - 知乎
https://zhuanlan.zhihu.com/p/402123341

https://github.com/MemoryForSky/deepctr

https://github.com/HeartFu/DSSM.git

```
 
### wide & deep & XDeepFM 
1. wide
   1. 特征构造
   2. 特征交叉
   3. FTRL优化器（特征稀疏）
2. depp
   1. embedding层
   2. nn层
   3. AdaGrad优化器

### FM & FFM & DeepFM & DeepFFM
```





```

### DCN & DCNv2

### bias问题
1. position-bias pCTR 华为
2. exposure-bias ESMM 阿里
3. popularity-bias ESAM

### 模型效果优化
1. 为什么回归问题不能用Dropout - Lukan的文章 - 知乎 https://zhuanlan.zhihu.com/p/561124500


### 精排模型
```
快手精排模型实践 - DataFunTalk的文章 - 知乎
https://zhuanlan.zhihu.com/p/602322538


一文说尽推荐系统中的精排模型 - Tang AI的文章 - 知乎
https://zhuanlan.zhihu.com/p/586162228

小红书如何实现高效推荐？解密背后的大数据计算平台架构 - 阿里云云栖号的文章 - 知乎
https://zhuanlan.zhihu.com/p/77409613

推荐算法—精排模型DIN/DIEN/SIM/DFN/DCIN - 一分钟666的文章 - 知乎
https://zhuanlan.zhihu.com/p/674125085


```



#### embedding 空间对齐
```

```

#### 特征重要性对齐
```

```

### 召回
```
TDM系列解读-概述 - 星翰的文章 - 知乎
https://zhuanlan.zhihu.com/p/583118370

TDM到二向箔：阿里妈妈展示广告Match底层技术架构演进 - 阿里妈妈<em>技术</em>的文章 - 知乎
https://zhuanlan.zhihu.com/p/443113850

召回概念解释 kv kkv vector
https://help.aliyun.com/zh/airec/be/getting-started/data-specifications?spm=a2c4g.11186623.0.0.40ab6485O50VoV

召回策略打分实践
https://help.aliyun.com/zh/airec/be/use-cases/custom-rough-sort-scores?spm=a2c4g.11186623.0.nextDoc.67e82724ezcZy3


java召回系统代码示例
https://help.aliyun.com/zh/airec/be/developer-reference/quick-start-on-sdks-for-java?spm=a2c4g.11186623.0.0.21bd583bnItklV

```



### 混排 粗排
```


WWW2022｜美团基于强化学习的信息流广告混排算法 - papacai的文章 - 知乎
https://zhuanlan.zhihu.com/p/558087806

阿里定向广告最新突破：面向下一代的粗排排序系统COLD - 萧瑟的文章 - 知乎
https://zhuanlan.zhihu.com/p/186320100

阿里广告技术最新突破：全链路联动-面向最终目标的全链路一致性建模 - 萧瑟的文章 - 知乎
https://zhuanlan.zhihu.com/p/413240790

工业界（搜索 推荐）粗排模型一般怎么做？ - 谢杨易的回答 - 知乎
https://www.zhihu.com/question/441037971/answer/3338246520

召回算法有哪些？ - 余文毅的回答 - 知乎
https://www.zhihu.com/question/423384620/answer/3344167214

OPPO 广告全链路一致性召回算法实践与探索 - 余文毅的文章 - 知乎
https://zhuanlan.zhihu.com/p/675351007


推荐系统多目标优化专题(1)——深入理解推荐系统 - iwtbs的文章 - 知乎
https://zhuanlan.zhihu.com/p/476753154

广告召回论文阅读笔记（2）-从TDM到二向箔 - magicwt的文章 - 知乎
https://zhuanlan.zhihu.com/p/675418752


阿里的TDM树深度模型为什么很少有人用，是有哪些问题吗？ - magicwt的回答 - 知乎
https://www.zhihu.com/question/485938484/answer/3349977619


OPPO 广告召回算法实践与探索 - DataFunTalk的文章 - 知乎
https://zhuanlan.zhihu.com/p/675609025



```

## 统计
```

字节跳动数据挖掘岗面经(杭州) - starfly的文章 - 知乎
https://zhuanlan.zhihu.com/p/518212490



```

### 基础概念
1. 标准误差SE 
2. 置信区间
3. p值：
1. 差值：实验组-对照组数量
2. 变化率：差值/对照组数量
3. T分布，Z分布
4. F检验，卡方检验

### 置信区间
```
如何通俗地解释「置信区间」和「置信水平」？ - 猴子的回答 - 知乎
https://www.zhihu.com/question/24801731/answer/251576717


相爱相杀的置信区间和p值 - 医小咖的文章 - 知乎
https://zhuanlan.zhihu.com/p/32432629


Z检验、T检验下 P-value 和置信区间的计算 - energy百分百的文章 - 知乎
https://zhuanlan.zhihu.com/p/386921569

火山引擎ab实验
https://www.volcengine.com/docs/6287/65818
https://www.volcengine.com/docs/6287/65837

【AB实验统计学】P-value和置信区间 - Effyyy的文章 - 知乎
https://zhuanlan.zhihu.com/p/372485716



```

## 特征 - 样本
1. 近3年关于特征交叉、特征选择的顶会文章集合 - 甲丙寅的文章 - 知乎 https://zhuanlan.zhihu.com/p/694157745
2. 

### SequenceExample
1. 超长序列特征：https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/example.proto
```

```

### FlatBuffer
1. 二进制及FlatBuffer
```

```

### 特征表达式
```

```

### SparseTensor
```

```

### TFRecord
1. spark生成：https://github.com/linkedin/spark-tfrecord
2. spark-tensorflow-connector：https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-connector
3. 扩展能力记录数据位置、实时分发数据、断点续训、底层缓存、多线程拉取等功能
```

```

### 样本分发
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```


## 课程
### 李宏毅ML课程 
```
https://speech.ee.ntu.edu.tw/~hylee/ml/2023-spring.php



```

### Andrej Karpathy课程
```
【【精校珍藏版】大牛Andrej Karpathy的stanford深度学习课程：深入理解Transformer，从零打造最简版GPT】 https://www.bilibili.com/video/BV1Tm4y1b7UP/?share_source=copy_web&vd_source=8783d6f7758784f093c06edba717af3d

大佬的思路
搞清 history of attention
自编码器
隐藏状态加权和


```

### 数据库2021~2023回顾
```
万字带你走过数据库的这激荡的三年 - NebulaGraph的文章 - 知乎
https://zhuanlan.zhihu.com/p/684728712

```
## paper reading
### Actions Speak Louder than Words Trillion-Parameter Sequential Transducers for Generative Recommendations

#### GPT
```
论文介绍
背景与挑战：介绍了大规模推荐系统的背景，包括其对高基数、异构特征的依赖，以及处理数十亿用户日常行为的需求。尽管深度学习推荐模型（DLRMs）在大量数据和特征上进行了训练，但它们在计算扩展性上存在限制。

创新方法：论文提出了一种新架构HSTU（Hierarchical Sequential Transduction Units），它是为了处理高基数、非平稳的流式推荐数据而设计的。HSTU在合成数据集和公共数据集上的性能优于基线模型，并且在序列长度为8192的序列上比基于FlashAttention2的Transformer快5.3倍到15.2倍。

Generative Recommenders (GRs)：提出了一种新的推荐范式，将推荐问题重新定义为生成模型框架内的序列转导任务。GRs通过1.5万亿参数的模型，在在线A/B测试中提高了12.4%的指标，并已部署在拥有数十亿用户的互联网平台上。

模型质量与训练计算的关系：发现生成推荐模型的模型质量与训练计算量之间存在幂律关系，这减少了未来模型开发所需的碳足迹，并为推荐系统中的第一个基础模型铺平了道路。

主要贡献：论文详细介绍了将DLRMs转换为GRs的过程，包括统一DLRMs中的异构特征空间，将排名和检索任务重新定义为GRs中的纯序列转导任务，并提出了一种新的序列转导架构HSTU。

实验验证：通过在合成数据集、公共数据集以及大型互联网平台的多个界面上的部署，验证了所提出技术的 effectiveness。

相关工作：讨论了先前关于序列推荐器的工作，以及高效注意力机制和硬件感知公式的研究。

结论：论文总结了GRs的优势，包括在生产中部署更复杂的模型，以及与传统DLRMs相比的优越扩展性能。同时，强调了用户行为在生成建模中的潜力。

广泛影响：论文讨论了其工作可能带来的积极影响，包括提高推荐、搜索和广告系统的隐私友好性，改善用户体验，以及减少模型研究和开发所需的碳足迹。






DLRMs（Deep Learning Recommendation Models）和GRs（Generative Recommenders）是两种不同类型的推荐系统模型，它们在设计理念、处理方式和应用场景上存在一些关键区别：

设计理念：

DLRMs：这类模型通常依赖于大量的手工特征工程，使用深度学习技术来学习用户和物品之间的复杂交互。它们通常包括多种类型的神经网络组件，如嵌入层、多层感知机（MLPs）、注意力机制等，以处理异构特征并进行最终的推荐。
GRs：生成推荐器将推荐任务视为序列转导问题，并通过生成模型框架来解决。它们将用户的交互历史视为序列，并尝试直接从这些序列中学习并预测下一个可能的交互或推荐内容。这种方法强调了端到端的学习，减少了对特征工程的依赖。
处理方式：

DLRMs：传统DLRMs通常在训练时使用复杂的网络结构来捕捉特征间的交互，并且在推理时可能需要大量的计算资源来处理每个用户的个性化推荐。
GRs：生成推荐器通过统一的特征空间和序列转导任务来简化模型结构。它们使用如HSTU这样的高效编码器来处理长序列数据，并通过生成训练来提高数据利用率和模型效率。
应用场景：

DLRMs：适用于需要精细化特征处理和模型调优的场景，特别是在特征维度高且需要复杂交互建模的情况下。
GRs：更适合于大规模、实时的推荐系统，尤其是在用户交互数据量大、更新频繁的环境中。
性能和效率：

DLRMs：可能在特定场景下提供良好的性能，但随着模型复杂度的增加，它们的扩展性和计算效率可能会受到限制。
GRs：通过端到端的生成方式和高效的序列处理，GRs在处理大规模数据时显示出更好的扩展性和计算效率。
总的来说，GRs代表了一种新的推荐系统范式，它通过生成模型的方法来简化推荐任务，减少了对复杂特征工程的依赖，并且在大规模数据集上显示出了优越的性能和扩展性。




总结论文中的异构特征


在论文 "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations" 中，异构特征（Heterogeneous Features）指的是推荐系统中使用的多种不同类型的数据属性，这些属性可以是数值型的（dense），也可以是类别型的（sparse）。这些特征通常包括但不限于以下几种：

数值特征（Numerical Features）：这些特征通常是连续的数值，例如用户的点击率（CTR）、观看时长、评分等。这些数值型特征可以是加权的、衰减的计数器或比率，它们反映了用户与内容之间的交互强度。

类别特征（Categorical Features）：这些特征是离散的，如用户ID、物品ID、创建者ID、用户所在的社区、用户语言等。这些特征通常用于表示用户或物品的属性，并且在推荐系统中起着至关重要的作用。

用户行为序列：用户的交互历史，如喜欢的物品、关注的创建者、发起请求的城市等，这些序列化的特征在生成推荐模型中被统一处理。

论文中提出的方法将这些异构特征整合到一个统一的时间序列中，以便在生成推荐模型（GRs）中进行处理。这种整合允许模型以一种更加连贯和有效的方式学习特征之间的相互作用，而不是像传统的深度学习推荐模型（DLRMs）那样依赖于复杂的特征工程和多个神经网络组件。

通过这种方式，生成推荐模型能够更好地捕捉用户的长期行为模式，并据此生成个性化的推荐。论文中提出的HSTU（Hierarchical Sequential Transduction Units）架构特别设计了一种新的注意力机制，以适应大规模、非平稳的词汇表和长序列数据，从而提高了模型在处理异构特征时的效率和准确性。




异构特征（Heterogeneous Features）在数据科学和机器学习领域中指的是来自不同来源、类型或格式的特征集合。这些特征可能包括数值型数据（如年龄、温度读数）、类别型数据（如性别、产品类别）、文本数据（如用户评论）、图像数据（如商品图片）等。异构特征的“异构”一词强调了这些特征在本质上的差异性和多样性。

在推荐系统中，异构特征的理解可以从以下几个方面进行：

数据类型多样性：推荐系统可能需要处理各种类型的数据，包括用户的基本资料信息（如年龄、性别）、用户的行为日志（如点击、浏览历史）、用户生成的内容（如评分、评论）以及物品的属性（如商品的类别、品牌）等。

数据来源多样性：特征可能来自不同的数据源，如内部数据库、第三方数据提供商、社交媒体平台等。这些数据源可能提供不同格式和质量的数据。

数据结构多样性：即使在同一类型的数据中，结构也可能有所不同。例如，用户行为日志可能包括时间序列数据（用户在不同时间点的行为），而用户生成的内容可能是非结构化的文本数据。

数据尺度多样性：特征可能具有不同的尺度和范围。例如，用户的年龄可能是一个较小的整数范围，而用户的浏览历史可能是一个非常长的序列。

在处理异构特征时，推荐系统需要采用适当的方法来整合和利用这些多样化的信息。这可能涉及到特征工程（如归一化、编码）、模型设计（如使用多模态神经网络）以及训练策略（如处理不同特征的缺失值和不平衡问题）。

在论文 "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations" 中，作者通过将异构特征整合到一个统一的时间序列中，并使用HSTU架构来处理这些特征，从而简化了模型的复杂性，并提高了处理大规模、非平稳推荐数据的效率。这种方法允许模型在生成推荐时更好地捕捉和利用异构特征中的信息。


```

#### 论文结构拆解
1. 优化目标是什么
   1. From DLRMs to GRs，从深度推荐模型转向生成式推荐
   2. 设计新架构HSTU优化高基数、非平稳的流式数据的推荐场景
2. 业务场景来源和灵感
   1. 灵感：Actions speak louder than words 事实胜于雄辩
3. 如何实验验证呢
   1. 数据集：NDCG
   2. 
   3. 
4. 运用技术和细节
   1. 支持8k长度序列输入
   2. 5.3x-15.2x faster than state-of-the art Transformers
   3. M-FALCON 新算法
   4. 异构特征的处理
5. 关键语句
   1. We reformulate recommendation problems as sequential transduction tasks within a generative modeling framework
   2. propose a new architecture, HSTU, designed for high cardinality,non-stationary streaming recommendation data.
   3.  a unified feature space to be used across domains 一个统一的特征空间跨域使用
6. 概念扫盲
   1. 序列转导任务（Sequential Transduction Tasks）是一种自然语言处理（NLP）中的序列建模方法，它涉及到将输入序列转换为输出序列的过程。这种任务通常在生成模型中出现，其中模型需要基于给定的输入序列生成一个新的序列，而不是简单地分类或回归。
   2. 

#### GR复现
```
论文
https://github.com/facebookresearch/generative-recommenders?tab=readme-ov-file

apt install -y python3.8
apt install -y python3-pip
pip3 install gin-config absl-py scikit-learn scipy matplotlib numpy apex hypothesis pandas fbgemm_gpu iopath -i https://mirrors.aliyun.com/pypi/simple

构建时序样本
mkdir -p tmp/ && python3 preprocess_public_data.py

movielens_seq_features_from_row
historical_lengths 是历史序列的长度，形状为 [B]，其中 B 是批次大小。
historical_ids 是历史序列的项目标识符，形状为 [B, N]，其中 N 是历史序列的最大长度。
historical_ratings 是历史序列的评分，形状与 historical_ids 相同。
historical_timestamps 是历史序列的时间戳，形状与 historical_ids 相同。
target_ids 是目标项目的标识符，形状为 [B, 1]。
target_ratings 是目标项目的评分，形状与 target_ids 相同。
target_timestamps 是目标项目的时间戳，形状与 target_ids 相同。

用户
item_embedding_dim 商品/电影/书籍/广告
获取item向量
获取点击或者mol相似函数

用户向量 user_embedding_norm l2_norm

L2NormEmbeddingPostprocessor
LearnablePositionalEmbeddingInputFeaturesPreprocessor
添加可学习的位置嵌入，适应给定的序列长度和嵌入维度。

get_sequential_encoder
函数 get_sequential_encoder 是一个自定义函数，用于创建一个序列编码器模型。
module_type 是模型的类型，main_module 是一个变量，用于指定模型的具体类型。
max_sequence_length 是输入序列的最大长度。
max_output_length 是输出序列的最大长度，这里加1是因为模型的输出会比输入多一个时间步。
embedding_module 是用于将输入序列进行嵌入的模块。
interaction_module 是用于对嵌入后的序列进行交互的模块。
input_preproc_module 是用于对输入序列进行预处理的模块。
output_postproc_module 是用于对输出序列进行后处理的模块。
verbose=True 表示在创建模型时打印详细信息。
model.debug_str() 是模型的调试方法，返回模型的详细信息的字符串表示。



损失函数
SampledSoftmaxLoss
InBatchNegativesSampler



Module
RelativeAttentionBiasModule
RelativePositionalBias

RelativeAttentionBiasModule
RelativeBucketedTimeAndPositionBasedBias

SequentialTransductionUnitJagged

why
HSTUCacheState = Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]


```
### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

## 思考题
```

```

### embedding维数越多越好吗
```
为什么Transformer 需要进行 Multi-head Attention？ - 取个好名字真难的回答 - 知乎
https://www.zhihu.com/question/341222779/answer/3476103514

GPT-3 的embedding维数是12288。线性代数告诉我们，当空间维数非常非常大时，向量都非常分散——整个空间太大了，很难得到两个非常靠近的向量。

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

## 图可视化
```
dolphinscheduler
wget https://dlcdn.apache.org/dolphinscheduler/3.2.1/apache-dolphinscheduler-3.2.1-bin.tar.gz

安装介绍
https://dolphinscheduler.apache.org/zh-cn/docs/3.2.1/guide/installation/standalone

tar -xvzf apache-dolphinscheduler-*-bin.tar.gz
chmod -R 755 apache-dolphinscheduler-*-bin
cd apache-dolphinscheduler-*-bin
bash ./bin/dolphinscheduler-daemon.sh start standalone-server

默认的用户名和密码是 admin/dolphinscheduler123


搜索dag接口
https://dataverse.search.sankuai.com/kuggetPlatform/dag/handle


阿里云开源组件 小蝴蝶
http://10.216.241.123:5080/
https://github.com/aliyun/react-lineage-dag
https://github.com/alibaba/butterfly/blob/master/README.md


sql助手
http://doc.sqlzhushou.com/quick-start/support
https://github.com/youqiang95/DAG-SQL-Builder



```
## 环境

bml
1. 限制paddle
2. 第三方包下载总是有问题
魔塔
1. 限制魔塔包
macbook
1. gpu有限制
ubuntu20
1. 版本均OK
ubuntu18
1. git版本低
2. python低

并行计算
1. 多线程
2. 多进程




## 从0到1安装
```bash
ubuntu
apt-get update
apt install sudo -y
# programm
apt install -y gcc-9 g++-9

alias gcc=/usr/bin/gcc-9
alias g++=/usr/bin/g++-9

# golang 1.20版本
wget https://mirrors.ustc.edu.cn/golang/go1.21.0.linux-amd64.tar.gz
tar -zxvf go1.21.0.linux-amd64.tar.gz
rm -rf /usr/local/go && tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz
rm -rf /usr/bin/go && tar -C /usr/bin -xzf go1.21.0.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
go version
go env -w GO111MODULE=on
go env -w GOPROXY=https://goproxy.cn,direct

# pg库
apt-get install libpq-dev -y
apt install postgresql -y

# 创建库表 - 业务操作
# service postgresql start
# sudo -u postgres psql
# CREATE USER dbusername WITH PASSWORD 'dbpassword';
# CREATE DATABASE db;


# python3
apt install -y python3.8
apt install -y python3-pip
alias pip=pip3
alias python=python3
# openGL库
apt-get install -y libgl1-mesa-glx
# 进度条库
pip3 install tqdm   
# sql
pip3 install SQLAlchemy==1.4.23 -i https://mirrors.aliyun.com/pypi/simple
pip3 install psycopg2 


# cuda安装
wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda_12.4.1_550.54.15_linux.run
sudo sh cuda_12.4.1_550.54.15_linux.run


# pytorch
pip3 install torch torchvision -i https://mirrors.aliyun.com/pypi/simple

pip3 install graphviz -i https://mirrors.aliyun.com/pypi/simple

# huggingface
pip3 install setuptools_rust
pip3 install transformers

# juypter
pip3 install setuptools_scm
pip3 install argon2-cffi-bindings
pip3 install jupyter



# paddlepaddle 全家桶
pip3 install paddlepaddle==2.5.1 -i https://mirrors.aliyun.com/pypi/simple
pip3 install paddleocr
pip3 install visualdl==2.4.0  
pip3 install flask-babel==1.0.0
pip3 install paddlenlp -i https://mirrors.aliyun.com/pypi/simple

# pdf工具
pip3 install pdf2image
pip3 install gradio
pip3 install pdfplumber   

pip3 install langchain
# embedding
pip3 install fastNLP  
pip3 install fuzzywuzzy
python3 -m pip install milvus
pip3 install jieba

# modelscope
pip3 install numpy pandas urllib3
pip3 install datasets==2.13.0
pip3 install dill==0.3.6
pip3 install multiprocess==0.70.14
pip3 install accelerate -U
pip3 install sentencepiece -U
pip3 install modelscope -U 

# 打包当前环境
pip3 freeze > requirements.txt



# 业务逻辑
# llm_demo服务
dir=`pwd`
export PYTHONPATH=$PYTHONPATH:$dir
export PYTHONPATH=$PYTHONPATH:/mnt/workspace

# 写入数据
cd /mnt/workspace/llm_demo/util
python3 insert_balance_sheet.py
python3 insert_cash_flow.py
python3 insert_company_annual_reports.py
python3 insert_profit_statement.py

mv /etc/dsw/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /etc/dsw/lib/libffi.so.8 /mnt/workspace/libffi/.
mv /opt/conda/lib/libffi.so.8 /mnt/workspace/libffi/.
mv /opt/conda/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /opt/conda/pkgs/libffi-3.4.2-h6a678d5_6/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /opt/conda/pkgs/libffi-3.4.2-h6a678d5_6/lib/libffi.so.8 /mnt/workspace/libffi/.


cp /mnt/workspace/libffi/libffi.so.8 /opt/conda/lib/libffi.so.8 



```

## 包编译
### 全局配置
cur_dir=/docker/root/projects/demo/package
export PATH="$cur_dir/cmake-3.24.0-linux-x86_64/bin:$PATH"
export PATH="$cur_dir/lib:$cur_dir/bin:$PATH"

### 拼表3.16.0
export PATH=$cur_dir/protobuf/build_source/installed_protobuf_lib/bin:${PATH}



### cmake
wget https://cmake.org/files/v3.24/cmake-3.24.0-linux-x86_64.tar.gz
tar xf cmake-3.24.0-linux-x86_64.tar.gz
export PATH=$cur_dir/include:$cur_dir/bin:$cur_dir/cmake-3.24.0-linux-x86_64/bin:/root/.nvm/versions/node/v14.17.2/bin:/root/.nvm/versions/node/v14.17.2/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
export LD_LIBRARY_PATH=/usr/local/lib
export LIBRARY_PATH=/usr/local/lib:$cur_dir/lib:$cur_dir/include
export LAPACK_LIBRARIES=/usr/local/lib


### python3.9.7
```shell
cur_dir=/docker/root/projects/demo/package

cd $cur_dir
https://www.python.org/ftp/python/3.9.7/Python-3.9.7.tar.xz
tar -xf Python-3.9.7.tar.xz

cd Python-3.9.7
./configure --prefix=$cur_dir/python3.9
make
make install

export PATH="$cur_dir/python3.9/bin:$PATH"


```

### 基础库
```
# gfortran
apt-get install gfortran -y

# libsndfile
apt-get install libsndfile1 -y

# OpenBLAS
apt-get install build-essential -y
git clone https://github.com/xianyi/OpenBLAS.git
cd OpenBLAS
# x86_64
make TARGET=NEHALEM
make
make PREFIX=$cur_dir install


# LAPACK
# 参考 https://blog.csdn.net/dante0610/article/details/113853805
apt-get install libscalapack-mpi-dev -y
apt-get install liblapack-dev -y

wget http://www.netlib.org/lapack/lapack-3.4.2.tgz
tar -xvf lapack-3.4.2.tgz
cd lapack-3.4.2
mkdir build
cd build
cmake ..
make -j4
make PREFIX=$cur_dir install

# gTest
git clone --depth 1 https://github.com/google/googletest.git
cd googletest
mkdir build && cd build
cmake ..
make -j40
make PREFIX=$cur_dir install

```

### faiss
/docker/root/projects/demo/package/lib/libopenblas.a

cmake -B build -DLAPACK_LIBRARIES=/usr/local/lib/liblapack.a -DBLAS_LIBRARIES=$cur_dir/lib/libopenblas.a  -DFAISS_ENABLE_GPU=OFF .
make -C build clean && make -C build -j40 && make -C build PREFIX=$cur_dir install

cmake -B build -DLAPACK_LIBRARIES=/usr/lib/x86_64-linux-gnu/lapack -DBLAS_LIBRARIES=$cur_dir/lib  -DFAISS_ENABLE_GPU=OFF -DBUILD_SHARED_LIBS=ON .


cd build
make -j40
make PREFIX=$cur_dir install

### puck


### starrocks

### juypter安装
1. https://fancyerii.github.io/2022/10/19/docker-jupyter/#%E5%9C%A8%E9%95%9C%E5%83%8F%E9%87%8C%E5%AE%89%E8%A3%85juypter-notebook
```
pip install notebook
pip install ipywidgets

启动juypter服务
jupyter notebook --ip=0.0.0.0 --port=3344 --no-browser --allow-root

vscode 选择这个服务链接即可
copy and paste one of these URLs:
hhttp://MagnetoWang:3344/treetoken=069128991cdb486b1a9a0d8b582821432951dcbfc2baeba9
        
http://127.0.0.1:3344/tree?token=069128991cdb486b1a9a0d8b582821432951dcbfc2baeba9

```


### pytorch源码安装
```bash


# g++安装
apt-get update
apt install sudo -y
# programm
apt install -y gcc-9 g++-9
apt install openssl libssl-dev
apt install -y build-essential
apt-get install -y patchelf
# python安装
apt install -y python3.8
apt install -y python3-pip
apt install -y python3.9-dev
pip install --upgrade pip
pip install --upgrade setuptools


# cmake安装
# 略

# 安装conda
wget https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh

# 自动化安装
sh Anaconda3-2023.09-0-Linux-x86_64.sh -b -u
# 国内镜像源
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
conda config --set show_channel_urls yes

conda install -c https://mirrors.aliyun.com/anaconda/ intel::mkl-static intel::mkl-include -y
# CUDA only: Add LAPACK support for the GPU if needed
conda install -c pytorch magma-cuda110  # or the magma-cuda* that matches your CUDA version from https://anaconda.org/pytorch/repo


alias pip=pip3
alias python=python3
alias gcc=/usr/bin/gcc
alias g++=/usr/bin/g++
# gcc 路径会在pytorch中被用到
mv /usr/bin/gcc-9 /usr/bin/gcc
mv /usr/bin/g++-9 /usr/bin/g++
export PATH="/root/anaconda3/bin:$PATH"

# cmake 配置 指定编译器
export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-"$(dirname $(which conda))/../"}
export CMAKE_C_COMPILER=/usr/bin/gcc
export CMAKE_CXX_COMPILER=/usr/bin/g++




# Ninja 生成代码需要指定路径 手动修改
# export CMAKE_BUILD_WITH_INSTALL_RPATH=ON
# set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE)


# 安装第三方依赖，只能用pip
# conda install --file requirements.txt
conda install -c https://mirrors.aliyun.com/anaconda/ cmake ninja -y
conda install cmake ninja -y
pip install -i https://mirrors.aliyun.com/pypi/simple pyqt5==5.15
pip install -i https://mirrors.aliyun.com/pypi/simple pyqtwebengine==5.15
pip install -i https://mirrors.aliyun.com/pypi/simple -r requirements.txt



# 代码依赖下载
git clone --recursive https://github.com/pytorch/pytorch
cd pytorch
git submodule sync
git submodule update --init --recursive

# 国内访问限制问题，需要手动clone
cd third_party

## https://gitclone.com/github.com/xxx 可以加速 git submodule
# 参考
# https://github.com/NVlabs/cub.git 改成下面
# https://gitclone.com/github.com/NVlabs/cub.git
rm -rf ios-cmake
git clone https://521github.com/Yangqing/ios-cmake.git

rm -rf psimd
git clone https://521github.com/Maratyszcza/psimd.git


rm -rf QNNPACK
git clone https://521github.com/pytorch/QNNPACK

rm -rf foxi
git clone https://521github.com/houseroad/foxi.git
cd ..




# (optional) If using torch.compile with inductor/triton, install the matching version of triton
# Run from the pytorch directory after cloning
make triton

export MAX_JOBS=4
python setup.py develop > build.log



```

### python直接安装
```
pip install torchvision


```

### pytorch配置
```
https://mirror.tuna.tsinghua.edu.cn/help/anaconda/

先执行 conda config --set show_channel_urls yes 生成该文件之后再修改

channels:
  - defaults
show_channel_urls: true
default_channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
custom_channels:
  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/


```

### pytorch submodule修改
```
[submodule "third_party/pybind11"]
    ignore = dirty
    path = third_party/pybind11
    url = https://gitclone.com/github.com/pybind/pybind11.git
[submodule "third_party/cub"]
    ignore = dirty
    path = third_party/cub
    url = https://gitclone.com/github.com/NVlabs/cub.git
[submodule "third_party/eigen"]
    ignore = dirty
    path = third_party/eigen
    url = https://gitlab.com/libeigen/eigen.git
[submodule "third_party/googletest"]
    ignore = dirty
    path = third_party/googletest
    url = https://gitclone.com/github.com/google/googletest.git
[submodule "third_party/benchmark"]
    ignore = dirty
    path = third_party/benchmark
    url = https://gitclone.com/github.com/google/benchmark.git
[submodule "third_party/protobuf"]
    ignore = dirty
    path = third_party/protobuf
    url = https://gitclone.com/github.com/protocolbuffers/protobuf.git
[submodule "third_party/ios-cmake"]
    ignore = dirty
    path = third_party/ios-cmake
    url = https://gitclone.com/github.com/Yangqing/ios-cmake.git
[submodule "third_party/NNPACK"]
    ignore = dirty
    path = third_party/NNPACK
    url = https://gitclone.com/github.com/Maratyszcza/NNPACK.git
[submodule "third_party/gloo"]
    ignore = dirty
    path = third_party/gloo
    url = https://gitclone.com/github.com/facebookincubator/gloo
[submodule "third_party/NNPACK_deps/pthreadpool"]
    ignore = dirty
    path = third_party/pthreadpool
    url = https://gitclone.com/github.com/Maratyszcza/pthreadpool.git
[submodule "third_party/NNPACK_deps/FXdiv"]
    ignore = dirty
    path = third_party/FXdiv
    url = https://gitclone.com/github.com/Maratyszcza/FXdiv.git
[submodule "third_party/NNPACK_deps/FP16"]
    ignore = dirty
    path = third_party/FP16
    url = https://gitclone.com/github.com/Maratyszcza/FP16.git
[submodule "third_party/NNPACK_deps/psimd"]
    ignore = dirty
    path = third_party/psimd
    url = https://gitclone.com/github.com/Maratyszcza/psimd.git
[submodule "third_party/zstd"]
    ignore = dirty
    path = third_party/zstd
    url = https://gitclone.com/github.com/facebook/zstd.git
[submodule "third_party/cpuinfo"]
    ignore = dirty
    path = third_party/cpuinfo
    url = https://gitclone.com/github.com/pytorch/cpuinfo.git
[submodule "third_party/python-peachpy"]
    ignore = dirty
    path = third_party/python-peachpy
    url = https://gitclone.com/github.com/malfet/PeachPy.git
[submodule "third_party/onnx"]
    ignore = dirty
    path = third_party/onnx
    url = https://gitclone.com/github.com/onnx/onnx.git
[submodule "third_party/onnx-tensorrt"]
    ignore = dirty
    path = third_party/onnx-tensorrt
    url = https://gitclone.com/github.com/onnx/onnx-tensorrt
[submodule "third_party/sleef"]
    ignore = dirty
    path = third_party/sleef
    url = https://gitclone.com/github.com/shibatch/sleef
[submodule "third_party/ideep"]
    ignore = dirty
    path = third_party/ideep
    url = https://gitclone.com/github.com/intel/ideep
[submodule "third_party/nccl/nccl"]
    ignore = dirty
    path = third_party/nccl/nccl
    url = https://gitclone.com/github.com/NVIDIA/nccl
[submodule "third_party/gemmlowp/gemmlowp"]
    ignore = dirty
    path = third_party/gemmlowp/gemmlowp
    url = https://gitclone.com/github.com/google/gemmlowp.git
[submodule "third_party/QNNPACK"]
    ignore = dirty
    path = third_party/QNNPACK
    url = https://gitclone.com/github.com/pytorch/QNNPACK
[submodule "third_party/neon2sse"]
    ignore = dirty
    path = third_party/neon2sse
    url = https://gitclone.com/github.com/intel/ARM_NEON_2_x86_SSE.git
[submodule "third_party/fbgemm"]
    ignore = dirty
    path = third_party/fbgemm
    url = https://gitclone.com/github.com/pytorch/fbgemm
[submodule "third_party/foxi"]
    ignore = dirty
    path = third_party/foxi
    url = https://gitclone.com/github.com/houseroad/foxi.git
[submodule "third_party/tbb"]
    path = third_party/tbb
    url = https://gitclone.com/github.com/01org/tbb
    branch = tbb_2018
[submodule "android/libs/fbjni"]
    ignore = dirty
    path = android/libs/fbjni
    url = https://gitclone.com/github.com/facebookincubator/fbjni.git
[submodule "third_party/XNNPACK"]
    ignore = dirty
    path = third_party/XNNPACK
    url = https://gitclone.com/github.com/google/XNNPACK.git
[submodule "third_party/fmt"]
    ignore = dirty
    path = third_party/fmt
    url = https://gitclone.com/github.com/fmtlib/fmt.git
[submodule "third_party/tensorpipe"]
    ignore = dirty
    path = third_party/tensorpipe
    url = https://gitclone.com/github.com/pytorch/tensorpipe.git
[submodule "third_party/cudnn_frontend"]
	path = third_party/cudnn_frontend
	url = https://gitclone.com/github.com/NVIDIA/cudnn-frontend.git
[submodule "third_party/kineto"]
    path = third_party/kineto
    url = https://gitclone.com/github.com/pytorch/kineto
[submodule "third_party/pocketfft"]
	path = third_party/pocketfft
	url = https://gitclone.com/github.com/mreineck/pocketfft
[submodule "third_party/ittapi"]
	path = third_party/ittapi
	url = https://gitclone.com/github.com/intel/ittapi.git
[submodule "third_party/flatbuffers"]
	path = third_party/flatbuffers
	url = https://gitclone.com/github.com/google/flatbuffers.git
[submodule "third_party/nlohmann"]
	path = third_party/nlohmann
	url = https://gitclone.com/github.com/nlohmann/json.git
[submodule "third_party/VulkanMemoryAllocator"]
	path = third_party/VulkanMemoryAllocator
	url = https://gitclone.com/github.com/GPUOpen-LibrariesAndSDKs/VulkanMemoryAllocator.git
[submodule "third_party/cutlass"]
	path = third_party/cutlass
	url = https://gitclone.com/github.com/NVIDIA/cutlass.git
[submodule "third_party/mimalloc"]
	path = third_party/mimalloc
	url = https://gitclone.com/github.com/microsoft/mimalloc.git


```
### pytorch-tune微调工具
```
PyTorch官方发布LLM微调工具TorchTune - 小小将的文章 - 知乎
https://zhuanlan.zhihu.com/p/688671130
```

### paddle源码安装
```shell
全局环境
apt-get update
apt install sudo -y
# programm
apt install -y gcc-9 g++-9

# 编译工具
apt install -y build-essential
apt-get install -y libffi-dev
apt-get install -y patchelf
apt install clang clangd lldb ccache -y

# python包
apt install -y python3.9
apt install -y python3.9-dev
apt install -y python3-pip
pip install --upgrade pip


cur_dir=/docker/root/projects/demo/package
export PATH="$cur_dir/cmake-3.24.0-linux-x86_64/bin:$PATH"
export PATH="$cur_dir/lib:$cur_dir/bin:$PATH"

git clone https://github.com/PaddlePaddle/Paddle.git
cd Paddle
git checkout 20ee0d7fbfb0034e37d86ceef7dd11059e5d3fad


pip install -t /usr/lib/python3.9/dist-packages/  -i https://mirrors.aliyun.com/pypi/simple  -r python/requirements.txt
pip install -i https://mirrors.aliyun.com/pypi/simple numpy
pip install -i https://mirrors.aliyun.com/pypi/simple protobuf
pip install -i https://mirrors.aliyun.com/pypi/simple pyyaml

mkdir build && cd build
cmake .. -DPY_VERSION=3.8 -DWITH_GPU=OFF -DWITH_TESTING=ON -DCMAKE_EXPORT_COMPILE_COMMANDS=1
# 后台编译
make -j10 > paddle_compile_v1.log &

# 加速编译过程
ccache cmake .. -DPY_VERSION=3.8 -DWITH_GPU=OFF -DWITH_TESTING=ON -DCMAKE_EXPORT_COMPILE_COMMANDS=1
ccache make -j10 > paddle.log & 

查看python lib
python3 -c "import distutils.sysconfig as sysconfig; print(sysconfig.get_config_var('LIBDIR'))"


查看python include
python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())" 


linux 镜像安装
https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/install/compile/linux-compile-by-make.html
docker pull registry.baidubce.com/paddlepaddle/paddle:latest-dev
docker pull registry.baidubce.com/paddlepaddle/paddle:latest-dev-cuda12.0-cudnn8.9-trt8.6-gcc12.2

docker pull paddlepaddle/paddle:latest-dev
docker pull paddlepaddle/paddle:latest-dev-cuda12.0-cudnn8.9-trt8.6-gcc12.2

docker run --name paddle-test -v $PWD:/paddle --network=host -it registry.baidubce.com/paddlepaddle/paddle:latest-dev /bin/bash


```
### paddle虚拟环境
```
HOME=~
export PYENV_ROOT="$HOME/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"
export PYTHON_BUILD_MIRROR_URL="https://npm.taobao.org/mirrors/python/"
alias python=python3
alias pip=pip3



安装和激活
git clone https://gitee.com/mirrors/pyenv.git ~/.pyenv
git clone https://github.com/pyenv/pyenv-virtualenv.git  ~/.pyenv/plugins/pyenv-virtualenv


pyenv install 3.9
pyenv virtualenv 3.9.19 env39
pyenv local env39

```
### paddle ci
```
https://www.paddlepaddle.org.cn/documentation/docs/zh/develop/dev_guides/git_guides/paddle_ci_manual_cn.html

```

### paddle编译问题
```
找不到PYTHON_LIBRARIES PYTHON_INCLUDE_DIRS
解决：apt install -y python3.9-dev


cmake .. -DPY_VERSION=3.9 -DPYTHON_LIBRARIES=/usr/lib/python3.9  -DPYTHON_INCLUDE_DIRS=/usr/include/python3.8 -DWITH_GPU=OFF -DWITH_TESTING=ON

-- Found PythonInterp: /usr/bin/python3.9 (found suitable version "3.9.5", minimum required is "3.9") 
CMake Error at /docker/root/projects/demo/package/cmake-3.24.0-linux-x86_64/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:230 (message):
  Could NOT find PythonLibs (missing: PYTHON_LIBRARIES PYTHON_INCLUDE_DIRS)
  (Required is at least version "3.9")
Call Stack (most recent call first):
  /docker/root/projects/demo/package/cmake-3.24.0-linux-x86_64/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE)
  /docker/root/projects/demo/package/cmake-3.24.0-linux-x86_64/share/cmake-3.24/Modules/FindPythonLibs.cmake:310 (FIND_PACKAGE_HANDLE_STANDARD_ARGS)
  cmake/external/python.cmake:21 (find_package)
  cmake/third_party.cmake:305 (include)
  CMakeLists.txt:604 (include)


-- Configuring incomplete, errors occurred!
See also "/docker/root/projects/demo/github/Paddle/build/CMakeFiles/CMakeOutput.log".
See also "/docker/root/projects/demo/github/Paddle/build/CMakeFiles/CMakeError.log".
make: *** No targets specified and no makefile found.  Stop.



找不到numpy，其实已经安装了，只是cmake文件用的python解释器有问题，不够兼容
修改 python_module.cmake
"${PYTHON_EXECUTABLE}" "-c" 
改成 python3 
 execute_process(
      COMMAND
        "python3" "-c"
        "import re, ${module}; print(re.compile('/__init__.py.*').sub('',${module}.__file__))"
      RESULT_VARIABLE _${module}_status
      OUTPUT_VARIABLE _${module}_location
      ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE)


解决：
pip3 install --upgrade --force-reinstall -i https://mirrors.aliyun.com/pypi/simple  numpy

-t /usr/lib/python3.9/dist-packages

-- Could NOT find PY_numpy (missing: PY_NUMPY) 
CMake Error at cmake/python_module.cmake:29 (message):
  python module numpy is not found
Call Stack (most recent call first):
  cmake/external/python.cmake:73 (find_python_module)
  cmake/third_party.cmake:305 (include)
  CMakeLists.txt:604 (include)



同理修改FindNumPy.cmake
 "${PYTHON_EXECUTABLE}" ${PROJECT_BINARY_DIR}
 为
 "python3" ${PROJECT_BINARY_DIR}


CMake Error at /docker/root/projects/demo/package/cmake-3.24.0-linux-x86_64/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:230 (message):
  Could NOT find NumPy (missing: PYTHON_NUMPY_INCLUDE_DIR)
Call Stack (most recent call first):
  /docker/root/projects/demo/package/cmake-3.24.0-linux-x86_64/share/cmake-3.24/Modules/FindPackageHandleStandardArgs.cmake:594 (_FPHSA_FAILURE_MESSAGE)
  cmake/FindNumPy.cmake:41 (find_package_handle_standard_args)
  cmake/external/python.cmake:77 (find_package)
  cmake/third_party.cmake:305 (include)
  CMakeLists.txt:604 (include)

```

