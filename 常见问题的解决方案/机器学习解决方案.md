## 框架安装
```
初学者建议统一安装cpu版本

安装pytorch
http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/#21-%E5%AE%89%E8%A3%85-pytorch

pip3 install torch torchvision -i https://pypi.mirrors.ustc.edu.cn/simple # 用国内源
pip3 install graphviz -i https://pypi.mirrors.ustc.edu.cn/simple


安装paddlepaddle全家桶
pip3 install paddlepaddle==2.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple    
pip3 install paddleocr
```

### 前置安装
```bash
apt install python3.9
apt install python3-pip
# openGL库
apt-get install libgl1-mesa-glx


```

### transformers 安装
```bash
安装rust
curl https://sh.rustup.rs -sSf | sh
# rust生效
source "$HOME/.cargo/env"

pip3 install setuptools_rust
pip3 install transformers

```

### juypter 安装
```
pip install --upgrade pip
pip3 install --upgrade pip
pip3 install --upgrade pip3

pip3 install setuptools_scm
pip3 install argon2-cffi-bindings
pip3 install jupyter

```

### 镜像安装
```
阿里云
https://cr.console.aliyun.com/cn-shanghai/instances/artifact

cpu
docker pull dsw-registry.cn-hangzhou.cr.aliyuncs.com/pai/pytorch:1.8-cpu-py36-ubuntu18.04

gpu
dsw-registry.cn-hangzhou.cr.aliyuncs.com/pai/pytorch:1.8PAI-gpu-py36-cu101-ubuntu18.04

sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 100 --slave /usr/bin/g++ g++ /usr/bin/g++-9


```

## 工具向
### 翻译工具
```
训练Transformer 模型将 中文翻译成英语：https://zhuanlan.zhihu.com/p/469388563

```

## 数据处理
```
paddle：https://paddlenlp.readthedocs.io/zh/latest/data_prepare/data_preprocess.html



```





## Embedding
### 介绍
```
向量检索引擎：https://zhuanlan.zhihu.com/p/364923722
IndexFlatL2（基于欧氏距离的暴力索引）
IndexIVFFlat（加聚类的倒排索引，支持欧式距离和向量内积两种距离算法）
IndexIVFPQ（加聚类、加量化的倒排索引）

开源项目
facebook：https://github.com/facebookresearch/faiss
阿里：https://github.com/alibaba/proxima

手把手搭建一个语义检索系统：https://github.com/PaddlePaddle/PaddleNLP/tree/develop/applications/neural_search



```
### 模型和工业实践
```


```
### 标签 转 embedding
```


```

### 数值 转 embedding
```


```
### 文字 转 embedding
```


```
### 数学公式 转 embedding
```


```
### pdf 转 embedding
```
pdf文本加载
https://zhuanlan.zhihu.com/p/644938147

paddleOCR解析文本：https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart.md



安装ocr工具
yum install mupdf-devel


paddleocr --image_dir=/home/aistudio/data/pdf/IETS13_A.pdf --type=structure --recovery=true --use_pdf2docx_api=true

paddleocr --image_dir=/home/aistudio/data/pdf/IETS13_A.pdf --type=structure --recovery=true --lang='en'

paddleocr --image_dir=/home/aistudio/data/pdf/MOBIUS\ Towards\ the\ Next\ Generation\ of\ Query-Ad\ Matching\ in\ Baidu\ Sponsored\ Search.pdf --type=structure --recovery=true --lang='en'



```
### 图片 转 embedding
```


```
### 语音 转 embedding
```


```

### 语音
```bash
https://aistudio.baidu.com/aistudio/projectdetail/4353348?sUid=2470186&shared=1&ts=1660878142250

# 前置依赖
apt-get install libsndfile1 -y
apt-get install ffmpeg -y

# 新增speech环境
git clone https://gitee.com/mirrors/pyenv.git ~/.pyenv
export PYTHON_BUILD_MIRROR_URL="https://npm.taobao.org/mirrors/python/"
export HOME=~
export PYENV_ROOT="$HOME/.pyenv"
export PATH="$PYENV_ROOT/bin:$PATH"

pyenv virtualenv 3.8.10 speech 
pyenv activate speech
source speech/bin/activate
pip3 install paddlepaddle==2.4.2
pip3 install paddlespeech
pip3 install paddlespeech_ctcdecoders
# mp3 to wav 格式
pip3 install pydub

# 退出
pyenv deactivate


paddlespeech asr --lang zh --input /docker/root/projects/demo/data/mp4/剑4真题听力/test1/test1_section1.wav


```

## GPT
### 制作一个BadyGpt
```
参考文档：http://arthurchiao.art/blog/gpt-as-a-finite-state-markov-chain-zh/#21-%E5%AE%89%E8%A3%85-pytorch

langchain方式
https://github.com/chatchat-space/langchain-ChatGLM

```

### chatGLM
```
https://github.com/RonaldJEN/FinanceChatGLM.git



比赛
官网论坛：https://tianchi.aliyun.com/competition/entrance/532126/forum
全训练过程：https://tianchi.aliyun.com/forum/post/573555
数据集：https://modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset/summary?spm=a2c22.21852664.0.0.68171434jkTm0x
baseline代码：https://github.com/RonaldJEN/FinanceChatGLM/
参赛笔记：https://tianchi.aliyun.com/forum/post/571708
基于paddlepaddle的chatglm推理实现代码：https://tianchi.aliyun.com/forum/post/572601

微调模型：https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning
paddle结合GLM：https://aistudio.baidu.com/aistudio/projectdetail/6195067
动手搭建一套端到端文本语义检索系统：https://aistudio.baidu.com/projectdetail/3351784

思路 
gpt生成关键词 prompt 区分文本分析 数学计算
先测试分类效果 
请将下述问题区分为搜索信息类，计算数值类，总结陈述类

关键词语义搜索找到相关pdf paddle语义召回
5000行构建花了10分钟 cpu

pdf识别语义



解析pdf逻辑参考
Traceback (most recent call last):
  File "paddle_model.py", line 16, in <module>
    pprint(docprompt([{"doc": pdf_path, "prompt": ["财报利润率多少",  "住宅投资是多少?"]}]))
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/taskflow.py", line 850, in __call__
    results = self.task_instance(inputs)
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/task.py", line 515, in __call__
    inputs = self._preprocess(*args)
  File "/usr/local/lib/python3.8/dist-packages/paddlenlp/taskflow/document_intelligence.py", line 90, in _preprocess
    ocr_result = self._ocr.ocr(example["doc"], cls=True)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py", line 637, in ocr
    img = check_img(img)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/paddleocr.py", line 527, in check_img
    img, flag_gif, flag_pdf = check_and_read(image_file)
  File "/usr/local/lib/python3.8/dist-packages/paddleocr/ppocr/utils/utility.py", line 96, in check_and_read
    for pg in range(0, pdf.pageCount):


下载模型和数据集
参考链接：https://tianchi.aliyun.com/forum/post/573555
pip3 install datasets==2.13.0
pip3 install dill==0.3.6
pip3 install multiprocess==0.70.14
pip3 install numpy pandas urllib3
pip3 install torch
pip3 install transformers -U
pip3 install accelerate -U
pip3 install sentencepiece -U
pip3 install torch torchvision -U
pip3 install modelscope -U 

打包当前环境
pip3 freeze > requirements.txt

数据集
git clone http://www.modelscope.cn/datasets/modelscope/chatglm_llm_fintech_raw_dataset.git

异常
RuntimeError: "addmm_impl_cpu_" not implemented for 'Half'
原因
机器没有gpu，需要配置只跑cpu。加参数 trust_remote_code=True
model = Model.from_pretrained('ZhipuAI/chatglm2-6b', low_cpu_mem_usage=False, trust_remote_code=True, revision='v1.0.7')



export PYTHONPATH=$PYTHONPATH:/docker/root/projects/demo/project/chatglm/baseline_demo/FinanceChatGLM

总结
大模型现阶段一些问题和优势
问题：
模型需要的资源太多了，响应慢，开发慢。这些都是成本
模型对数据质量要求很高，不然基本不可用
输出结果不可控
不适合做大数据计算
不适合做搜索引擎

优势
在提供足量的正确的数据，能融合数据，并生成可看的结果

大模型 + 向量 + 搜索 + 大数据
数据存储成本
索引构建成本
向量生成成本
大模型运行成本
每一个成本都很高
而且pipeline很长
数据同步延迟高，排查问题慢，同时依赖没有简化现有的软件开发模式，反而新增一个链路

我理想中认为的大模型
存储所有的大数据内容，完成端到端的数据链路更新

实际中，因为大模型的成本问题
大模型应该需要具备推理和分析能力，来代替人，生成sql，生成代码。然后提交执行命令
完成一系列自动化机器运维，软件开发，bug修复等操作
这样就能带来明显的价值效益


```

### AI小镇
```
https://github.com/joonspk-research/generative_agents

```

## huggingface
### SkyTextTiny 模型
```
git clone https://huggingface.co/SkyWork/SkyTextTiny.git    


```
## 业务向
### 智能文档信息提取
```
https://www.paddlepaddle.org.cn/support/news?action=detail&id=3174

DocVQA榜单
https://rrc.cvc.uab.es/?ch=17&com=evaluation&task=1 

百度AI开放平台——智能文档分析平台
https://ai.baidu.com/tech/nlp/Textanalysis

在线调试
https://console.bce.baidu.com/tools/#/api?product=AI&project=%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB&parent=%E9%89%B4%E6%9D%83%E8%AE%A4%E8%AF%81%E6%9C%BA%E5%88%B6&api=oauth%2F2.0%2Ftoken&method=post


开源了！文心大模型ERNIE-Tiny轻量化技术，又准又快，效果全开 - 飞桨PaddlePaddle的文章 - 知乎
https://zhuanlan.zhihu.com/p/535541528

【快速上手ERNIE 3.0】机器阅读理解实战 - 快速实现AI想法的文章 - 知乎
https://zhuanlan.zhihu.com/p/536541088


```
### 2023IKCEST第五届一带一路国际大数据竞赛
#### todolist
1. 提供resnet模型效果
2. bert ernie模型训练加载器
3. LinearDecayWithWarmup 学习率调度器类，它根据线性递减策略计算学习率。在训练过程中
4. LinearWarmup
5. 交叉熵损失
6. 评估的时候采用准确率指标
7. Optimizer
   1. Momentum
   2. adam
8. 模型断点训练
9.  paddle
   1. vision
   2. paddle.concat
   3. paddle.stack
   4. paddle.reshape
   5. 

#### 优化目标
```
文本识别
图形识别
向量concat

预测分类

我的想法
文本识别的特征如何 和 图像识别的特征保持一致呢

数据增广 丰富训练集，加强训练

可使用工具
PaddleDetection


```

#### 模型训练优化经验
```
如何优化你的模型 - 错乱空时的文章 - 知乎
https://zhuanlan.zhihu.com/p/360647927

NLP中文预训练模型泛化能力挑战赛
https://tianchi.aliyun.com/competition/entrance/531841/forum

2021语言与智能技术竞赛：多形态信息抽取任务
https://aistudio.baidu.com/competition/detail/65/0/introduction

二等奖方案|产品评论观点提取赛题
https://discussion.datafountain.cn/articles/detail/3764

推荐 nlp cv大模型参数量总结
https://zhuanlan.zhihu.com/p/529863941

竞赛达人的竞赛之旅
https://zhuanlan.zhihu.com/p/375688838

数据
数据预处理
数据增广
外部数据
模型
大力出奇迹
模型结构
loss
label Smooting
优化方法
学习率
对抗训练
EMA，SWA
正则化
word mixup
dropout
early stop
后处理
阈值优化
其他
未起效方法
训练技巧
自知识蒸馏


```

### 竞赛方案复现
```
关键词搜索
名方案

竞赛达人竞赛之旅
https://zhuanlan.zhihu.com/p/375688838


“公益AI之星”挑战赛-新冠疫情相似句对判定大赛
https://tianchi.aliyun.com/competition/entrance/231776/forum
第一名
https://tianchi.aliyun.com/notebook/101624

NLP中文预训练模型泛化能力挑战赛
https://tianchi.aliyun.com/competition/entrance/531841/forum

2021语言与智能技术竞赛：多形态信息抽取任务
https://aistudio.baidu.com/competition/detail/65/0/introduction

二等奖方案|产品评论观点提取赛题
https://discussion.datafountain.cn/articles/detail/3764

表格检测
https://aistudio.baidu.com/competition/detail/702/0/submit-result
https://aistudio.baidu.com/competition/detail/704/0/introduction

第二名方案
https://aistudio.baidu.com/projectdetail/5398861?channelType=0&channel=0


百度网盘AI大赛——图像处理挑战赛：文档图像摩尔纹消除第1名方案
https://aistudio.baidu.com/projectdetail/3462083?channelType=0&channel=0


百度网盘文档图像超分比赛-Serendipity团队-AB榜第二方案 metaRLFN网络
https://aistudio.baidu.com/projectdetail/5133608?channelType=0&channel=0


第五届“中国法研杯”司法人工智能挑战赛
https://aistudio.baidu.com/competition/detail/664/0/submit-result

中国人工智能大赛·语言与知识技术竞赛（个人赛）冠军方案分享
https://aistudio.baidu.com/projectdetail/755387?channelType=0&channel=0

WSDM Cup 2023: Pre-training for Web Search Demo Code
https://aistudio.baidu.com/projectdetail/4844225?channelType=0&channel=0

【飞桨学习赛：百度搜索首届技术创新挑战赛：赛道一】第5名方案
https://aistudio.baidu.com/projectdetail/4950227?channelType=0&channel=0


百度搜索首届技术创新挑战赛赛道二Baseline
https://aistudio.baidu.com/projectdetail/5007642?channelType=0&channel=0


“飞桨杯”重庆市首届人工智能创新大赛-社交网络大数据谣言核查官方baseline
https://aistudio.baidu.com/projectdetail/4913037?channelType=0&channel=0

2022 IKCEST第四届“一带一路”国际大数据竞赛：“一带一路”重点语种-法俄泰阿与中文互译
https://aistudio.baidu.com/competition/detail/477/0/introduction

2022 CCF BDCI 基于文心NLP大模型的阅读理解可解释评测
https://aistudio.baidu.com/competition/detail/394/0/introduction
第五名
https://aistudio.baidu.com/projectdetail/5016503?channelType=0&channel=0


CCKS2022基于知识图谱的优质文章识别
https://aistudio.baidu.com/competition/detail/255/0/introduction


2022 CCF BDCI 基于文心CV大模型的智慧城市视觉多任务识别
https://aistudio.baidu.com/competition/detail/455/0/introduction
第一名
https://aistudio.baidu.com/projectdetail/5035322?channelType=0&channel=0


AIWIN 世界人工智能创新大赛：中文保险小样本多任务竞赛
https://aistudio.baidu.com/competition/detail/218/0/introduction

AIWIN 世界人工智能创新大赛：发债主体违约风险预测竞赛
https://aistudio.baidu.com/competition/detail/222/0/introduction

2021“智荟杯”浦发百度高校极客挑战赛
https://aistudio.baidu.com/competition/detail/123/0/task-definition

【Paddle打比赛】基于PaddleNLP法研杯2022 -犯罪事实实体识别
https://aistudio.baidu.com/projectdetail/4821353?channelType=0&channel=0

2021中国软件杯——新闻智分系统
https://aistudio.baidu.com/projectdetail/1981601?channelType=0&channel=0


2022 CCF BDCI 模心智创-文心大模型智能创意赛
https://aistudio.baidu.com/competition/detail/397/0/introduction



文本智能校对大赛
https://aistudio.baidu.com/competition/detail/404/0/introduction

航旅纵横-领域知识问答测评
https://aistudio.baidu.com/competition/detail/313/0/introduction

飞桨论文复现挑战赛（第六期）
https://aistudio.baidu.com/competition/detail/205/0/introduction

飞桨论文复现挑战赛（第七期）
https://aistudio.baidu.com/competition/detail/406/0/task-definition

2022世界人工智能大会黑客马拉松：百度飞桨论文复现赛
https://aistudio.baidu.com/competition/detail/430/0/introduction

2022世界人工智能大会黑客马拉松：百度飞桨黑客马拉松
https://aistudio.baidu.com/competition/detail/428/0/introduction

兴智杯 全国人工智能创新应用大赛：百度飞桨论文复现赛
https://aistudio.baidu.com/competition/detail/439/0/introduction

“兴智杯”全国人工智能创新应用大赛：深度学习模型可解释性赛
https://aistudio.baidu.com/competition/detail/472/0/introduction



```

## 基础
### Transformer
```

```
#### layer-normal
```

```
#### position
```

```

### Bert
```

```

### resnet
```

```



### ernie-m 网络结构
```
NetWork(
  (ernie): ErnieMModel(
    (embeddings): ErnieMEmbeddings(
      (word_embeddings): Embedding(250002, 768, sparse=False)
      (position_embeddings): Embedding(514, 768, sparse=False)
      (layer_norm): LayerNorm(normalized_shape=[768], epsilon=1e-05)
      (dropout): Dropout(p=0.1, axis=None, mode=upscale_in_train)
    )
    (encoder): TransformerEncoder(
      (layers): LayerList(
        (0): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (1): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (2): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (3): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (4): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (5): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (6): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (7): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (8): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (9): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (10): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
        (11): TransformerEncoderLayer(
          (self_attn): MultiHeadAttention(
            (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
            (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
          )
          (linear1): Linear(in_features=768, out_features=3072, dtype=float32)
          (dropout): Dropout(p=0, axis=None, mode=upscale_in_train)
          (linear2): Linear(in_features=3072, out_features=768, dtype=float32)
          (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-05)
          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)
          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)
        )
      )
    )
    (pooler): ErnieMPooler(
      (dense): Linear(in_features=768, out_features=768, dtype=float32)
      (activation): Tanh()
    )
  )
  (resnet): EncoderCNN(
    (resnet): Sequential(
      (0): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)
      (1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
      (2): ReLU()
      (3): MaxPool2D(kernel_size=3, stride=2, padding=1)
      (4): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
            (1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=64, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (5): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=128, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (6): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (3): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (4): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (5): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (6): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (7): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (8): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (9): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (10): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (11): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (12): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (13): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (14): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (15): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (16): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (17): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (18): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (19): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (20): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (21): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (22): BottleneckBlock(
          (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=1024, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
      (7): Sequential(
        (0): BottleneckBlock(
          (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
          (downsample): Sequential(
            (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)
            (1): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
        (2): BottleneckBlock(
          (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)
          (bn1): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
          (bn2): BatchNorm2D(num_features=512, momentum=0.9, epsilon=1e-05)
          (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)
          (bn3): BatchNorm2D(num_features=2048, momentum=0.9, epsilon=1e-05)
          (relu): ReLU()
        )
      )
    )
    (adaptive_pool): AdaptiveAvgPool2D(output_size=(1, 1))
  )
  (classifier1): Linear(in_features=5632, out_features=1024, dtype=float32)
  (classifier2): Linear(in_features=1024, out_features=3, dtype=float32)
  (attention_text): MultiHeadAttention(
    (q_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (k_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (v_proj): Linear(in_features=768, out_features=768, dtype=float32)
    (out_proj): Linear(in_features=768, out_features=768, dtype=float32)
  )
  (attention_image): MultiHeadAttention(
    (q_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (k_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (v_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
    (out_proj): Linear(in_features=2048, out_features=2048, dtype=float32)
  )
)
```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

### 
```

```

## 从0到1安装
```bash
ubuntu
apt-get update
apt install sudo -y
# programm
apt install -y gcc-9 g++-9
# golang 1.20版本
wget https://mirrors.ustc.edu.cn/golang/go1.21.0.linux-amd64.tar.gz
tar -zxvf go1.21.0.linux-amd64.tar.gz
rm -rf /usr/local/go && tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz
rm -rf /usr/bin/go && tar -C /usr/bin -xzf go1.21.0.linux-amd64.tar.gz
export PATH=$PATH:/usr/local/go/bin
go version
go env -w GO111MODULE=on
go env -w GOPROXY=https://goproxy.cn,direct

# pg库
apt-get install libpq-dev -y
apt install postgresql -y
service postgresql start
# 创建库表
sudo -u postgres psql
CREATE USER dbusername WITH PASSWORD 'dbpassword';
CREATE DATABASE db;


# python3
apt install -y python3.8
apt install -y python3-pip
# openGL库
apt-get install -y libgl1-mesa-glx

# sql
pip3 install SQLAlchemy==1.4.23 -i https://pypi.mirrors.ustc.edu.cn/simple
pip3 install psycopg2 


# pytorch
pip3 install torch torchvision -i https://pypi.mirrors.ustc.edu.cn/simple # 用国内源
pip3 install graphviz -i https://pypi.mirrors.ustc.edu.cn/simple

# huggingface
pip3 install setuptools_rust
pip3 install transformers

# juypter
pip3 install setuptools_scm
pip3 install argon2-cffi-bindings
pip3 install jupyter



# paddlepaddle 全家桶
pip3 install paddlepaddle==2.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip3 install paddleocr
pip3 install visualdl==2.4.0  
pip3 install flask-babel==1.0.0
pip3 install paddlenlp -i https://pypi.tuna.tsinghua.edu.cn/simple    

# pdf工具
pip3 install pdf2image
pip3 install gradio
pip3 install pdfplumber   

pip3 install langchain
# embedding
pip3 install fastNLP  
pip3 install fuzzywuzzy
python3 -m pip install milvus
pip3 install jieba

# modelscope
pip3 install numpy pandas urllib3
pip3 install datasets==2.13.0
pip3 install dill==0.3.6
pip3 install multiprocess==0.70.14
pip3 install accelerate -U
pip3 install sentencepiece -U
pip3 install modelscope -U 

# 打包当前环境
pip3 freeze > requirements.txt



# 业务逻辑
# llm_demo服务
dir=`pwd`
export PYTHONPATH=$PYTHONPATH:$dir
export PYTHONPATH=$PYTHONPATH:/mnt/workspace

# 写入数据
cd /mnt/workspace/llm_demo/util
python3 insert_balance_sheet.py
python3 insert_cash_flow.py
python3 insert_company_annual_reports.py
python3 insert_profit_statement.py

mv /etc/dsw/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /etc/dsw/lib/libffi.so.8 /mnt/workspace/libffi/.
mv /opt/conda/lib/libffi.so.8 /mnt/workspace/libffi/.
mv /opt/conda/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /opt/conda/pkgs/libffi-3.4.2-h6a678d5_6/lib/libffi.so.8.1.0 /mnt/workspace/libffi/.
mv /opt/conda/pkgs/libffi-3.4.2-h6a678d5_6/lib/libffi.so.8 /mnt/workspace/libffi/.


cp /mnt/workspace/libffi/libffi.so.8 /opt/conda/lib/libffi.so.8 



```
