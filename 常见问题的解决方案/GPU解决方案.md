## GPUè§£å†³æ–¹æ¡ˆ

### èµ„æ–™
```

[CUDA å­¦ä¹ ç¬”è®°] GEMM ä¼˜åŒ–: åŒç¼“å†² (Prefetch) å’Œ Bank Conflict è§£å†³ - PeakCrosserçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/696844342


å¦‚ä½•ç³»ç»Ÿåœ°å­¦ä¹ CUDAï¼Ÿ - Kedreamixçš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/263832290/answer/3322864217
https://github.com/Kedreamix/pytorch-cppcuda-tutorial


cudaç¼–ç¨‹ç¤ºä¾‹
https://face2ai.com/program-blog/#GPU%E7%BC%96%E7%A8%8B%EF%BC%88CUDA%EF%BC%89



CUDAè¿˜èƒ½èµ°å¤šè¿œï¼Ÿ - ç‹æŒ¯é‚¦çš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/30597217/answer/3024851394


å¦‚ä½•ç³»ç»Ÿå­¦ä¹ GPUæ¶æ„ï¼Ÿ - Bruce ä»—å‰‘èµ°å¤©æ¶¯çš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/319355296/answer/3374307130


gpuè®¡ç®—ï¼šhttps://www.bilibili.com/video/BV1hE41187Mb?p=3


HPC ä¸­kernel fusionæ˜¯ä»€ä¹ˆï¼Œè¯¥æ€ä¹ˆå­¦ä¹ å‘¢? - æœ‰äº†ç¦ç¦çš„æ£å­çš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/514144710/answer/2491596085


é«˜æ€§èƒ½è®¡ç®—å·¥ç¨‹å¸ˆéœ€è¦ä»€ä¹ˆæŠ€æœ¯å †æ ˆï¼Ÿ opencl dsp neon perf profile tvmï¼Ÿ - æœ‰äº†ç¦ç¦çš„æ£å­çš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/481648758/answer/2206937333

CUDA WarpReduceå­¦ä¹  - zzk againçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/492560229


GPUç¡¬ä»¶çš„å‘å±•ä¸ç‰¹æ€§åˆ†æ---Teslaç³»åˆ—æ±‡æ€» - kaiyuançš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/515584277


cudaç¬”è®°
https://github.com/DefTruth/CUDA-Learn-Note



å¦‚ä½•å­¦ä¹ cudaç¼–ç¨‹ï¼Ÿ - DefTruthçš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/62996995/answer/3369541594


[C++][3Wå­—]ğŸ’¡é™æ€é“¾æ¥å’Œé™æ€åº“å®è·µæŒ‡åŒ—-åŸç†ç¯‡ - DefTruthçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/595527528

æ¨ç†éƒ¨ç½²å·¥ç¨‹å¸ˆé¢è¯•é¢˜åº“ - è¿›å‡»çš„Killuaçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/673046520


OneFlowæŠ€æœ¯å¹´è´§ï¼š800+é¡µå…è´¹â€œå¤§æ¨¡å‹â€ç”µå­ä¹¦ - OneFlowçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/675561734


[AIç¼–è¯‘å™¨åç«¯ä¼˜åŒ–]å¾ªç¯ä¼˜åŒ– - å®ˆå¤œäººçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/685444117



ç†è§£Tensor Core - Frank Wangçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/75753718



```

### cuda æŸ¥çœ‹
```
import paddle


# æ‰“å° PaddlePaddle ç‰ˆæœ¬ä¿¡æ¯
print("PaddlePaddle ç‰ˆæœ¬ä¿¡æ¯ï¼š", paddle.__version__)

# åˆ¤æ–­æ˜¯å¦æœ‰å¯ç”¨çš„ GPU
if paddle.device.is_compiled_with_cuda():
    print("GPU å¯ç”¨")
else:
    print("GPU ä¸å¯ç”¨")

# è·å–å½“å‰å¯ç”¨çš„ GPU æ•°é‡
device_count = paddle.device.cuda.device_count()
print("å½“å‰å¯ç”¨çš„ GPU æ•°é‡ï¼š", device_count)

# è·å–å½“å‰ä½¿ç”¨çš„ GPU çš„è®¡ç®—èƒ½åŠ›
device_capability = paddle.device.cuda.get_device_capability()
print("å½“å‰ä½¿ç”¨çš„ GPU çš„è®¡ç®—èƒ½åŠ›ï¼š", device_capability)

# è·å–å½“å‰ä½¿ç”¨çš„ GPU çš„å±æ€§
device_properties = paddle.device.cuda.get_device_properties(paddle.get_device())
print("å½“å‰ä½¿ç”¨çš„ GPU çš„å±æ€§ï¼š", device_properties)

# è·å–å½“å‰ä½¿ç”¨çš„ GPU åç§°
device_name = paddle.device.cuda.get_device_name(paddle.get_device())
print("å½“å‰ä½¿ç”¨çš„ GPU åç§°ï¼š", device_name)

# è·å–æ‰€æœ‰å¯ç”¨çš„è®¾å¤‡
available_devices = paddle.device.get_available_device()
print("æ‰€æœ‰å¯ç”¨çš„è®¾å¤‡ï¼š", available_devices)

```

### æ˜¾å¡

```
ç‰¹æ–¯æ‹‰t4ï¼šhttp://detail.zol.com.cn/vga/index1242654.shtml
ravenæ˜¾å¡ï¼šhttp://www.fishheadscanada.net/raven-t4/
```

### å¹¶è¡Œè®¡ç®—

```
cudaä»‹ç»ï¼šhttps://zhuanlan.zhihu.com/p/34587739
```

### ç¬”è®°

```
===================================================================================
bank å†²çªï¼Œå½±å“è®¿é—®æ—¶é—´



===================================================================================
cpu gpuæ··åˆç¼–ç¨‹
host deviceçš„ä»£ç å’Œå†…å­˜ç®¡ç† æœ‰ç‚¹ç±»ä¼¼sparkçš„driveræœºå™¨å’Œexcutoræœºå™¨

åˆ†é…hostå†…å­˜ï¼Œæ•°æ®åˆå§‹åŒ–
åˆ†é…deviceå†…å­˜ï¼Œhostæ•°æ®æ‹·è´åˆ°device
cudaæ ¸å‡½æ•° åœ¨deviceä¸­è®¡ç®—
è¿”å›deviceçš„ç»“æœ
ç¨‹åºç»“æŸï¼Œé‡Šæ”¾å†…å­˜

çœŸçš„å’Œsparkçš„map reduceæ€æƒ³ä¸€æ¨¡ä¸€æ ·
å¯ä»¥åšä¸ªå¯¹æ¯”è¡¨


===================================================================================
cudaæ ¸å‡½æ•° kernel
__gloabal__ <grid,block>
threadID
è¿”å›ç±»å‹åªèƒ½æ˜¯void

===================================================================================
grid blockæ˜¯dim3ç±»å‹çš„å˜é‡
(x,y,z)ç»“æ„ä½“å˜é‡

dim3 grid(3,2) 6ä¸ªblock
dim3 block(5,3) 15ä¸ªçº¿ç¨‹ æ€»å…±90ä¸ªçº¿ç¨‹

dim3 grid(128) 128ä¸ªblock
dim3 block(256) 256ä¸ªçº¿ç¨‹ æ€»å…±128 * 256ä¸ªçº¿ç¨‹


===================================================================================
__device__ deviceä¸Šæ‰§è¡Œ
__host__ hostä¸Šæ‰§è¡Œ
__global__ å¼‚æ­¥æ‰§è¡Œ


===================================================================================
ä¸€ä¸ªçº¿ç¨‹å—ä¸Šçš„çº¿ç¨‹æ˜¯æ”¾åœ¨åŒä¸€ä¸ªæµå¤±å¤„ç†å™¨SMä¸Šçš„


===================================================================================
å‘é‡åŠ æ³•


===================================================================================
å…±äº«å†…å­˜
æœ‰ç«äº‰é—®é¢˜
void __synch è®¾ç½®å±éšœç‚¹

å†…å­˜åˆ†æˆbankï¼Œbankåªæ˜¯å°†å…±äº«å†…å­˜åˆ’åˆ†ä¸åŒçš„å°å†…å­˜å—
å¤šä¸ªçº¿ç¨‹è®¿é—®å¤šä¸ªbankï¼Œå¦‚æœéƒ½æ²¡æœ‰å†²çªï¼Œé‚£ä¹ˆå°±æ˜¯æ•ˆç‡æœ€å¤§åŒ–äº†
å¦‚æœå¤šä¸ªçº¿ç¨‹åŒæ—¶è®¿é—®ä¸€ä¸ªbankï¼Œä¸ºäº†æ•°æ®ä¸€è‡´æ€§ï¼Œå¤šä¸ªçº¿ç¨‹ä¼šå˜æˆé¡ºåºæ‰§è¡Œï¼Œæ€§èƒ½å˜å¾—å¾ˆå·®


===================================================================================
ç»Ÿä¸€(unified)å†…å­˜åˆ†é…é‡Šæ”¾
cudaMallocManaged
cudaFree
cudaMemcpy å†…å­˜æ‹·è´

===================================================================================
wrap æ˜¯smçš„åŸºæœ¬æ‰§è¡Œå•ä½ï¼Œæœ‰32ä¸ªçº¿ç¨‹
æœ‰ç‹¬ç«‹çš„æŒ‡ä»¤åœ°å€è®¡æ•°å™¨ï¼Œç‹¬ç«‹çš„æ‰§è¡Œè·¯å¾„
åˆ†æ”¯ç»“æ„å¯èƒ½å‡ºç°æ­»ç­‰
çº¿ç¨‹æŸä¸­çš„æ‰€æœ‰çº¿ç¨‹åœ¨åŒä¸€å‘¨æœŸæ‰§è¡Œç›¸åŒæŒ‡ä»¤
æå°åŒ–å‘½ä»¤çš„åˆ†åŒ–

===================================================================================
çº¿ç¨‹å— åˆ’åˆ†ä¸ºå¤šä¸ªçº¿ç¨‹æŸ


===================================================================================
è§„çº¦ç®—æ³•
ç±»ä¼¼æ ‘çš„ç»“æ„ï¼Œæ¯”å¦‚æ±‚å’Œï¼Œä¸¤ä¸¤ä¸ªèŠ‚ç‚¹ç›¸åŠ æ±‚å’Œ

æ¯ä¸€å±‚çš„ç»“æœéœ€è¦åŒæ­¥



===================================================================================
å……åˆ†åˆ©ç”¨gpuæ€§èƒ½
æé«˜æµ®ç‚¹æ•°è¿ç®—
æé«˜å†…å­˜å¸¦å®½

è®©åŒä¸€ä¸ªwrapæ‰§è¡Œä¸€æ ·çš„æŒ‡ä»¤ï¼Œä¸è¦åˆ†åŒ–

ä¸è¦æ•°æ®è®¿é—®å†²çªï¼Œæ”¹å–„bankæ•°æ®è®¿é—®

ä¼˜åŒ–å…¨å±€å†…å­˜è®¿é—®ï¼Œåœ¨æ±‚å’Œçš„æ—¶å€™ï¼ŒåŒæ—¶è®¿é—®ä¸¤ä¸ªæ•°æ®

ä¸€ä¸ªwrapæ˜¯32ä¸ªçº¿ç¨‹ï¼Œå½“è®¡ç®—çš„æ—¶å€™ä¸éœ€è¦32ä¸ªçº¿ç¨‹ï¼Œå°äº32ä¸ªçº¿ç¨‹ï¼Œå¯ä»¥æŠŠè®¡ç®—æ–¹å¼å±•å¼€
ä¸ç”¨å¾ªç¯å’Œç›¸å…³æŒ‡ä»¤ï¼Œæ•°æ®åŒæ­¥

ç”¨switchæ–¹å¼ï¼ŒæŠŠæ‰€æœ‰æƒ…å†µéƒ½å±•å¼€å‡ºæ¥ï¼Œä¸ä½¿ç”¨forå¾ªç¯åšåŠ æ³•

volatile å¯ä»¥é˜²æ­¢ç¼–è¯‘å™¨æå‰ä¼˜åŒ–ä»£ç ï¼Œå› ä¸ºå…±äº«å†…å­˜çš„æ–¹é¢çš„è®¡ç®—ä¼šå‡ºç°ä¼˜åŒ–çš„å¯èƒ½æ€§
===================================================================================
ä¼˜åŒ–ç­–ç•¥
ç®—æ³•æœ€å¤§åŒ–å¹¶è¡Œæ‰§è¡Œ
ä¼˜åŒ–å†…å­˜ä½¿ç”¨
ä¼˜åŒ–ç¼–è¯‘æŒ‡ä»¤




===================================================================================


===================================================================================
```


## ç®—å­ä¼˜åŒ–
```



[CUDA å­¦ä¹ ç¬”è®°] Reduce ç®—å­ä¼˜åŒ– - PeakCrosserçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/688610091

è‹±ä¼Ÿè¾¾å®˜æ–¹æ–‡æ¡£
https://developer.download.nvidia.cn/assets/cuda/files/reduction.pdf

æ·±å…¥æµ…å‡ºGPUä¼˜åŒ–ç³»åˆ—ï¼šreduceä¼˜åŒ– - æœ‰äº†ç¦ç¦çš„æ£å­çš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/426978026

æ¼«è°ˆé«˜æ€§èƒ½è®¡ç®—ä¸æ€§èƒ½ä¼˜åŒ–ï¼šè®¡ç®— - æœ‰äº†ç¦ç¦çš„æ£å­çš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/688613416


å¦‚ä½•çœ‹å¾…DeepMindæœ€æ–°çš„AIç³»ç»ŸAlphaTensorå¯ä»¥å‘ç°çŸ©é˜µç›¸ä¹˜çš„æ±‚è§£æ–¹æ³•ï¼Ÿ - æœ‰äº†ç¦ç¦çš„æ£å­çš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/557880171/answer/2705627296


å¦‚ä½•å®ç°ä¸€ä¸ªé«˜æ•ˆçš„Softmax CUDA kernelï¼Ÿâ€”â€”OneFlow æ€§èƒ½ä¼˜åŒ–åˆ†äº« - OneFlowçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/341059988


é«˜æ•ˆCUDA Scanç®—æ³•æµ…æ - ç†Šå‹’ä¸ªçŒ«çš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/499963645


FasterTransformer Decoding æºç åˆ†æ(å…«)-FFNLayer MoE(ä¸‹ç¯‡) - è¿›å‡»çš„Killuaçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/672189305

FlashAttention çš„é€Ÿåº¦ä¼˜åŒ–åŸç†æ˜¯æ€æ ·çš„ï¼Ÿ - DefTruthçš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/611236756/answer/3410300997


CUDAä¼˜åŒ–ä¹‹LayerNormæ€§èƒ½ä¼˜åŒ–å®è·µ - OneFlowçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/443026261

[æ–½å·¥ä¸­] CUDA GEMM ç†è®ºæ€§èƒ½åˆ†æä¸ kernel ä¼˜åŒ– - æå°‘ä¾ çš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/441146275


FlashAttention v2æ ¸å¿ƒä»£ç è§£æ(ä¸€ï¼‰ - è¿›å‡»çš„Killuaçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/686225377


æœ‰æ²¡æœ‰å¤§æ¨¡å‹æ¨ç†åŠ é€Ÿå¼•æ“FasterTransformerå…¥é—¨çº§æ•™ç¨‹ï¼Ÿ - è¿›å‡»çš„Killuaçš„å›ç­” - çŸ¥ä¹
https://www.zhihu.com/question/602468960/answer/3315182172


flash-attentionå¿«é€Ÿå®ç°
https://github.com/tspeterkim/flash-attention-minimal


ops(2)ï¼šSoftMax ç®—å­çš„ CUDA å®ç°ä¸ä¼˜åŒ– - ç´«æ°”ä¸œæ¥çš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/695307283

```

### GEMMï¼ˆçŸ©é˜µä¹˜ï¼‰çš„ä¼˜åŒ–
1. Spmvï¼ˆç¨€ç–çŸ©é˜µä¹˜ï¼‰

## æ€§èƒ½åˆ†æ
```


åˆ©ç”¨Nsight System å’Œ Nsight Computeè¿›è¡Œæ€§èƒ½ä¼˜åŒ–åˆ†æ - è¿›å‡»çš„Killuaçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/673282220


ã€æ¨ç†å¼•æ“ã€‘NNæ¨¡å‹éƒ¨ç½²æ¡†æ¶/æ¨ç†å¼•æ“æ€»ç»“ - eyesightingçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/672617025


Optimize softmax cuda kernel
https://github.com/Oneflow-Inc/oneflow/pull/4058


ã€åˆ†å¸ƒå¼è®­ç»ƒæŠ€æœ¯åˆ†äº«ä¸ƒã€‘èŠèŠå­—èŠ‚ AML ä¸‡å¡å·¥ä½œ MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs - æ— æ¶ä¸ä½œçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/684619370


æ··åˆè¾“å…¥çŸ©é˜µä¹˜æ³•çš„æ€§èƒ½ä¼˜åŒ– - OneFlowçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/685893061



DeepSpeed-FastGenï¼šé€šè¿‡ MII å’Œ DeepSpeed-Inference å®ç° LLM é«˜ååé‡æ–‡æœ¬ç”Ÿæˆ - å¾®è½¯DeepSpeedçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/665494115


[Transformer 101ç³»åˆ—] LLMæ¨¡å‹é‡åŒ–ä¸–ç•Œè§‚(ä¸Š) - aaronxicçš„æ–‡ç«  - çŸ¥ä¹
https://zhuanlan.zhihu.com/p/686232369


```



### 

### 


## TensorRT
1. å¦‚ä½•è‡ªå­¦TensorRT? - chamberçš„å›ç­” - çŸ¥ä¹ https://www.zhihu.com/question/567947309/answer/3184968930
2. onnxï¼šhttps://onnx.ai/

## é¢è¯•
1. æ¨ç†éƒ¨ç½²å·¥ç¨‹å¸ˆé¢è¯•é¢˜åº“ - è¿›å‡»çš„Killuaçš„æ–‡ç«  - çŸ¥ä¹ https://zhuanlan.zhihu.com/p/673046520
2. 