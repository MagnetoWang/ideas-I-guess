## GPU解决方案

### 资料

```
gpu计算：https://www.bilibili.com/video/BV1hE41187Mb?p=3
```



### 显卡

```
特斯拉t4：http://detail.zol.com.cn/vga/index1242654.shtml
raven显卡：http://www.fishheadscanada.net/raven-t4/
```

### 并行计算

```
cuda介绍：https://zhuanlan.zhihu.com/p/34587739
```

### 笔记

```
===================================================================================
bank 冲突，影响访问时间



===================================================================================
cpu gpu混合编程
host device的代码和内存管理 有点类似spark的driver机器和excutor机器

分配host内存，数据初始化
分配device内存，host数据拷贝到device
cuda核函数 在device中计算
返回device的结果
程序结束，释放内存

真的和spark的map reduce思想一模一样
可以做个对比表


===================================================================================
cuda核函数 kernel
__gloabal__ <grid,block>
threadID
返回类型只能是void

===================================================================================
grid block是dim3类型的变量
(x,y,z)结构体变量

dim3 grid(3,2) 6个block
dim3 block(5,3) 15个线程 总共90个线程

dim3 grid(128) 128个block
dim3 block(256) 256个线程 总共128 * 256个线程


===================================================================================
__device__ device上执行
__host__ host上执行
__global__ 异步执行


===================================================================================
一个线程块上的线程是放在同一个流失处理器SM上的


===================================================================================
向量加法


===================================================================================
共享内存
有竞争问题
void __synch 设置屏障点

内存分成bank，bank只是将共享内存划分不同的小内存块
多个线程访问多个bank，如果都没有冲突，那么就是效率最大化了
如果多个线程同时访问一个bank，为了数据一致性，多个线程会变成顺序执行，性能变得很差


===================================================================================
统一(unified)内存分配释放
cudaMallocManaged
cudaFree
cudaMemcpy 内存拷贝

===================================================================================
wrap 是sm的基本执行单位，有32个线程
有独立的指令地址计数器，独立的执行路径
分支结构可能出现死等
线程束中的所有线程在同一周期执行相同指令
极小化命令的分化

===================================================================================
线程块 划分为多个线程束


===================================================================================
规约算法
类似树的结构，比如求和，两两个节点相加求和

每一层的结果需要同步



===================================================================================
充分利用gpu性能
提高浮点数运算
提高内存带宽

让同一个wrap执行一样的指令，不要分化

不要数据访问冲突，改善bank数据访问

优化全局内存访问，在求和的时候，同时访问两个数据

一个wrap是32个线程，当计算的时候不需要32个线程，小于32个线程，可以把计算方式展开
不用循环和相关指令，数据同步

用switch方式，把所有情况都展开出来，不使用for循环做加法

volatile 可以防止编译器提前优化代码，因为共享内存的方面的计算会出现优化的可能性
===================================================================================
优化策略
算法最大化并行执行
优化内存使用
优化编译指令




===================================================================================


===================================================================================
```



