## 整体过程

```mermaid
graph LR
Kafka
ClickHouse
playback(数据转换)
search(回放平台)
Kafka-->playback
playback-->ClickHouse
ClickHouse-->search

```


## 服务

```mermaid
graph LR
Kafka
ClickHouse
KafkaService
ClickHouseService
playbackService

Kafka-->KafkaService
ClickHouseService-->ClickHouse

KafkaService-->playbackService
playbackService-->ClickHouseService


```

## 数据转换

```mermaid
graph LR
Kafka
ClickHouse
playback(数据转换)

Kafka-->playback
playback-->ClickHouse
```





## KafkaService
```mermaid
graph LR
Kafka
KafkaService
JsonService
ClickHouseService
MessageClass

Kafka-->|1.提供消息|KafkaService
KafkaService-->|2.消息格式转换|MessageClass
MessageClass-->|3.提供json格式|KafkaService
JsonService-->|4.提供json定位服务|KafkaService
JsonService-->|5.提供json对象转SQL服务|KafkaService


KafkaService-->|6.提供SQL语句|ClickHouseService



```


## ClickHouseService
```mermaid
graph LR
KafkaService
ClickHouseService

OperationType 
PlayBackTableClass


KafkaService-->|提供日志|ClickHouseService
ClickHouseService-->|日志分析得出用户行为|OperationType
ClickHouseService-->|日志分析得出有效时间点|operation_timestamp


OperationType-->1(输入搜索词)
OperationType-->2(点击sug)
OperationType-->3(修改筛选条件)
OperationType-->4(点击搜索结果)
OperationType-->5(进入结果详情)
OperationType-->6(拨打400电话)



OperationType-->|写入|PlayBackTableClass
operation_timestamp-->|写入|PlayBackTableClass
```

## 用户行为逻辑

- 问题：如何从已有的日志数据提取我们想要的有用的数据呢？



```mermaid
graph LR
log
search_log
click_log
search_words


log-->click_log
log-->search_log

search_log-->search_words

click_log-->sort
click_log-->filter
```



## 多线程PlayBackService

- 原则
  - run函数：必须只执行一个工作
  - 线程池数据必须加约束条件
- 方案
  - 只生成insert语句
  - 用队列维护数据，确保多线程下操作不冲突
- 问题
  - 高并发大流量情况下，连接池始终不够用
  - 而且数据库那边拒绝100个以上的并发请求
  - 不过小流量情况，跑的挺稳定的



```mermaid
graph TD
MessageQueue
InsertQueue
PlayBackService
ClickHouseService
ConnectionPool

Kafka-->MessageQueue
MessageQueue-->PlayBackService1
MessageQueue-->PlayBackService2
MessageQueue-->PlayBackService3



PlayBackService1-->InsertQueue
PlayBackService2-->InsertQueue
PlayBackService3-->InsertQueue

InsertQueue-->PlayBackService
PlayBackService-->Connection1
PlayBackService-->Connection2
PlayBackService-->Connection3
Connection1-->ConnectionPool
Connection2-->ConnectionPool
Connection3-->ConnectionPool


ConnectionPool-->ClickHouseService

```

## 用户行为总结

1. 输入搜索词，显示搜索词结果
2. 点击sug
3. 修改筛选条件，filter字段
4. 点击搜索结果，显示点击的位置
5. 进入结果详情
6. 拨打400电话
7. 排序，sort字段

## PlayBackTable的填充

```mermaid
graph TD
PlayBackTable-->time
PlayBackTable-->Summary
Summary-->Type1(点击)
Summary-->Type2(无点击)
Type2-->Type3(搜索)
Type2-->Type4(排序)
Type2-->Type5(过滤)
Type2-->Type6(sug)

```



## PlayBackTypeTable的填充

```mermaid
graph LR
PlayBackTable



PlayBackTable-->PlayBackTypeTable1(排序)
PlayBackTable-->PlayBackTypeTable2(过滤)
PlayBackTable-->PlayBackTypeTable3(点击)
PlayBackTable-->PlayBackTypeTable4(sug)
PlayBackTable-->PlayBackTypeTable5(搜索)
PlayBackTable-->PlayBackTypeTable6(结果详情)


```





## 问题

- clickhouse连接池超时问题
  - 单连接方案
  - 自己建立连接池
  - 使用C3P0可是不熟悉，折腾到后面也没有跑动代码
  - 用clickhouseDataSource明显减少这个问题
  - 如何达到一万条不漏数据呢！
  - 因为连接超时丢出的是异常！所以在catch段中在执行一次。目前1万条数据，不少1条。可以说比较完美的解决方案了
  - 

## 回放平台



## 显示房源详细信息



```mermaid
graph TD
detailInformation
api
controller
data


controller-->|调用业务方|api
api-->|返回|data
data-->|过滤|detailInformation
detailInformation-->|显示|playback


```

## 字段解析

### filter字段

- and 和 or 
- 无论match，range直接选中
- 过滤字段的id映射文件

### sort字段

- 上升或下降
- 同样需要映射文件

### 难点

- id映射特别容易出错，为了保证以后的扩展是容易调用，必须切割成一个个功能模块
- filter解析后的格式应该是怎样的
- sort解析格式又是怎样的



## 字段解析流程图一般化

```mermaid
graph TD

api


web
service


web-->|调用|api
api-->|发送json字符串|service
service-->|解析|sort
service-->|解析|filter
service-->|解析|housecode
housecode-->|返回|data
filter-->|返回|data
sort-->|返回|data
data-->|渲染|web
```